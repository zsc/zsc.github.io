<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MNIST ViT Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.18.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script src="https://zsc.github.io/widgets/mnist/mnist_train_labels.js"></script>
    <script src="https://zsc.github.io/widgets/mnist/mnist_test_labels.js"></script>
    <style>
        body { font-family: sans-serif; margin: 20px; display: flex; flex-direction: column; align-items: center; }
        .container { display: flex; flex-wrap: wrap; gap: 20px; justify-content: center; }
        .config-panel, .training-panel, .test-panel { border: 1px solid #ccc; padding: 15px; border-radius: 5px; min-width: 300px; }
        h3 { margin-top: 0; }
        label { display: inline-block; width: 150px; margin-bottom: 5px;}
        input[type="number"], input[type="text"] { width: 80px; margin-bottom: 10px; }
        button { padding: 10px 15px; background-color: #007bff; color: white; border: none; border-radius: 4px; cursor: pointer; margin-top: 10px; }
        button:disabled { background-color: #ccc; }
        #status { margin-top: 15px; font-style: italic; white-space: pre-line; }
        #accuracyChartContainer { max-height: 300px; width: 100%; max-width: 600px; margin-top:20px;}
        #testImageCanvas { border: 1px solid black; margin-top: 10px; }
    </style>
</head>
<body>
    <h1>MNIST Vision Transformer (ViT) Demo</h1>

    <div class="container">
        <div class="config-panel">
            <h3>Hyperparameters</h3>
            <label for="numLayers">ViT Layers:</label>
            <input type="number" id="numLayers" value="2"><br>
            <label for="embeddingDim">Embedding Dim:</label>
            <input type="number" id="embeddingDim" value="64"><br>
            <label for="numHeads">Num Heads:</label>
            <input type="number" id="numHeads" value="4"><br>
            <label for="mlpDim">MLP Dim:</label>
            <input type="number" id="mlpDim" value="128"><br>
            <label for="patchSize">Patch Size (divides 28):</label>
            <input type="number" id="patchSize" value="7"><br>
            <label for="lr">Learning Rate:</label>
            <input type="text" id="lr" value="0.001"><br>
            <label for="numTrainImages">Train Images (max 60k):</label>
            <input type="number" id="numTrainImages" value="6000"><br>
            <label for="epochs">Epochs:</label>
            <input type="number" id="epochs" value="10"><br>
            <label for="batchSize">Batch Size:</label>
            <input type="number" id="batchSize" value="128"><br>
            <button id="startTrainingBtn">Start Training</button>
        </div>

        <div class="training-panel">
            <h3>Training Progress</h3>
            <div id="accuracyChartContainer">
                <canvas id="accuracyChart"></canvas>
            </div>
            <button id="exportWeightsBtn" disabled>Export Model Weights</button>
        </div>

        <div class="test-panel">
            <h3>Test Model</h3>
            <button id="testRandomBtn" disabled>Test Random Image</button>
            <div>
                <canvas id="testImageCanvas" width="56" height="56"></canvas>
                <p id="testResult"></p>
            </div>
        </div>
    </div>
    <div id="status">Status: Idle. Configure parameters and start training.</div>

    <script>
        // Global variables
        let model;
        let trainImg, testImg;
        let trainImageData, testImageData;
        const trainLabels = typeof mnistTrainLabels !== 'undefined' ? mnistTrainLabels : [];
        const testLabels = typeof mnistTestLabels !== 'undefined' ? mnistTestLabels : [];
        let accuracyChart;
        let currentHyperparams = {};

        const IMG_WIDTH = 28;
        const IMG_HEIGHT = 28;
        const NUM_CLASSES = 10;

        const statusEl = document.getElementById('status');
        const startTrainingBtn = document.getElementById('startTrainingBtn');
        const exportWeightsBtn = document.getElementById('exportWeightsBtn');
        const testRandomBtn = document.getElementById('testRandomBtn');

        function log(message) {
            console.log(message);
            statusEl.textContent = message;
        }

        // --- Data Loading and Preprocessing ---
        async function loadStitchedImage(url) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = "anonymous"; // Needed for canvas operations on images from other domains
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = url; // img.src must be set after onload
            });
        }

        function getImageDataFromStitched(stitchedImg) {
            const canvas = document.createElement('canvas');
            canvas.width = stitchedImg.width;
            canvas.height = stitchedImg.height;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(stitchedImg, 0, 0);
            return ctx.getImageData(0, 0, stitchedImg.width, stitchedImg.height);
        }
        
        function extractImageTensor(sourceImageData, index, imagesPerRow) {
            return tf.tidy(() => {
                const H = IMG_HEIGHT;
                const W = IMG_WIDTH;
                const C = 1; // Grayscale

                const row = Math.floor(index / imagesPerRow);
                const col = index % imagesPerRow;
                const sx = col * W;
                const sy = row * H;

                const pixels = new Float32Array(H * W * C);
                for (let y = 0; y < H; y++) {
                    for (let x = 0; x < W; x++) {
                        const srcIdx = ((sy + y) * sourceImageData.width + (sx + x)) * 4; // RGBA
                        pixels[y * W + x] = sourceImageData.data[srcIdx] / 255.0; // Use R channel, normalize
                    }
                }
                return tf.tensor3d(pixels, [H, W, C]);
            });
        }

        function* dataGenerator(imageData, labels, imagesPerRow, numSamples, batchSize, shuffle = true) {
            const indices = tf.util.createShuffledIndices(numSamples);
            for (let i = 0; i < numSamples; i += batchSize) {
                const batchIndices = shuffle ? 
                    Array.from(indices.slice(i, Math.min(i + batchSize, numSamples))) :
                    Array.from({length: Math.min(batchSize, numSamples - i)}, (_, k) => i + k);

                const imageTensors = [];
                const labelTensors = [];

                for (const index of batchIndices) {
                    imageTensors.push(extractImageTensor(imageData, index, imagesPerRow));
                    labelTensors.push(labels[index]);
                }
                
                const batchImages = tf.stack(imageTensors);
                const batchLabels = tf.oneHot(tf.tensor1d(labelTensors, 'int32'), NUM_CLASSES);
                
                yield { xs: batchImages, ys: batchLabels };

                imageTensors.forEach(t => t.dispose()); // Clean up individual tensors
                // batchImages and batchLabels will be disposed by the training loop's tf.tidy
            }
        }


        // --- ViT Model Definition ---
        class MultiHeadAttention extends tf.layers.Layer {
            constructor(config) {
                super(config);
                this.embeddingDim = config.embeddingDim;
                this.numHeads = config.numHeads;
                if (this.embeddingDim % this.numHeads !== 0) {
                    throw new Error('MultiHeadAttention: embeddingDim must be divisible by numHeads');
                }
                this.headDim = this.embeddingDim / this.numHeads;
            }

            build(inputShape) {
                this.wq = this.addWeight('wq_kernel', [this.embeddingDim, this.embeddingDim], 'float32', tf.initializers.glorotUniform());
                this.bq = this.addWeight('wq_bias', [this.embeddingDim], 'float32', tf.initializers.zeros());
                this.wk = this.addWeight('wk_kernel', [this.embeddingDim, this.embeddingDim], 'float32', tf.initializers.glorotUniform());
                this.bk = this.addWeight('wk_bias', [this.embeddingDim], 'float32', tf.initializers.zeros());
                this.wv = this.addWeight('wv_kernel', [this.embeddingDim, this.embeddingDim], 'float32', tf.initializers.glorotUniform());
                this.bv = this.addWeight('wv_bias', [this.embeddingDim], 'float32', tf.initializers.zeros());
                this.wo = this.addWeight('wo_kernel', [this.embeddingDim, this.embeddingDim], 'float32', tf.initializers.glorotUniform());
                this.bo = this.addWeight('wo_bias', [this.embeddingDim], 'float32', tf.initializers.zeros());
                this.built = true;
            }

            call(inputs) {
                return tf.tidy(() => {
                    const x = Array.isArray(inputs) ? inputs[0] : inputs;
                    const batchSize = x.shape[0];
                    const seqLen = x.shape[1];

                    let q = tf.matMul(x, this.wq).add(this.bq);
                    let k = tf.matMul(x, this.wk).add(this.bk);
                    let v = tf.matMul(x, this.wv).add(this.bv);

                    q = q.reshape([batchSize, seqLen, this.numHeads, this.headDim]).transpose([0, 2, 1, 3]);
                    k = k.reshape([batchSize, seqLen, this.numHeads, this.headDim]).transpose([0, 2, 1, 3]);
                    v = v.reshape([batchSize, seqLen, this.numHeads, this.headDim]).transpose([0, 2, 1, 3]);

                    let scores = tf.matMul(q, k.transpose([0, 1, 3, 2]));
                    scores = scores.div(tf.sqrt(tf.scalar(this.headDim)));
                    
                    const attentionWeights = tf.softmax(scores, -1);
                    let context = tf.matMul(attentionWeights, v);
                    context = context.transpose([0, 2, 1, 3]).reshape([batchSize, seqLen, this.embeddingDim]);
                    
                    return tf.matMul(context, this.wo).add(this.bo);
                });
            }
            getClassName() { return 'MultiHeadAttention'; }
        }
        tf.serialization.registerClass(MultiHeadAttention);

        class VisionTransformer extends tf.layers.Layer {
            constructor(config) {
                super(config);
                this.patchSize = config.patchSize;
                this.embeddingDim = config.embeddingDim;
                this.numLayers = config.numLayers;
                this.numHeads = config.numHeads;
                this.mlpDim = config.mlpDim;
                this.numClasses = config.numClasses;
                this.imageSize = IMG_WIDTH; // MNIST specific

                if (this.imageSize % this.patchSize !== 0) {
                    throw new Error('VisionTransformer: Image size must be divisible by patch size.');
                }
                this.numPatches = (this.imageSize / this.patchSize) * (this.imageSize / this.patchSize);
                this.seqLength = this.numPatches + 1;
            }

            build(inputShape) { // inputShape [batch, H, W, C]
                const C = inputShape[3];
                this.patchProjectionKernel = this.addWeight('patch_projection_kernel', 
                    [this.patchSize * this.patchSize * C, this.embeddingDim], 
                    'float32', tf.initializers.glorotUniform());
                this.patchProjectionBias = this.addWeight('patch_projection_bias', 
                    [this.embeddingDim], 'float32', tf.initializers.zeros());

                this.classToken = this.addWeight('class_token', 
                    [1, 1, this.embeddingDim], 'float32', tf.initializers.zeros());

                this.positionalEmbeddings = this.addWeight('positional_embeddings',
                    [1, this.seqLength, this.embeddingDim], 'float32', tf.initializers.randomNormal({stddev: 0.02}));
                
                this.encoderBlocks = [];
                for (let i = 0; i < this.numLayers; i++) {
                    this.encoderBlocks.push({
                        norm1: tf.layers.layerNormalization({epsilon: 1e-6, name: `encoder_norm1_${i}`}),
                        mha: new MultiHeadAttention({embeddingDim: this.embeddingDim, numHeads: this.numHeads, name: `mha_${i}`}),
                        norm2: tf.layers.layerNormalization({epsilon: 1e-6, name: `encoder_norm2_${i}`}),
                        mlp_dense1: tf.layers.dense({units: this.mlpDim, activation: 'gelu', name: `mlp_dense1_${i}`}),
                        mlp_dense2: tf.layers.dense({units: this.embeddingDim, name: `mlp_dense2_${i}`})
                    });
                }
                
                this.headNorm = tf.layers.layerNormalization({epsilon: 1e-6, name: 'head_norm'});
                this.headDense = tf.layers.dense({units: this.numClasses, name: 'head_dense'});
                
                super.build(inputShape);
            }

            call(inputs) {
                return tf.tidy(() => {
                    const x = Array.isArray(inputs) ? inputs[0] : inputs;
                    const batchSize = x.shape[0];

                    const patches = tf.image.extractPatches({
                        images: x,
                        sizes: [1, this.patchSize, this.patchSize, 1],
                        strides: [1, this.patchSize, this.patchSize, 1],
                        rates: [1, 1, 1, 1],
                        padding: 'VALID'
                    }).reshape([batchSize, this.numPatches, -1]);

                    let embeddings = tf.matMul(patches, this.patchProjectionKernel).add(this.patchProjectionBias);
                    
                    const classTokenBroadcast = tf.tile(this.classToken, [batchSize, 1, 1]);
                    embeddings = tf.concat([classTokenBroadcast, embeddings], 1);
                    embeddings = embeddings.add(this.positionalEmbeddings);

                    let encoded = embeddings;
                    for (let i = 0; i < this.numLayers; i++) {
                        const block = this.encoderBlocks[i];
                        const x1 = block.norm1.apply(encoded);
                        const attentionOutput = block.mha.apply(x1);
                        const x2 = tf.add(encoded, attentionOutput);
                        
                        const x3 = block.norm2.apply(x2);
                        let mlpOutput = block.mlp_dense1.apply(x3);
                        mlpOutput = block.mlp_dense2.apply(mlpOutput);
                        encoded = tf.add(x2, mlpOutput);
                    }
                    
                    const classTokenOutput = encoded.slice([0, 0, 0], [batchSize, 1, this.embeddingDim]).reshape([batchSize, this.embeddingDim]);
                    const headOutputNorm = this.headNorm.apply(classTokenOutput);
                    return this.headDense.apply(headOutputNorm);
                });
            }
            getClassName() { return 'VisionTransformer'; }
        }
        tf.serialization.registerClass(VisionTransformer);

        function createModel(params) {
            currentHyperparams = {...params}; // Store for export
            const vit = new VisionTransformer({
                patchSize: params.patchSize,
                embeddingDim: params.embeddingDim,
                numLayers: params.numLayers,
                numHeads: params.numHeads,
                mlpDim: params.mlpDim,
                numClasses: NUM_CLASSES
            });

            // To make it behave like a tf.Model for compile/fit, wrap it
            const input = tf.input({shape: [IMG_HEIGHT, IMG_WIDTH, 1]});
            const output = vit.apply(input);
            return tf.model({inputs: input, outputs: output});
        }


        // --- Training ---
        async function trainModel(params) {
            startTrainingBtn.disabled = true;
            exportWeightsBtn.disabled = true;
            testRandomBtn.disabled = true;
            log('Initializing model...');

            if (model) model.dispose(); // Dispose previous model
            model = createModel(params);
            
            const optimizer = tf.train.adam(params.lr);
            model.compile({
                optimizer: optimizer,
                loss: 'categoricalCrossentropy',
                metrics: ['accuracy']
            });
            log('Model compiled. Starting training...');

            const trainDataset = dataGenerator(trainImageData, trainLabels, 245, params.numTrainImages, params.batchSize);
            const testDatasetForEval = () => dataGenerator(testImageData, testLabels, 100, testLabels.length, params.batchSize, false);
            
            const trainAccs = [];
            const testAccs = [];
            const epochLabels = [];

            for (let epoch = 0; epoch < params.epochs; epoch++) {
                log(`Epoch ${epoch + 1}/${params.epochs} starting...`);
                let epochTrainSamples = 0;
                let epochTrainCorrect = 0;
                
                let batchCount = 0;
                for (const batch of dataGenerator(trainImageData, trainLabels, 245, params.numTrainImages, params.batchSize)) {
                    const history = await model.trainOnBatch(batch.xs, batch.ys);
                    const batchAcc = history.acc; // acc is usually a tensor
                    const batchLoss = history.loss;

                    // Accumulate accuracy manually from predictions for more robust calculation
                    const preds = model.predict(batch.xs);
                    const correct = preds.argMax(-1).equal(batch.ys.argMax(-1)).sum().dataSync()[0];
                    preds.dispose();
                    
                    epochTrainCorrect += correct;
                    epochTrainSamples += batch.xs.shape[0];
                    
                    batch.xs.dispose();
                    batch.ys.dispose();
                    
                    if (batchCount % 10 === 0) { // Log progress every 10 batches
                       log(`Epoch ${epoch + 1}, Batch ${batchCount}: loss = ${batchLoss.dataSync()[0].toFixed(4)}, acc = ${batchAcc.dataSync()[0].toFixed(4)} (batch specific)`);
                    }
                    batchCount++;
                    await tf.nextFrame(); // Yield to UI
                }
                const trainEpochAcc = epochTrainCorrect / epochTrainSamples;
                trainAccs.push(trainEpochAcc);

                // Evaluate on test set
                log(`Epoch ${epoch + 1} finished. Evaluating on test set...`);
                let testSamples = 0;
                let testCorrect = 0;
                for (const batch of testDatasetForEval()) {
                     const preds = model.predict(batch.xs);
                     const correct = preds.argMax(-1).equal(batch.ys.argMax(-1)).sum().dataSync()[0];
                     preds.dispose();
                     testCorrect += correct;
                     testSamples += batch.xs.shape[0];
                     batch.xs.dispose();
                     batch.ys.dispose();
                }
                const testEpochAcc = testCorrect / testSamples;
                testAccs.push(testEpochAcc);
                epochLabels.push(`Epoch ${epoch + 1}`);

                updateChart(epochLabels, trainAccs, testAccs);
                log(`Epoch ${epoch + 1}: Train Acc: ${trainEpochAcc.toFixed(4)}, Test Acc: ${testEpochAcc.toFixed(4)}`);
                await tf.nextFrame();
            }

            log('Training finished.');
            startTrainingBtn.disabled = false;
            exportWeightsBtn.disabled = false;
            testRandomBtn.disabled = false;
        }

        // --- UI and Chart ---
        function initChart() {
            const ctx = document.getElementById('accuracyChart').getContext('2d');
            accuracyChart = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: [],
                    datasets: [
                        {
                            label: 'Train Accuracy',
                            borderColor: 'rgb(75, 192, 192)',
                            data: [],
                            fill: false,
                        },
                        {
                            label: 'Test Accuracy',
                            borderColor: 'rgb(255, 99, 132)',
                            data: [],
                            fill: false,
                        }
                    ]
                },
                options: {
                    responsive: true,
                    maintainAspectRatio: false,
                    scales: {
                        y: {
                            beginAtZero: true,
                            suggestedMax: 1.0
                        }
                    }
                }
            });
        }

        function updateChart(labels, trainData, testData) {
            accuracyChart.data.labels = labels;
            accuracyChart.data.datasets[0].data = trainData;
            accuracyChart.data.datasets[1].data = testData;
            accuracyChart.update();
        }

        function getHyperparameters() {
            return {
                numLayers: parseInt(document.getElementById('numLayers').value),
                embeddingDim: parseInt(document.getElementById('embeddingDim').value),
                numHeads: parseInt(document.getElementById('numHeads').value),
                mlpDim: parseInt(document.getElementById('mlpDim').value),
                patchSize: parseInt(document.getElementById('patchSize').value),
                lr: parseFloat(document.getElementById('lr').value),
                numTrainImages: parseInt(document.getElementById('numTrainImages').value),
                epochs: parseInt(document.getElementById('epochs').value),
                batchSize: parseInt(document.getElementById('batchSize').value),
            };
        }

        function validateHyperparameters(params) {
            if (params.embeddingDim % params.numHeads !== 0) {
                alert("Error: Embedding Dimension must be divisible by Number of Heads.");
                return false;
            }
            if (IMG_WIDTH % params.patchSize !== 0) {
                 alert("Error: Patch Size must be a divisor of 28 (e.g., 4, 7, 14).");
                return false;
            }
            if (params.numTrainImages > trainLabels.length || params.numTrainImages <=0) {
                alert(`Error: Number of training images must be between 1 and ${trainLabels.length}.`);
                return false;
            }
            return true;
        }

        startTrainingBtn.addEventListener('click', async () => {
            const params = getHyperparameters();
            if (!validateHyperparameters(params)) return;
            
            if (!trainImageData || !testImageData) {
                log('Please wait, data is still loading.');
                return;
            }
            // Reset chart for new training
            accuracyChart.data.labels = [];
            accuracyChart.data.datasets[0].data = [];
            accuracyChart.data.datasets[1].data = [];
            accuracyChart.update();
            
            await trainModel(params);
        });

        exportWeightsBtn.addEventListener('click', () => {
            if (!model) {
                log('No model trained yet.');
                return;
            }
            const weights = model.getWeights().map(w => ({
                name: w.name,
                shape: w.shape,
                values: w.arraySync() // Get as nested JS array
            }));
            
            const modelData = {
                hyperparameters: currentHyperparams, // Save the hyperparams used for this model
                weights: weights
            };

            const jsonString = JSON.stringify(modelData);
            const blob = new Blob([jsonString], {type: "application/json"});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'vit_mnist_weights.json';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            log('Model weights exported.');
        });
        
        testRandomBtn.addEventListener('click', () => {
            if (!model || !testImageData) {
                log('Model not trained or test data not loaded.');
                return;
            }
            tf.tidy(() => {
                const randomIndex = Math.floor(Math.random() * testLabels.length);
                const imageTensor = extractImageTensor(testImageData, randomIndex, 100); // 100 images per row for test set
                const actualLabel = testLabels[randomIndex];

                const inputTensor = imageTensor.expandDims(0); // Add batch dimension
                const prediction = model.predict(inputTensor);
                const predictedLabel = prediction.argMax(-1).dataSync()[0];
                
                // Display image on canvas
                const testImageCanvas = document.getElementById('testImageCanvas');
                const ctx = testImageCanvas.getContext('2d');
                ctx.clearRect(0,0,testImageCanvas.width, testImageCanvas.height); // Clear previous
                // Draw a 2x scaled image
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = IMG_WIDTH;
                tempCanvas.height = IMG_HEIGHT;
                const tempCtx = tempCanvas.getContext('2d');
                tf.browser.toPixels(imageTensor, tempCanvas).then(() => {
                     ctx.drawImage(tempCanvas, 0, 0, testImageCanvas.width, testImageCanvas.height);
                });


                document.getElementById('testResult').textContent = 
                    `Random Test Image #${randomIndex}\nActual: ${actualLabel}, Predicted: ${predictedLabel} ${actualLabel === predictedLabel ? '✅' : '❌'}`;
                
                imageTensor.dispose();
                inputTensor.dispose();
                prediction.dispose();
            });
        });

        // --- Initialization ---
        async function main() {
            log('Setting up TensorFlow.js backend...');
            try {
                await tf.setBackend('webgl');
                log('Using WebGL backend.');
            } catch (e) {
                log('WebGL not available or error during setup, using CPU backend.');
                await tf.setBackend('cpu');
            }
            tf.enableProdMode(); // For performance
            log('TensorFlow.js setup complete. Backend: ' + tf.getBackend());

            initChart();

            log('Loading MNIST data (labels are preloaded)...');
            try {
                // Ensure labels are loaded
                if (trainLabels.length === 0 || testLabels.length === 0) {
                     log('Error: MNIST label data not found. Ensure mnist_train_labels.js and mnist_test_labels.js are loaded.');
                     return;
                }
                log(`Train labels: ${trainLabels.length}, Test labels: ${testLabels.length}`);

                const trainImgUrl = 'https://zsc.github.io/widgets/mnist/mnist_train_stitched.png';
                const testImgUrl = 'https://zsc.github.io/widgets/mnist/mnist_test_stitched.png';

                log('Loading training image...');
                trainImg = await loadStitchedImage(trainImgUrl);
                trainImageData = getImageDataFromStitched(trainImg);
                log('Training image loaded and processed.');

                log('Loading test image...');
                testImg = await loadStitchedImage(testImgUrl);
                testImageData = getImageDataFromStitched(testImg);
                log('Test image loaded and processed. Ready to train.');
                
                startTrainingBtn.disabled = false; // Enable training button only after data is ready

            } catch (error) {
                log('Error loading MNIST image data: ' + error);
                console.error(error);
            }
        }

        main();
    </script>
</body>
</html>
