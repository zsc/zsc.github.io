<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MNIST ViT Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://zsc.github.io/widgets/mnist/mnist_train_labels.js"></script>
    <script src="https://zsc.github.io/widgets/mnist/mnist_test_labels.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        body { font-family: sans-serif; margin: 20px; display: flex; flex-direction: column; align-items: center; }
        .container { display: flex; flex-direction: row; gap: 20px; width: 95%; max-width: 1200px; }
        .controls { flex: 1; padding: 15px; border: 1px solid #ccc; border-radius: 5px; }
        .results { flex: 2; padding: 15px; border: 1px solid #ccc; border-radius: 5px; }
        .controls label, .controls input, .controls button { display: block; margin-bottom: 10px; width: calc(100% - 22px); }
        .controls input[type="number"] { padding: 8px; }
        .controls button { padding: 10px; background-color: #007bff; color: white; border: none; cursor: pointer; border-radius: 4px; }
        .controls button:disabled { background-color: #aaa; }
        .chart-container { position: relative; height: 200px; width: 100%; margin-bottom: 20px; } /* Fixed height for charts */
        #status { margin-top: 15px; font-style: italic; white-space: pre-wrap; max-height: 150px; overflow-y: auto; border: 1px solid #eee; padding: 5px;}
        #visualization { margin-top: 20px; text-align: center; }
        #testImageCanvas { border: 1px solid black; image-rendering: pixelated; width: 112px; height: 112px; }
    </style>
</head>
<body>
    <h1>MNIST Vision Transformer (ViT) Demo</h1>

    <div class="container">
        <div class="controls">
            <h2>Hyperparameters</h2>
            <label for="numLayers">ViT Layers (Transformer Blocks): <span id="numLayersVal">2</span></label>
            <input type="range" id="numLayers" min="1" max="6" value="2" oninput="document.getElementById('numLayersVal').textContent = this.value;">

            <label for="embedDim">Embedding Dimension: <span id="embedDimVal">64</span></label>
            <input type="range" id="embedDim" min="16" max="128" step="16" value="64" oninput="document.getElementById('embedDimVal').textContent = this.value;">
            
            <label for="numHeads">Number of Heads (MHA): <span id="numHeadsVal">4</span></label>
            <input type="range" id="numHeads" min="1" max="8" value="4" oninput="document.getElementById('numHeadsVal').textContent = this.value;">

            <label for="patchSize">Patch Size (e.g., 7 for 7x7): <span id="patchSizeVal">7</span></label>
            <input type="range" id="patchSize" min="4" max="14" step="1" value="7" oninput="document.getElementById('patchSizeVal').textContent = this.value;">
            
            <label for="mlpDim">MLP Dimension (Transformer): <span id="mlpDimVal">128</span></label>
            <input type="range" id="mlpDim" min="32" max="256" step="32" value="128" oninput="document.getElementById('mlpDimVal').textContent = this.value;">

            <label for="learningRate">Learning Rate:</label>
            <input type="number" id="learningRate" value="0.001" step="0.0001">

            <label for="batchSize">Batch Size:</label>
            <input type="number" id="batchSize" value="64" step="16">

            <label for="epochs">Epochs:</label>
            <input type="number" id="epochs" value="5" step="1">
            
            <label for="numTrainSamples">Number of Training Samples (max 60000):</label>
            <input type="number" id="numTrainSamples" value="6000" step="1000">

            <label for="numTestSamples">Number of Test Samples (max 10000):</label>
            <input type="number" id="numTestSamples" value="1000" step="100">

            <button id="trainButton">Start Training</button>
            <button id="exportButton" disabled>Export Model Weights</button>
            <button id="testRandomButton" disabled>Test Random Sample</button>
        </div>

        <div class="results">
            <h2>Training Progress</h2>
            <div class="chart-container">
                <canvas id="trainAccChart"></canvas>
            </div>
            <div class="chart-container">
                <canvas id="testAccChart"></canvas>
            </div>
            <div id="status">Logs will appear here...</div>
            <div id="visualization">
                <h3>Test Sample Visualization</h3>
                <canvas id="testImageCanvas" width="28" height="28"></canvas>
                <p id="predictionText">Prediction: - | True Label: -</p>
            </div>
        </div>
    </div>

    <!-- Hidden canvases for stitched images -->
    <canvas id="stitchedTrainCanvas" style="display:none;"></canvas>
    <canvas id="stitchedTestCanvas" style="display:none;"></canvas>
    <canvas id="tempImageCanvas" width="28" height="28" style="display:none;"></canvas>


    <script>
        // Global variables
        let model;
        let trainAccChartInstance, testAccChartInstance;
        let trainStitchedImage, testStitchedImage;
        let stitchedTrainCtx, stitchedTestCtx, tempImageCtx;
        
        const IMG_SIZE = 28;
        const NUM_CLASSES = 10;

        const TRAIN_IMG_URL = 'https://zsc.github.io/widgets/mnist/mnist_train_stitched.png';
        const TRAIN_IMG_WIDTH = 6860; // 245 images per row
        const TRAIN_IMG_HEIGHT = 6860; // 245 rows
        const TRAIN_IMGS_PER_ROW = 245;

        const TEST_IMG_URL = 'https://zsc.github.io/widgets/mnist/mnist_test_stitched.png';
        const TEST_IMG_WIDTH = 2800; // 100 images per row
        const TEST_IMG_HEIGHT = 2800; // 100 rows
        const TEST_IMGS_PER_ROW = 100;

        // --- UI Elements ---
        const ui = {
            numLayers: document.getElementById('numLayers'),
            embedDim: document.getElementById('embedDim'),
            numHeads: document.getElementById('numHeads'),
            patchSize: document.getElementById('patchSize'),
            mlpDim: document.getElementById('mlpDim'),
            learningRate: document.getElementById('learningRate'),
            batchSize: document.getElementById('batchSize'),
            epochs: document.getElementById('epochs'),
            numTrainSamples: document.getElementById('numTrainSamples'),
            numTestSamples: document.getElementById('numTestSamples'),
            trainButton: document.getElementById('trainButton'),
            exportButton: document.getElementById('exportButton'),
            testRandomButton: document.getElementById('testRandomButton'),
            status: document.getElementById('status'),
            testImageCanvas: document.getElementById('testImageCanvas'),
            predictionText: document.getElementById('predictionText'),
            trainAccChart: document.getElementById('trainAccChart').getContext('2d'),
            testAccChart: document.getElementById('testAccChart').getContext('2d'),
        };

        function log(message) {
            console.log(message);
            ui.status.textContent = message + '\n' + ui.status.textContent;
            if (ui.status.childNodes.length > 100) { // Limit log lines
                ui.status.removeChild(ui.status.lastChild);
            }
        }

        // --- GELU Activation ---
        function gelu(x) {
            return tf.tidy(() => {
                const cdf = tf.mul(0.5, tf.add(1, tf.erf(tf.div(x, Math.sqrt(2)))));
                return tf.mul(x, cdf);
            });
        }
        
        // --- ViT Layers ---
        class MultiHeadAttention extends tf.layers.Layer {
            constructor(config) {
                super(config);
                this.embedDim = config.embedDim;
                this.numHeads = config.numHeads;
                if (this.embedDim % this.numHeads !== 0) {
                    throw new Error('Embedding dimension must be divisible by number of heads.');
                }
                this.headDim = this.embedDim / this.numHeads;

                // Use Dense layers for projections
                this.wq_layer = tf.layers.dense({units: this.embedDim, useBias: false, name: 'wq_mha', kernelInitializer: 'glorotUniform'});
                this.wk_layer = tf.layers.dense({units: this.embedDim, useBias: false, name: 'wk_mha', kernelInitializer: 'glorotUniform'});
                this.wv_layer = tf.layers.dense({units: this.embedDim, useBias: false, name: 'wv_mha', kernelInitializer: 'glorotUniform'});
                this.dense_out = tf.layers.dense({units: this.embedDim, name: 'dense_out_mha', kernelInitializer: 'glorotUniform'});
            }

            splitHeads(x, batchSize) {
                // x shape: (batchSize, seqLen, embedDim)
                x = tf.reshape(x, [batchSize, -1, this.numHeads, this.headDim]);
                return tf.transpose(x, [0, 2, 1, 3]); // (batchSize, numHeads, seqLen, headDim)
            }

            call(inputs) {
                return tf.tidy(() => {
                    const inputTensor = Array.isArray(inputs) ? inputs[0] : inputs;
                    const batchSize = inputTensor.shape[0];
                    const seqLen = inputTensor.shape[1]; 

                    const q = this.wq_layer.apply(inputTensor); 
                    const k = this.wk_layer.apply(inputTensor);
                    const v = this.wv_layer.apply(inputTensor);
                    
                    const q_heads = this.splitHeads(q, batchSize); 
                    const k_heads = this.splitHeads(k, batchSize);
                    const v_heads = this.splitHeads(v, batchSize);

                    const scaledAttentionLogits = tf.matMul(q_heads, k_heads, false, true); 
                    const scaledAttention = tf.div(scaledAttentionLogits, tf.sqrt(tf.scalar(this.headDim, 'float32')));
                    const attentionWeights = tf.softmax(scaledAttention, -1); 
                    
                    const scaledAttentionOutput = tf.matMul(attentionWeights, v_heads); 
                    
                    const concatAttention = tf.transpose(scaledAttentionOutput, [0, 2, 1, 3]); 
                    const reshapedAttention = tf.reshape(concatAttention, [batchSize, seqLen, this.embedDim]); 
                    
                    const output = this.dense_out.apply(reshapedAttention); 
                    return output;
                });
            }
            static get className() { return 'MultiHeadAttention'; }
        }
        tf.serialization.registerClass(MultiHeadAttention);


        class TransformerEncoderLayer extends tf.layers.Layer {
            constructor(config) {
                super(config);
                this.embedDim = config.embedDim;
                this.numHeads = config.numHeads;
                this.mlpDim = config.mlpDim;
                this.dropoutRate = config.dropoutRate || 0.1;

                this.mha = new MultiHeadAttention({embedDim: this.embedDim, numHeads: this.numHeads});
                this.norm1 = tf.layers.layerNormalization({epsilon: 1e-6});
                this.norm2 = tf.layers.layerNormalization({epsilon: 1e-6});
                this.dense1 = tf.layers.dense({units: this.mlpDim, activation: 'linear', kernelInitializer: 'glorotUniform'}); 
                this.dense2 = tf.layers.dense({units: this.embedDim, kernelInitializer: 'glorotUniform'});
                this.dropout1 = tf.layers.dropout({rate: this.dropoutRate});
                this.dropout2 = tf.layers.dropout({rate: this.dropoutRate});

            }

            call(inputs, training) {
                 return tf.tidy(() => {
                    const inputTensor = Array.isArray(inputs) ? inputs[0] : inputs;
                    const attnOutput = this.mha.apply(inputTensor, {training: training}); // Pass training flag
                    const attnOutputDropped = this.dropout1.apply(attnOutput, {training: training});
                    const out1 = this.norm1.apply(tf.add(inputTensor, attnOutputDropped));

                    let mlpOutput = this.dense1.apply(out1);
                    mlpOutput = gelu(mlpOutput); 
                    mlpOutput = this.dense2.apply(mlpOutput);
                    const mlpOutputDropped = this.dropout2.apply(mlpOutput, {training: training});
                    const out2 = this.norm2.apply(tf.add(out1, mlpOutputDropped));
                    return out2;
                });
            }
            static get className() { return 'TransformerEncoderLayer'; }
        }
        tf.serialization.registerClass(TransformerEncoderLayer);

        class ViT extends tf.layers.Layer {
            constructor(config) {
                super(config);
                this.numLayers = config.numLayers;
                this.embedDim = config.embedDim;
                this.numHeads = config.numHeads;
                this.mlpDim = config.mlpDim;
                this.patchSize = config.patchSize;
                this.numPatches = (IMG_SIZE / this.patchSize) * (IMG_SIZE / this.patchSize);
                this.numClasses = config.numClasses;
                this.dropoutRate = config.dropoutRate || 0.1;

                this.patchProjection = tf.layers.dense({units: this.embedDim, kernelInitializer: 'glorotUniform'});
                
                this.clsToken = this.addWeight(
                    'clsToken', 
                    [1, 1, this.embedDim], 
                    'float32', 
                    tf.initializers.randomNormal({stddev: 0.02})
                );
                this.positionalEmbedding = this.addWeight(
                    'positionalEmbedding',
                    [1, this.numPatches + 1, this.embedDim],
                    'float32',
                    tf.initializers.randomNormal({stddev: 0.02})
                );

                this.encoderLayers = [];
                for (let i = 0; i < this.numLayers; i++) {
                    this.encoderLayers.push(new TransformerEncoderLayer({
                        embedDim: this.embedDim, 
                        numHeads: this.numHeads, 
                        mlpDim: this.mlpDim,
                        dropoutRate: this.dropoutRate
                    }));
                }
                
                this.norm = tf.layers.layerNormalization({epsilon: 1e-6});
                this.head = tf.layers.dense({units: this.numClasses, activation: 'softmax', kernelInitializer: 'glorotUniform'});
                this.dropoutEmbed = tf.layers.dropout({rate: this.dropoutRate}); // Added dropout for embeddings
            }

            extractPatches(images) { 
                return tf.tidy(() => {
                    const batchSize = images.shape[0];
                    const inHeight = images.shape[1];
                    const inWidth = images.shape[2];
                    const channels = images.shape[3];
                    
                    const stride = this.patchSize; 

                    const numPatchesH = Math.floor((inHeight - this.patchSize) / stride) + 1;
                    const numPatchesW = Math.floor((inWidth - this.patchSize) / stride) + 1;
                    
                    const batchAllPatches = []; 
                    for (let b = 0; b < batchSize; b++) {
                        const singleImage = tf.slice(images, [b, 0, 0, 0], [1, inHeight, inWidth, channels]);
                        const imagePatchesList = []; 
                        
                        for (let r = 0; r < numPatchesH; r++) { 
                            for (let c = 0; c < numPatchesW; c++) { 
                                const y_start = r * stride;
                                const x_start = c * stride;
                                
                                const patch = tf.slice(singleImage,
                                    [0, y_start, x_start, 0], 
                                    [1, this.patchSize, this.patchSize, channels]); 
                                
                                const flattenedPatch = tf.reshape(patch, [this.patchSize * this.patchSize * channels]);
                                imagePatchesList.push(flattenedPatch);
                            }
                        }
                        const stackedPatchesForImage = tf.stack(imagePatchesList); 
                        batchAllPatches.push(stackedPatchesForImage);
                    }
                    const finalPatches = tf.stack(batchAllPatches);
                    return finalPatches;
                });
            }

            call(inputs, training) {
                return tf.tidy(() => {
                    const images = Array.isArray(inputs) ? inputs[0] : inputs; 
                    const batchSize = images.shape[0];

                    let x = this.extractPatches(images); 
                    x = this.patchProjection.apply(x); 

                    const clsTokenValue = this.clsToken.read();
                    const broadcastedClsToken = tf.tile(clsTokenValue, [batchSize, 1, 1]);
                    
                    x = tf.concat([broadcastedClsToken, x], 1); 
                    x = tf.add(x, this.positionalEmbedding.read());
                    x = this.dropoutEmbed.apply(x, {training: training}); // Apply dropout after pos embedding

                    for (let i = 0; i < this.numLayers; i++) {
                        x = this.encoderLayers[i].apply(x, {training: training});
                    }

                    x = this.norm.apply(x);
                    const clsOutput = tf.slice(x, [0, 0, 0], [batchSize, 1, this.embedDim]); 
                    const reshapedClsOutput = tf.reshape(clsOutput, [batchSize, this.embedDim]);
                    
                    return this.head.apply(reshapedClsOutput);
                });
            }

            static get className() { return 'ViT'; }
        }
        tf.serialization.registerClass(ViT);


        // --- Data Handling ---
        async function loadImageToCanvas(imageUrl, canvasElement) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = "anonymous";
                img.onload = () => {
                    canvasElement.width = img.width;
                    canvasElement.height = img.height;
                    const ctx = canvasElement.getContext('2d');
                    ctx.drawImage(img, 0, 0);
                    log(`${imageUrl} loaded into canvas.`);
                    resolve(ctx);
                };
                img.onerror = (err) => {
                    log(`Error loading ${imageUrl}: ${err}`);
                    reject(err);
                };
                img.src = imageUrl;
            });
        }

        function getImageAndLabel(index, isTrain) {
            return tf.tidy(() => {
                const sourceCtx = isTrain ? stitchedTrainCtx : stitchedTestCtx;
                const labels = isTrain ? mnistTrainLabels : mnistTestLabels;
                const imgsPerRow = isTrain ? TRAIN_IMGS_PER_ROW : TEST_IMGS_PER_ROW;

                const row = Math.floor(index / imgsPerRow);
                const col = index % imgsPerRow;
                const sx = col * IMG_SIZE;
                const sy = row * IMG_SIZE;

                tempImageCtx.clearRect(0, 0, IMG_SIZE, IMG_SIZE);
                tempImageCtx.drawImage(sourceCtx.canvas, sx, sy, IMG_SIZE, IMG_SIZE, 0, 0, IMG_SIZE, IMG_SIZE);
                
                const imageData = tempImageCtx.getImageData(0, 0, IMG_SIZE, IMG_SIZE);
                
                let imgTensor = tf.browser.fromPixels(imageData, 1); 
                imgTensor = imgTensor.toFloat().div(tf.scalar(255.0));

                const label = labels[index];
                const labelTensor = tf.oneHot(tf.tensor1d([label], 'int32'), NUM_CLASSES).toFloat();
                
                return { image: imgTensor, label: labelTensor.squeeze() }; 
            });
        }
        
        function* dataGenerator(numSamples, batchSize, isTrain) {
            const totalAvailable = isTrain ? mnistTrainLabels.length : mnistTestLabels.length;
            const effectiveNumSamples = Math.min(numSamples, totalAvailable);

            const numBatches = Math.floor(effectiveNumSamples / batchSize);
            const allIndices = tf.util.createShuffledIndices(totalAvailable);
            const indicesToUse = allIndices.slice(0, effectiveNumSamples);


            for (let i = 0; i < numBatches; i++) {
                const batchIndices = indicesToUse.slice(i * batchSize, (i + 1) * batchSize);
                if (batchIndices.length === 0) continue;

                const imageBatch = [];
                const labelBatch = [];
                for (const index of batchIndices) {
                    const {image, label} = getImageAndLabel(index, isTrain);
                    imageBatch.push(image);
                    labelBatch.push(label);
                }
                
                const stackedImages = tf.stack(imageBatch); 
                const stackedLabels = tf.stack(labelBatch); 
                
                yield { xs: stackedImages, ys: stackedLabels };

                imageBatch.forEach(t => t.dispose());
                labelBatch.forEach(t => t.dispose());
            }
        }


        // --- Charting ---
        function initCharts() {
            const commonOptions = {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    x: { title: { display: true, text: 'Epoch' } },
                    y: { 
                        title: { display: true, text: 'Accuracy' },
                        beginAtZero: true, 
                        suggestedMax: 1.0,
                        ticks: { callback: value => (value * 100).toFixed(0) + '%' }
                    }
                }
            };
            if (trainAccChartInstance) trainAccChartInstance.destroy();
            trainAccChartInstance = new Chart(ui.trainAccChart, {
                type: 'line',
                data: { labels: [], datasets: [{ label: 'Train Accuracy', data: [], borderColor: 'blue', fill: false }] },
                options: commonOptions
            });
            if (testAccChartInstance) testAccChartInstance.destroy();
            testAccChartInstance = new Chart(ui.testAccChart, {
                type: 'line',
                data: { labels: [], datasets: [{ label: 'Test Accuracy', data: [], borderColor: 'green', fill: false }] },
                options: commonOptions
            });
        }

        function updateChart(chartInstance, epoch, value) {
            chartInstance.data.labels.push(epoch);
            chartInstance.data.datasets.forEach((dataset) => {
                dataset.data.push(value);
            });
            chartInstance.update();
        }

        // --- Training Logic ---
        async function trainModel() {
            ui.trainButton.disabled = true;
            ui.exportButton.disabled = true;
            ui.testRandomButton.disabled = true;
            log("Starting training...");
            initCharts();

            const hyperparams = {
                numLayers: parseInt(ui.numLayers.value),
                embedDim: parseInt(ui.embedDim.value),
                numHeads: parseInt(ui.numHeads.value),
                patchSizeVal: parseInt(ui.patchSize.value),
                mlpDim: parseInt(ui.mlpDim.value),
                learningRateVal: parseFloat(ui.learningRate.value),
                batchSizeVal: parseInt(ui.batchSize.value),
                epochsVal: parseInt(ui.epochs.value),
                numTrainSamplesVal: Math.min(parseInt(ui.numTrainSamples.value), mnistTrainLabels.length),
                numTestSamplesVal: Math.min(parseInt(ui.numTestSamples.value), mnistTestLabels.length),
            };
            
            log(`Hyperparameters: ${JSON.stringify(hyperparams, null, 2)}`);

            if (hyperparams.embedDim % hyperparams.numHeads !== 0) {
                log("Error: Embedding Dimension must be divisible by Number of Heads.");
                ui.trainButton.disabled = false;
                return;
            }
            if (IMG_SIZE % hyperparams.patchSizeVal !== 0) {
                log("Error: Image size (28) must be divisible by Patch Size.");
                ui.trainButton.disabled = false;
                return;
            }

            // Dispose previous model if exists
            if (model && model.dispose) {
                try {
                    // model.dispose(); // Custom layers might not have a dispose method if not tf.LayersModel
                    // Instead, we'll just reassign and let JS garbage collect the old one.
                    // TF.js tensors within the old model should be managed by tf.tidy or disposed manually
                    // if they were created outside of layers.
                    log("Disposing old model structure (if any). Weights are managed by layers.");
                } catch (e) {
                    log("Error disposing previous model: " + e);
                }
            }
            tf.disposeVariables(); // Dispose all registered tf.variable()s. Good for retraining.


            model = new ViT({
                numLayers: hyperparams.numLayers,
                embedDim: hyperparams.embedDim,
                numHeads: hyperparams.numHeads,
                mlpDim: hyperparams.mlpDim,
                patchSize: hyperparams.patchSizeVal,
                numClasses: NUM_CLASSES,
                dropoutRate: 0.1 
            });
            
            const dummyInputShape = [1, IMG_SIZE, IMG_SIZE, 1]; 
            const dummyInput = tf.zeros(dummyInputShape);
            tf.tidy(() => model.apply(dummyInput, {training: false})); 
            dummyInput.dispose();
            log("Model constructed.");


            const optimizer = tf.train.adam(hyperparams.learningRateVal);

            for (let epoch = 1; epoch <= hyperparams.epochsVal; epoch++) {
                log(`Epoch ${epoch}/${hyperparams.epochsVal}`);
                let epochTrainLoss = 0;
                let epochTrainAcc = 0;
                let batchCount = 0;

                const trainData = dataGenerator(hyperparams.numTrainSamplesVal, hyperparams.batchSizeVal, true);
                
                for (const batch of trainData) {
                    if (!batch || !batch.xs || !batch.ys) {
                        log("Skipping empty batch from generator.");
                        continue;
                    }
                    const {xs, ys} = batch;
                    
                    const {loss, grads} = optimizer.computeGradients(() => {
                        const predictions = model.apply(xs, {training: true});
                        const currentLoss = tf.losses.softmaxCrossEntropy(ys, predictions).mean();
                        return currentLoss;
                    });
                    
                    optimizer.applyGradients(grads); // Grads is an object mapping var names to Tensors
                    
                    // Manually dispose individual gradient tensors if grads is an object
                    if (typeof grads === 'object' && grads !== null) {
                        for (const varName in grads) {
                            if (grads[varName] instanceof tf.Tensor) {
                                grads[varName].dispose();
                            }
                        }
                    } else if (Array.isArray(grads)) { // if grads is an array of {name, tensor}
                        grads.forEach(gradPair => gradPair.tensor.dispose());
                    }


                    const predictionsForAcc = tf.tidy(() => model.apply(xs, {training: false}));
                    const accTensor = tf.metrics.categoricalAccuracy(ys, predictionsForAcc);
                    const acc = accTensor.mean().arraySync();
                    
                    epochTrainLoss += loss.arraySync(); // loss is scalar, arraySync() is fine
                    epochTrainAcc += acc;
                    batchCount++;

                    loss.dispose();
                    // Grads are already disposed above
                    xs.dispose();
                    ys.dispose();
                    predictionsForAcc.dispose();
                    accTensor.dispose();


                    if (batchCount % 10 === 0) {
                        log(` Epoch ${epoch}, Batch ${batchCount}: Train Loss: ${(epochTrainLoss / batchCount).toFixed(4)}, Train Acc: ${(epochTrainAcc / batchCount).toFixed(4)}`);
                    }
                    await tf.nextFrame(); 
                }
                
                if (batchCount > 0) {
                    const avgTrainAcc = epochTrainAcc / batchCount;
                    const avgTrainLoss = epochTrainLoss / batchCount;
                    updateChart(trainAccChartInstance, epoch, avgTrainAcc);
                    log(`Epoch ${epoch} - Train Loss: ${avgTrainLoss.toFixed(4)}, Train Accuracy: ${avgTrainAcc.toFixed(4)}`);
                } else {
                    log(`Epoch ${epoch} - No training data processed.`);
                }


                // Evaluation
                let epochTestAcc = 0;
                let testBatchCount = 0;
                const testData = dataGenerator(hyperparams.numTestSamplesVal, hyperparams.batchSizeVal, false);
                for (const batch of testData) {
                     if (!batch || !batch.xs || !batch.ys) {
                        log("Skipping empty test batch from generator.");
                        continue;
                    }
                    const {xs, ys} = batch;
                    const predictions = tf.tidy(() => model.apply(xs, {training: false}));
                    const accTensor = tf.metrics.categoricalAccuracy(ys, predictions);
                    const acc = accTensor.mean().arraySync();
                    epochTestAcc += acc;
                    testBatchCount++;

                    xs.dispose();
                    ys.dispose();
                    predictions.dispose();
                    accTensor.dispose();
                    await tf.nextFrame(); 
                }
                if (testBatchCount > 0) {
                    const avgTestAcc = epochTestAcc / testBatchCount;
                    updateChart(testAccChartInstance, epoch, avgTestAcc);
                    log(`Epoch ${epoch} - Test Accuracy: ${avgTestAcc.toFixed(4)}`);
                } else {
                     log(`Epoch ${epoch} - No test data processed.`);
                }
            }

            log("Training finished.");
            ui.trainButton.disabled = false;
            ui.exportButton.disabled = false;
            ui.testRandomButton.disabled = false;
        }

        // --- Model Export ---
        function exportModelWeights() {
            if (!model) {
                log("Model not trained yet.");
                return;
            }
            log("Exporting model weights...");
            const weights = model.getWeights().map(w => w.arraySync()); // tf.Layer.getWeights() is fine
            
            // Reconstruct config for ViT based on its properties for export
            const modelInstanceConfig = {
                numLayers: model.numLayers,
                embedDim: model.embedDim,
                numHeads: model.numHeads,
                mlpDim: model.mlpDim,
                patchSize: model.patchSize,
                numClasses: model.numClasses,
                dropoutRate: model.dropoutRate
            };

            const serialized = {
                // For custom layers, we usually save config like this.
                // className is used by tf.serialization.deserializeKerasObject
                modelConfig: { className: model.getClassName(), config: modelInstanceConfig },
                weights: weights // This is an array of weight tensors (as JS arrays)
            };

            const jsonString = JSON.stringify(serialized);
            const blob = new Blob([jsonString], {type: "application/json"});
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = 'vit_mnist_model.json';
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
            log("Model weights exported.");
        }

        // --- Test Random Sample ---
        function testRandomSample() {
            if (!model) {
                log("Model not trained yet.");
                return;
            }
            const numTotalTestSamples = mnistTestLabels.length;
            if (numTotalTestSamples === 0) {
                log("No test labels loaded.");
                return;
            }
            const randomIndex = Math.floor(Math.random() * numTotalTestSamples);
            
            log(`Testing on random sample index: ${randomIndex} from the full test set.`);

            tf.tidy(() => {
                const {image, label} = getImageAndLabel(randomIndex, false); 
                const imageBatched = image.expandDims(0); 

                const displayCanvasCtx = ui.testImageCanvas.getContext('2d');
                tf.browser.toPixels(image.mul(255).cast('int32'), ui.testImageCanvas) 
                    .then(() => {
                        const prediction = model.apply(imageBatched, {training: false}); 
                        const predictedClass = prediction.argMax(-1).dataSync()[0];
                        const trueClass = label.argMax(-1).dataSync()[0];
                        
                        ui.predictionText.textContent = `Prediction: ${predictedClass} | True Label: ${trueClass}`;
                        log(`Random Test - Predicted: ${predictedClass}, True: ${trueClass}`);
                    });
            });
        }


        // --- Initialization ---
        window.onload = async () => {
            log("Initializing demo...");
            ui.trainButton.addEventListener('click', trainModel);
            ui.exportButton.addEventListener('click', exportModelWeights);
            ui.testRandomButton.addEventListener('click', testRandomSample);

            stitchedTrainCtx = document.getElementById('stitchedTrainCanvas').getContext('2d');
            stitchedTestCtx = document.getElementById('stitchedTestCanvas').getContext('2d');
            tempImageCtx = document.getElementById('tempImageCanvas').getContext('2d');
            
            document.getElementById('numLayersVal').textContent = ui.numLayers.value;
            document.getElementById('embedDimVal').textContent = ui.embedDim.value;
            document.getElementById('numHeadsVal').textContent = ui.numHeads.value;
            document.getElementById('patchSizeVal').textContent = ui.patchSize.value;
            document.getElementById('mlpDimVal').textContent = ui.mlpDim.value;


            initCharts();
            log("Loading MNIST stitched images (may take a moment)...");
            try {
                await Promise.all([
                    loadImageToCanvas(TRAIN_IMG_URL, document.getElementById('stitchedTrainCanvas')),
                    loadImageToCanvas(TEST_IMG_URL, document.getElementById('stitchedTestCanvas'))
                ]);
                log("MNIST images loaded and ready.");
                ui.trainButton.disabled = false; 
            } catch (error) {
                log("Error loading MNIST images. Demo might not work correctly.");
                console.error("Image loading error:", error);
            }
            log("Demo ready.");
        };

    </script>
</body>
</html>
