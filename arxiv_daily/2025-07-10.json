[
  {
    "id": "arXiv:2507.07017",
    "title": "First Return, Entropy-Eliciting Explore",
    "authors": "Tianyu Zheng, Tianshun Xing, Qingshui Gu, Taoran Liang, Xingwei Qu, Xin Zhou, Yizhi Li, Zhoufutu Wen, Chenghua Lin, Wenhao Huang, Qian Liu, Ge Zhang, Zejun Ma",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07017",
    "pdf_link": "https://arxiv.org/pdf/2507.07017",
    "score": 4,
    "abstract": "Reinforcement Learning from Verifiable Rewards (RLVR) improves the reasoning abilities of Large Language Models (LLMs) but it struggles with unstable exploration. We propose FR3E (First Return, Entropy-Eliciting Explore), a structured exploration framework that identifies high-uncertainty decision points in reasoning trajectories and performs targeted rollouts to construct semantically grounded intermediate feedback. Our method provides targeted guidance without relying on dense supervision. Empirical results on mathematical reasoning benchmarks(AIME24) show that FR3E promotes more stable training, produces longer and more coherent responses, and increases the proportion of fully correct trajectories. These results highlight the framework's effectiveness in improving LLM reasoning through more robust and structured exploration.",
    "chinese_title": "首次回报，熵诱导探索",
    "chinese_abstract": "基于可验证奖励的强化学习 (RLVR) 提高了大型语言模型 (LLM) 的推理能力，但它在不稳定的探索方面存在困难。我们提出 FR3E（首次回报，熵诱导探索），这是一种结构化的探索框架，可以识别推理轨迹中的高不确定性决策点，并执行有针对性的 rollout 以构建语义上扎实的中间反馈。我们的方法在不依赖密集监督的情况下提供有针对性的指导。在数学推理基准测试 (AIME24) 上的经验结果表明，FR3E 促进了更稳定的训练，产生了更长、更连贯的响应，并增加了完全正确的轨迹的比例。这些结果突出了该框架通过更强大、更结构化的探索来提高 LLM 推理的有效性。"
  },
  {
    "id": "arXiv:2507.06993",
    "title": "The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation",
    "authors": "Jieren Deng, Aleksandar Cvetkovic, Pak Kiu Chung, Dragomir Yankov, Chiqun Zhang",
    "subjects": "Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.06993",
    "pdf_link": "https://arxiv.org/pdf/2507.06993",
    "score": 4,
    "abstract": "Traditional travel-planning systems are often static and fragmented, leaving them ill-equipped to handle real-world complexities such as evolving environmental conditions and unexpected itinerary disruptions. In this paper, we identify three gaps between existing service providers causing frustrating user experience: intelligent trip planning, precision \"last-100-meter\" navigation, and dynamic itinerary adaptation. We propose three cooperative agents: a Travel Planning Agent that employs grid-based spatial grounding and map analysis to help resolve complex multi-modal user queries; a Destination Assistant Agent that provides fine-grained guidance for the final navigation leg of each journey; and a Local Discovery Agent that leverages image embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to trip plan disruptions. With evaluations and experiments, our system demonstrates substantial improvements in query interpretation, navigation accuracy, and disruption resilience, underscoring its promise for applications from urban exploration to emergency response.",
    "chinese_title": "以用户为中心的地理体验：基于LLM的增强规划、导航和动态适应框架",
    "chinese_abstract": "传统的旅行规划系统通常是静态和分散的，难以应对现实世界的复杂情况，例如不断变化的环境条件和意外的行程中断。在本文中，我们指出了现有服务提供商之间存在的三个差距，导致令人沮丧的用户体验：智能行程规划、精确的“最后100米”导航以及动态行程适应。我们提出了三个协同代理：一个旅行规划代理，它采用基于网格的空间定位和地图分析来帮助解决复杂的跨模态用户查询；一个目的地助手代理，为每个行程的最后导航阶段提供细粒度的指导；以及一个本地发现代理，它利用图像嵌入和检索增强生成（RAG）来检测和响应行程计划中断。通过评估和实验，我们的系统在查询解释、导航精度和中断恢复能力方面表现出显著的改进，突显了它在城市探索到应急响应等领域的应用前景。"
  },
  {
    "id": "arXiv:2507.06968",
    "title": "Scaling Towards the Information Boundary of Instruction Set: InfinityInstruct-Subject Technical Report",
    "authors": "Li Du, Hanyu Zhao, Yiming Ju, Tengfei Pan",
    "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06968",
    "pdf_link": "https://arxiv.org/pdf/2507.06968",
    "score": 4,
    "abstract": "Instruction tuning has become a foundation for unlocking the capabilities of large-scale pretrained models and improving their performance on complex tasks. Thus, the construction of high-quality instruction datasets is crucial for enhancing model performance and generalizability. Although current instruction datasets have reached tens of millions of samples, models finetuned on them may still struggle with complex instruction following and tasks in rare domains. This is primarily due to limited expansion in both ``coverage'' (coverage of task types and knowledge areas) and ``depth'' (instruction complexity) of the instruction set. To address this issue, we propose a systematic instruction data construction framework, which integrates a hierarchical labeling system, an informative seed selection algorithm, an evolutionary data synthesis process, and a model deficiency diagnosis with targeted data generation. These components form an iterative closed-loop to continuously enhance the coverage and depth of instruction data. Based on this framework, we construct InfinityInstruct-Subject, a high-quality dataset containing ~1.5 million instructions. Experiments on multiple foundation models and benchmark tasks demonstrate its effectiveness in improving instruction-following capabilities. Further analyses suggest that InfinityInstruct-Subject shows enlarged coverage and depth compared to comparable synthesized instruction datasets. Our work lays a theoretical and practical foundation for the efficient, continuous evolution of instruction datasets, moving from data quantity expansion to qualitative improvement.",
    "chinese_title": "无限指令集：迈向指令集信息边界的技术报告",
    "chinese_abstract": "指令微调已成为解锁大规模预训练模型能力并提高其在复杂任务上性能的基础。因此，构建高质量的指令数据集对于提升模型性能和泛化能力至关重要。尽管当前指令数据集已达到数千万样本，但基于这些数据集微调的模型在处理复杂指令和罕见领域任务时仍可能遇到困难。这主要是由于指令集的“覆盖范围”（任务类型和知识领域的覆盖）和“深度”（指令复杂性）的扩展有限。为了解决这个问题，我们提出了一种系统化的指令数据构建框架，该框架集成了分层标注系统、信息种子选择算法、进化数据合成过程以及模型缺陷诊断与针对性数据生成。这些组件形成了一个迭代闭环，以持续增强指令数据的覆盖范围和深度。基于此框架，我们构建了InfinityInstruct-Subject，一个高质量的数据集，包含约150万条指令。在多个基础模型和基准任务上的实验证明了其在提高指令遵循能力方面的有效性。进一步的分析表明，与可比较的合成指令数据集相比，InfinityInstruct-Subject显示出更大的覆盖范围和深度。我们的工作为指令数据集的有效、持续演化奠定了理论和实践基础，从数据量扩展转向质量提升。"
  },
  {
    "id": "arXiv:2507.06398",
    "title": "Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI",
    "authors": "David Orban",
    "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)",
    "abs_link": "https://arxiv.org/abs/2507.06398",
    "pdf_link": "https://arxiv.org/pdf/2507.06398",
    "score": 4,
    "abstract": "This paper investigates the Jolting Technologies Hypothesis, which posits superexponential growth (increasing acceleration, or a positive third derivative) in the development of AI capabilities. We develop a theoretical framework and validate detection methodologies through Monte Carlo simulations, while acknowledging that empirical validation awaits suitable longitudinal data. Our analysis focuses on creating robust tools for future empirical studies and exploring the potential implications should the hypothesis prove valid. The study examines how factors such as shrinking idea-to-action intervals and compounding iterative AI improvements drive this jolting pattern. By formalizing jolt dynamics and validating detection methods through simulation, this work provides the mathematical foundation necessary for understanding potential AI trajectories and their consequences for AGI emergence, offering insights for research and policy.",
    "chinese_title": "颠覆性技术：人工智能能力超指数加速及其对AGI的影响",
    "chinese_abstract": "本文研究了“颠覆性技术假说”，该假说认为人工智能能力的发展呈现超指数增长（加速增加，或正的三阶导数）。我们开发了一个理论框架，并通过蒙特卡洛模拟验证了检测方法，同时承认经验验证需要合适的纵向数据。我们的分析侧重于创建用于未来实证研究的强大工具，并探讨如果该假说被证明有效，其潜在影响。该研究考察了诸如想法到行动的时间间隔缩短以及迭代人工智能改进的复利效应如何驱动这种颠覆性模式。通过形式化颠覆性动力学并验证模拟中的检测方法，这项工作为理解潜在的人工智能轨迹及其对AGI出现的影响提供了数学基础，为研究和政策提供了见解。"
  },
  {
    "id": "arXiv:2507.06396",
    "title": "Representing Prompting Patterns with PDL: Compliance Agent Case Study",
    "authors": "Mandana Vaziri, Louis Mandel, Yuji Watanabe, Hirokuni Kitahara, Martin Hirzel, Anca Sailer",
    "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Programming Languages (cs.PL); Software Engineering (cs.SE)",
    "abs_link": "https://arxiv.org/abs/2507.06396",
    "pdf_link": "https://arxiv.org/pdf/2507.06396",
    "score": 4,
    "abstract": "Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.",
    "chinese_title": "使用PDL表示提示模式：合规代理案例研究",
    "chinese_abstract": "针对LLM的提示工程仍然很复杂，现有的框架要么隐藏复杂性在限制性API之后，要么提供无法自定义的固定模式，使得复杂的代理编程具有挑战性。我们提出了提示声明语言 (PDL)，这是一种新的提示表示方法，通过将提示置于前台来解决这种根本性复杂性，从而实现手动和自动提示调整，同时捕获LLM调用的组成以及基于规则的代码和外部工具。通过抽象化这种组合的管道，PDL旨在提高程序员的生产力，同时提供一种适合优化的声明式表示。本文通过合规代理的真实案例研究展示了PDL的效用。调整此代理的提示模式，与使用现成的代理和提示模式相比，性能提高了高达4倍。"
  },
  {
    "id": "arXiv:2507.07073",
    "title": "An AI Approach for Learning the Spectrum of the Laplace-Beltrami Operator",
    "authors": "Yulin An, Enrique del Castillo",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07073",
    "pdf_link": "https://arxiv.org/pdf/2507.07073",
    "score": 3,
    "abstract": "The spectrum of the Laplace-Beltrami (LB) operator is central in geometric deep learning tasks, capturing intrinsic properties of the shape of the object under consideration. The best established method for its estimation, from a triangulated mesh of the object, is based on the Finite Element Method (FEM), and computes the top k LB eigenvalues with a complexity of O(Nk), where N is the number of points. This can render the FEM method inefficient when repeatedly applied to databases of CAD mechanical parts, or in quality control applications where part metrology is acquired as large meshes and decisions about the quality of each part are needed quickly and frequently. As a solution to this problem, we present a geometric deep learning framework to predict the LB spectrum efficiently given the CAD mesh of a part, achieving significant computational savings without sacrificing accuracy, demonstrating that the LB spectrum is learnable. The proposed Graph Neural Network architecture uses a rich set of part mesh features - including Gaussian curvature, mean curvature, and principal curvatures. In addition to our trained network, we make available, for repeatability, a large curated dataset of real-world mechanical CAD models derived from the publicly available ABC dataset used for training and testing. Experimental results show that our method reduces computation time of the LB spectrum by approximately 5 times over linear FEM while delivering competitive accuracy.",
    "chinese_title": "一种学习拉普拉斯-贝尔特拉米算子谱的AI方法",
    "chinese_abstract": "拉普拉斯-贝尔特拉米 (LB) 算子的谱在几何深度学习任务中至关重要，它捕捉了所考虑对象形状的内在属性。从对象的三角网格估计该谱的最佳方法是基于有限元方法 (FEM)，并以 O(Nk) 的复杂度计算前 k 个 LB 特征值，其中 N 是点的数量。这可能导致 FEM 方法在重复应用于 CAD 机械零件数据库时效率低下，或在质量控制应用中，零件测量以大型网格形式获取，并且需要快速频繁地对每个零件的质量做出决策。作为解决此问题的一种方案，我们提出了一种几何深度学习框架，可以有效地预测给定零件 CAD 网格的 LB 谱，从而在不牺牲准确性的前提下实现显著的计算节省，证明 LB 谱是可学习的。所提出的图神经网络架构使用丰富的零件网格特征 - 包括高斯曲率、平均曲率和主曲率。为了可重复性，我们还提供了一个大型策划的真实世界机械 CAD 模型数据集，该数据集源自用于训练和测试的公开可用的 ABC 数据集。实验结果表明，与线性 FEM 相比，我们的方法可以将 LB 谱的计算时间减少约 5 倍，同时提供具有竞争力的准确性。"
  },
  {
    "id": "arXiv:2507.07066",
    "title": "Latent Acoustic Mapping for Direction of Arrival Estimation: A Self-Supervised Approach",
    "authors": "Adrian S. Roman, Iran R. Roman, Juan P. Bello",
    "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.07066",
    "pdf_link": "https://arxiv.org/pdf/2507.07066",
    "score": 3,
    "abstract": "Acoustic mapping techniques have long been used in spatial audio processing for direction of arrival estimation (DoAE). Traditional beamforming methods for acoustic mapping, while interpretable, often rely on iterative solvers that can be computationally intensive and sensitive to acoustic variability. On the other hand, recent supervised deep learning approaches offer feedforward speed and robustness but require large labeled datasets and lack interpretability. Despite their strengths, both methods struggle to consistently generalize across diverse acoustic setups and array configurations, limiting their broader applicability. We introduce the Latent Acoustic Mapping (LAM) model, a self-supervised framework that bridges the interpretability of traditional methods with the adaptability and efficiency of deep learning methods. LAM generates high-resolution acoustic maps, adapts to varying acoustic conditions, and operates efficiently across different microphone arrays. We assess its robustness on DoAE using the LOCATA and STARSS benchmarks. LAM achieves comparable or superior localization performance to existing supervised methods. Additionally, we show that LAM's acoustic maps can serve as effective features for supervised models, further enhancing DoAE accuracy and underscoring its potential to advance adaptive, high-performance sound localization systems.",
    "chinese_title": "用于到达方向估计的潜在声学映射：一种自监督方法",
    "chinese_abstract": "声学映射技术长期以来一直用于空间音频处理中的到达方向估计（DoAE）。传统的波束形成方法虽然可解释性强，但通常依赖于计算密集且对声学可变性敏感的迭代求解器。另一方面，最近的监督深度学习方法提供了前馈速度和鲁棒性，但需要大量的标记数据集并且缺乏可解释性。尽管各有优势，这两种方法都难以在不同的声学设置和阵列配置中始终如一地泛化，从而限制了它们的更广泛适用性。我们引入了潜在声学映射（LAM）模型，这是一个自监督框架，它弥合了传统方法的可解释性和深度学习方法的适应性和效率之间的差距。LAM生成高分辨率声学图，适应不同的声学条件，并在不同的麦克风阵列上高效运行。我们使用LOCATA和STARSS基准测试评估其在DoAE中的鲁棒性。LAM实现了与现有监督方法相当或更高的定位性能。此外，我们表明LAM的声学图可以作为监督模型的有效特征，进一步提高DoAE的准确性，并强调了其推进自适应、高性能声定位系统的潜力。"
  },
  {
    "id": "arXiv:2507.07060",
    "title": "DeepRetro: Retrosynthetic Pathway Discovery using Iterative LLM Reasoning",
    "authors": "Shreyas Vinaya Sathyanarayana, Rahil Shah, Sharanabasava D. Hiremath, Rishikesh Panda, Rahul Jana, Riya Singh, Rida Irfan, Ashwin Murali, Bharath Ramsundar",
    "subjects": "Quantitative Methods (q-bio.QM); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Biomolecules (q-bio.BM); Molecular Networks (q-bio.MN)",
    "abs_link": "https://arxiv.org/abs/2507.07060",
    "pdf_link": "https://arxiv.org/pdf/2507.07060",
    "score": 4,
    "abstract": "Retrosynthesis, the identification of precursor molecules for a target compound, is pivotal for synthesizing complex molecules, but faces challenges in discovering novel pathways beyond predefined templates. Recent large language model (LLM) approaches to retrosynthesis have shown promise but effectively harnessing LLM reasoning capabilities for effective multi-step planning remains an open question. To address this challenge, we introduce DeepRetro, an open-source, iterative, hybrid LLM-based retrosynthetic framework. Our approach integrates the strengths of conventional template-based/Monte Carlo tree search tools with the generative power of LLMs in a step-wise, feedback-driven loop. Initially, synthesis planning is attempted with a template-based engine. If this fails, the LLM subsequently proposes single-step retrosynthetic disconnections. Crucially, these suggestions undergo rigorous validity, stability, and hallucination checks before the resulting precursors are recursively fed back into the pipeline for further evaluation. This iterative refinement allows for dynamic pathway exploration and correction. We demonstrate the potential of this pipeline through benchmark evaluations and case studies, showcasing its ability to identify viable and potentially novel retrosynthetic routes. In particular, we develop an interactive graphical user interface that allows expert human chemists to provide human-in-the-loop feedback to the reasoning algorithm. This approach successfully generates novel pathways for complex natural product compounds, demonstrating the potential for iterative LLM reasoning to advance state-of-art in complex chemical syntheses.",
    "chinese_title": "DeepRetro：基于迭代LLM推理的反合成路径发现",
    "chinese_abstract": "反合成，即为目标化合物识别前体分子，对于合成复杂分子至关重要，但面临着发现超越预定义模板的新路径的挑战。最近基于大型语言模型（LLM）的反合成方法显示出前景，但有效地利用LLM推理能力进行有效的多步规划仍然是一个悬而未决的问题。为了应对这一挑战，我们引入DeepRetro，一个开源的、迭代的、混合LLM驱动的反合成框架。我们的方法将传统基于模板/蒙特卡洛树搜索工具的优势与LLM的生成能力相结合，形成一个循序渐进、反馈驱动的循环。最初，使用基于模板的引擎尝试合成规划。如果失败，LLM随后会提出单步反合成断裂。至关重要的是，这些建议在严格的有效性、稳定性和幻觉检查之后，才能将结果的前体递归地反馈到管道中以进行进一步评估。这种迭代细化允许动态路径探索和校正。我们通过基准评估和案例研究展示了该管道的潜力，展示了其识别可行且潜在的新反合成路线的能力。特别是，我们开发了一个交互式图形用户界面，允许专家化学家向推理算法提供人工参与的反馈。这种方法成功地为复杂的天然产物化合物生成了新的路径，证明了迭代LLM推理在复杂化学合成领域取得突破的潜力。"
  },
  {
    "id": "arXiv:2507.07046",
    "title": "A Novel Hybrid Deep Learning Technique for Speech Emotion Detection using Feature Engineering",
    "authors": "Shahana Yasmin Chowdhury, Bithi Banik, Md Tamjidul Hoque, Shreya Banerjee",
    "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.07046",
    "pdf_link": "https://arxiv.org/pdf/2507.07046",
    "score": 3,
    "abstract": "Nowadays, speech emotion recognition (SER) plays a vital role in the field of human-computer interaction (HCI) and the evolution of artificial intelligence (AI). Our proposed DCRF-BiLSTM model is used to recognize seven emotions: neutral, happy, sad, angry, fear, disgust, and surprise, which are trained on five datasets: RAVDESS (R), TESS (T), SAVEE (S), EmoDB (E), and Crema-D (C). The model achieves high accuracy on individual datasets, including 97.83% on RAVDESS, 97.02% on SAVEE, 95.10% for CREMA-D, and a perfect 100% on both TESS and EMO-DB. For the combined (R+T+S) datasets, it achieves 98.82% accuracy, outperforming previously reported results. To our knowledge, no existing study has evaluated a single SER model across all five benchmark datasets (i.e., R+T+S+C+E) simultaneously. In our work, we introduce this comprehensive combination and achieve a remarkable overall accuracy of 93.76%. These results confirm the robustness and generalizability of our DCRF-BiLSTM framework across diverse datasets.",
    "chinese_title": "一种用于语音情感检测的新型混合深度学习技术，结合特征工程",
    "chinese_abstract": "如今，语音情感识别 (SER) 在人机交互 (HCI) 和人工智能 (AI) 发展领域发挥着至关重要的作用。我们提出的 DCRF-BiLSTM 模型用于识别七种情绪：中性、快乐、悲伤、愤怒、恐惧、厌恶和惊讶，这些情绪在五个数据集上进行训练：RAVDESS (R)、TESS (T)、SAVEE (S)、EmoDB (E) 和 Crema-D (C)。该模型在各个数据集上均实现了高准确率，包括 RAVDESS 上的 97.83%、SAVEE 上的 97.02%、CREMA-D 上的 95.10%，以及 TESS 和 EMO-DB 上的完美 100%。对于组合 (R+T+S) 数据集，它实现了 98.82% 的准确率，优于先前报告的结果。据我们所知，目前还没有研究同时在所有五个基准数据集（即 R+T+S+C+E）上评估单个 SER 模型。在我们的工作中，我们引入了这种全面的组合，并实现了显著的总体准确率 93.76%。这些结果证实了我们的 DCRF-BiLSTM 框架在不同数据集上的鲁棒性和泛化能力。"
  },
  {
    "id": "arXiv:2507.07043",
    "title": "Advances in Intelligent Hearing Aids: Deep Learning Approaches to Selective Noise Cancellation",
    "authors": "Haris Khan, Shumaila Asif, Hassan Nasir",
    "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS); Signal Processing (eess.SP)",
    "abs_link": "https://arxiv.org/abs/2507.07043",
    "pdf_link": "https://arxiv.org/pdf/2507.07043",
    "score": 4,
    "abstract": "The integration of artificial intelligence into hearing assistance marks a paradigm shift from traditional amplification-based systems to intelligent, context-aware audio processing. This systematic literature review evaluates advances in AI-driven selective noise cancellation (SNC) for hearing aids, highlighting technological evolution, implementation challenges, and future research directions. We synthesize findings across deep learning architectures, hardware deployment strategies, clinical validation studies, and user-centric design. The review traces progress from early machine learning models to state-of-the-art deep networks, including Convolutional Recurrent Networks for real-time inference and Transformer-based architectures for high-accuracy separation. Key findings include significant gains over traditional methods, with recent models achieving up to 18.3 dB SI-SDR improvement on noisy-reverberant benchmarks, alongside sub-10 ms real-time implementations and promising clinical outcomes. Yet, challenges remain in bridging lab-grade models with real-world deployment - particularly around power constraints, environmental variability, and personalization. Identified research gaps include hardware-software co-design, standardized evaluation protocols, and regulatory considerations for AI-enhanced hearing devices. Future work must prioritize lightweight models, continual learning, contextual-based classification and clinical translation to realize transformative hearing solutions for millions globally.",
    "chinese_title": "智能助听器进展：基于深度学习的选择性噪声消除方法",
    "chinese_abstract": "人工智能融入助听领域标志着从传统的基于扩增的系统向智能、感知环境的音频处理的范式转变。这篇系统性文献综述评估了助听器中人工智能驱动的选择性噪声消除（SNC）的进展，重点介绍了技术演变、实施挑战和未来的研究方向。我们综合了深度学习架构、硬件部署策略、临床验证研究和以用户为中心的设计方面的研究结果。该综述追溯了从早期的机器学习模型到最先进的深度网络（包括用于实时推理的卷积循环网络和用于高精度分离的基于Transformer的架构）的进展。主要发现包括相对于传统方法的显著改进，最近的模型在嘈杂混响基准测试上实现了高达18.3 dB SI-SDR的改进，以及亚10毫秒的实时实现和有希望的临床结果。然而，在将实验室级模型与实际部署联系起来方面仍然存在挑战——特别是围绕功耗限制、环境可变性和个性化。已确定的研究差距包括软硬件协同设计、标准化评估协议以及人工智能增强助听设备的监管考虑。未来的工作必须优先考虑轻量级模型、持续学习、基于上下文的分类和临床转化，以实现为全球数百万人口提供的变革性助听解决方案。"
  },
  {
    "id": "arXiv:2507.07032",
    "title": "PLAME: Leveraging Pretrained Language Models to Generate Enhanced Protein Multiple Sequence Alignments",
    "authors": "Hanqun Cao, Xinyi Zhou, Zijun Gao, Chenyu Wang, Xin Gao, Zhi Zhang, Chunbin Gu, Ge Liu, Pheng-Ann Heng",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Quantitative Methods (q-bio.QM)",
    "abs_link": "https://arxiv.org/abs/2507.07032",
    "pdf_link": "https://arxiv.org/pdf/2507.07032",
    "score": 3,
    "abstract": "Protein structure prediction is essential for drug discovery and understanding biological functions. While recent advancements like AlphaFold have achieved remarkable accuracy, most folding models rely heavily on multiple sequence alignments (MSAs) to boost prediction performance. This dependency limits their effectiveness on low-homology proteins and orphan proteins, where MSA information is sparse or unavailable. To address this limitation, we propose PLAME, a novel MSA design model that leverages evolutionary embeddings from pretrained protein language models. Unlike existing methods, PLAME introduces pretrained representations to enhance evolutionary information and employs a conservation-diversity loss to enhance generation quality. Additionally, we propose a novel MSA selection method to effectively screen high-quality MSAs and improve folding performance. We also propose a sequence quality assessment metric that provides an orthogonal perspective to evaluate MSA quality. On the AlphaFold2 benchmark of low-homology and orphan proteins, PLAME achieves state-of-the-art performance in folding enhancement and sequence quality assessment, with consistent improvements demonstrated on AlphaFold3. Ablation studies validate the effectiveness of the MSA selection method, while extensive case studies on various protein types provide insights into the relationship between AlphaFold's prediction quality and MSA characteristics. Furthermore, we demonstrate that PLAME can serve as an adapter achieving AlphaFold2-level accuracy with the ESMFold's inference speed.",
    "chinese_title": "PLAME：利用预训练语言模型生成增强的蛋白质多序列比对",
    "chinese_abstract": "蛋白质结构预测对于药物发现和理解生物功能至关重要。虽然像AlphaFold这样的最新进展已经取得了显著的准确性，但大多数折叠模型严重依赖多序列比对（MSA）来提高预测性能。这种依赖性限制了它们在低同源性和孤儿蛋白质上的有效性，因为这些蛋白质的MSA信息稀疏或不可用。为了解决这个限制，我们提出了PLAME，一种新颖的MSA设计模型，它利用预训练蛋白质语言模型的进化嵌入。与现有方法不同，PLAME引入了预训练表示来增强进化信息，并采用保守-多样性损失来提高生成质量。此外，我们提出了一种新颖的MSA选择方法，以有效地筛选高质量的MSA并提高折叠性能。我们还提出了一种序列质量评估指标，该指标提供了正交视角来评估MSA质量。在AlphaFold2的低同源性和孤儿蛋白质基准测试中，PLAME在折叠增强和序列质量评估方面取得了最先进的性能，并在AlphaFold3上表现出一致的改进。消融研究验证了MSA选择方法的有效性，而对各种蛋白质类型的广泛案例研究提供了对AlphaFold的预测质量与MSA特征之间关系的洞察。此外，我们证明PLAME可以作为适配器，以ESMFold的推理速度实现AlphaFold2级别的准确性。"
  },
  {
    "id": "arXiv:2507.07024",
    "title": "FlexOlmo: Open Language Models for Flexible Data Use",
    "authors": "Weijia Shi, Akshita Bhagia, Kevin Farhat, Niklas Muennighoff, Pete Walsh, Jacob Morrison, Dustin Schwenk, Shayne Longpre, Jake Poznanski, Allyson Ettinger, Daogao Liu, Margaret Li, Dirk Groeneveld, Mike Lewis, Wen-tau Yih, Luca Soldaini, Kyle Lo, Noah A. Smith, Luke Zettlemoyer, Pang Wei Koh, Hannaneh Hajishirzi, Ali Farhadi, Sewon Min",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07024",
    "pdf_link": "https://arxiv.org/pdf/2507.07024",
    "score": 4,
    "abstract": "We introduce FlexOlmo, a new class of language models (LMs) that supports (1) distributed training without data sharing, where different model parameters are independently trained on closed datasets, and (2) data-flexible inference, where these parameters along with their associated data can be flexibly included or excluded from model inferences with no further training. FlexOlmo employs a mixture-of-experts (MoE) architecture where each expert is trained independently on closed datasets and later integrated through a new domain-informed routing without any joint training. FlexOlmo is trained on FlexMix, a corpus we curate comprising publicly available datasets alongside seven domain-specific sets, representing realistic approximations of closed sets. We evaluate models with up to 37 billion parameters (20 billion active) on 31 diverse downstream tasks. We show that a general expert trained on public data can be effectively combined with independently trained experts from other data owners, leading to an average 41% relative improvement while allowing users to opt out of certain data based on data licensing or permission requirements. Our approach also outperforms prior model merging methods by 10.1% on average and surpasses the standard MoE trained without data restrictions using the same training FLOPs. Altogether, this research presents a solution for both data owners and researchers in regulated industries with sensitive or protected data. FlexOlmo enables benefiting from closed data while respecting data owners' preferences by keeping their data local and supporting fine-grained control of data access during inference.",
    "chinese_title": "FlexOlmo：灵活数据使用的开放语言模型",
    "chinese_abstract": "我们介绍FlexOlmo，这是一种新型的语言模型（LM），它支持（1）分布式训练，无需共享数据，其中不同的模型参数在封闭数据集上独立训练，以及（2）数据灵活推理，这些参数及其相关数据可以在没有进一步训练的情况下灵活地包含或排除在模型推理中。FlexOlmo采用了一种混合专家（MoE）架构，其中每个专家在封闭数据集上独立训练，然后通过新的领域感知路由进行集成，无需联合训练。FlexOlmo在FlexMix上进行训练，FlexMix是一个我们策划的语料库，包含公开可用的数据集以及七个特定领域的集合，代表了封闭集合的真实近似。我们在31个不同的下游任务上评估了参数高达370亿（200亿激活）的模型。我们表明，在公共数据上训练的通用专家可以有效地与其他数据所有者独立训练的专家结合，从而平均提高41%的相对性能，同时允许用户根据数据许可或权限要求选择退出某些数据。我们的方法平均比先前的模型合并方法高出10.1%，并且在相同的训练FLOPs下优于未使用数据限制的标准MoE。总而言之，这项研究为数据所有者和受监管行业的研究人员提供了一种解决方案，他们拥有敏感或受保护的数据。FlexOlmo可以通过将数据保留在本地并支持在推理过程中对数据访问进行细粒度控制，从而受益于封闭数据，同时尊重数据所有者的偏好。"
  },
  {
    "id": "arXiv:2507.06996",
    "title": "Generating Multi-Table Time Series EHR from Latent Space with Minimal Preprocessing",
    "authors": "Eunbyeol Cho, Jiyoun Kim, Minjae Lee, Sungjin Park, Edward Choi",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06996",
    "pdf_link": "https://arxiv.org/pdf/2507.06996",
    "score": 3,
    "abstract": "Electronic Health Records (EHR) are time-series relational databases that record patient interactions and medical events over time, serving as a critical resource for healthcare research and applications. However, privacy concerns and regulatory restrictions limit the sharing and utilization of such sensitive data, necessitating the generation of synthetic EHR datasets. Unlike previous EHR synthesis methods, which typically generate medical records consisting of expert-chosen features (e.g. a few vital signs or structured codes only), we introduce RawMed, the first framework to synthesize multi-table, time-series EHR data that closely resembles raw EHRs. Using text-based representation and compression techniques, RawMed captures complex structures and temporal dynamics with minimal preprocessing. We also propose a new evaluation framework for multi-table time-series synthetic EHRs, assessing distributional similarity, inter-table relationships, temporal dynamics, and privacy. Validated on two open-source EHR datasets, RawMed outperforms baseline models in fidelity and utility. The code is available at https://github.com/eunbyeol-cho/RawMed.",
    "chinese_title": "基于潜在空间的、最少预处理的多表时间序列电子健康记录生成",
    "chinese_abstract": "电子健康记录 (EHR) 是记录患者互动和医疗事件随时间变化的、时间序列关系数据库，是医疗保健研究和应用的重要资源。然而，隐私问题和监管限制限制了此类敏感数据的共享和利用，因此需要生成合成的 EHR 数据集。与以往的 EHR 合成方法不同，以往的方法通常生成由专家选择的特征（例如，仅几个生命体征或结构化代码）组成的医疗记录，我们引入 RawMed，这是第一个合成多表、时间序列 EHR 数据，并且与原始 EHR 数据高度相似的框架。RawMed 使用基于文本的表示和压缩技术，在最少预处理的情况下捕获复杂的结构和时间动态。我们还提出了一种新的多表时间序列合成 EHR 的评估框架，评估分布相似性、表间关系、时间动态和隐私性。在两个开源 EHR 数据集上验证，RawMed 在保真度和实用性方面优于基线模型。代码可在 https://github.com/eunbyeol-cho/RawMed 获取。"
  },
  {
    "id": "arXiv:2507.06992",
    "title": "MCA-RG: Enhancing LLMs with Medical Concept Alignment for Radiology Report Generation",
    "authors": "Qilong Xing, Zikai Song, Youjia Zhang, Na Feng, Junqing Yu, Wei Yang",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06992",
    "pdf_link": "https://arxiv.org/pdf/2507.06992",
    "score": 4,
    "abstract": "Despite significant advancements in adapting Large Language Models (LLMs) for radiology report generation (RRG), clinical adoption remains challenging due to difficulties in accurately mapping pathological and anatomical features to their corresponding text descriptions. Additionally, semantic agnostic feature extraction further hampers the generation of accurate diagnostic reports. To address these challenges, we introduce Medical Concept Aligned Radiology Report Generation (MCA-RG), a knowledge-driven framework that explicitly aligns visual features with distinct medical concepts to enhance the report generation process. MCA-RG utilizes two curated concept banks: a pathology bank containing lesion-related knowledge, and an anatomy bank with anatomical descriptions. The visual features are aligned with these medical concepts and undergo tailored enhancement. We further propose an anatomy-based contrastive learning procedure to improve the generalization of anatomical features, coupled with a matching loss for pathological features to prioritize clinically relevant regions. Additionally, a feature gating mechanism is employed to filter out low-quality concept features. Finally, the visual features are corresponding to individual medical concepts, and are leveraged to guide the report generation process. Experiments on two public benchmarks (MIMIC-CXR and CheXpert Plus) demonstrate that MCA-RG achieves superior performance, highlighting its effectiveness in radiology report generation.",
    "chinese_title": "MCA-RG：利用医学概念对齐增强大型语言模型以生成放射学报告",
    "chinese_abstract": "尽管大型语言模型（LLM）在放射学报告生成（RRG）方面取得了显著进展，但由于难以将病理和解剖特征准确映射到相应的文本描述，其临床应用仍然面临挑战。此外，语义无关的特征提取进一步阻碍了准确诊断报告的生成。为了应对这些挑战，我们引入了医学概念对齐放射学报告生成（MCA-RG），这是一种知识驱动的框架，它明确地将视觉特征与不同的医学概念对齐，以增强报告生成过程。MCA-RG利用两个策划的概念库：一个包含病灶相关知识的病理库，以及一个包含解剖描述的解剖库。视觉特征与这些医学概念对齐并进行定制增强。我们进一步提出了一种基于解剖的对比学习程序，以提高解剖特征的泛化能力，并结合病理特征的匹配损失，以优先考虑临床相关区域。此外，还采用特征门控机制来过滤掉低质量的概念特征。最后，视觉特征对应于各个医学概念，并被用来指导报告生成过程。在两个公共基准（MIMIC-CXR和CheXpert Plus）上的实验表明，MCA-RG实现了卓越的性能，突出了其在放射学报告生成方面的有效性。"
  },
  {
    "id": "arXiv:2507.06959",
    "title": "CheXPO: Preference Optimization for Chest X-ray VLMs with Counterfactual Rationale",
    "authors": "Xiao Liang, Jiawei Hu, Di Wang, Zhi Ma, Lin Zhao, Ronghan Li, Bo Wan, Quan Wang",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06959",
    "pdf_link": "https://arxiv.org/pdf/2507.06959",
    "score": 4,
    "abstract": "Vision-language models (VLMs) are prone to hallucinations that critically compromise reliability in medical applications. While preference optimization can mitigate these hallucinations through clinical feedback, its implementation faces challenges such as clinically irrelevant training samples, imbalanced data distributions, and prohibitive expert annotation costs. To address these challenges, we introduce CheXPO, a Chest X-ray Preference Optimization strategy that combines confidence-similarity joint mining with counterfactual rationale. Our approach begins by synthesizing a unified, fine-grained multi-task chest X-ray visual instruction dataset across different question types for supervised fine-tuning (SFT). We then identify hard examples through token-level confidence analysis of SFT failures and use similarity-based retrieval to expand hard examples for balancing preference sample distributions, while synthetic counterfactual rationales provide fine-grained clinical preferences, eliminating the need for additional expert input. Experiments show that CheXPO achieves 8.93% relative performance gain using only 5% of SFT samples, reaching state-of-the-art performance across diverse clinical tasks and providing a scalable, interpretable solution for real-world radiology applications.",
    "chinese_title": "CheXPO：基于反事实理由的胸部X光VLMs偏好优化",
    "chinese_abstract": "视觉语言模型（VLMs）容易产生幻觉，这严重损害了其在医学应用中的可靠性。虽然偏好优化可以通过临床反馈来减轻这些幻觉，但其实现面临着临床无关的训练样本、不平衡的数据分布以及昂贵的专家标注成本等挑战。为了应对这些挑战，我们引入了CheXPO，一种结合置信度-相似性联合挖掘与反事实理由的胸部X光偏好优化策略。我们的方法首先合成一个统一的、细粒度的多任务胸部X光视觉指令数据集，涵盖不同类型的问题，用于监督微调（SFT）。然后，我们通过对SFT失败的token级别置信度分析来识别困难样本，并使用基于相似性的检索来扩展困难样本，以平衡偏好样本分布，同时合成的反事实理由提供了细粒度的临床偏好，无需额外的专家输入。实验表明，CheXPO仅使用5%的SFT样本就实现了8.93%的相对性能提升，在各种临床任务中达到了最先进的性能，并为现实世界的放射学应用提供了一个可扩展、可解释的解决方案。"
  },
  {
    "id": "arXiv:2507.06952",
    "title": "What Has a Foundation Model Found? Using Inductive Bias to Probe for World Models",
    "authors": "Keyon Vafa, Peter G. Chang, Ashesh Rambachan, Sendhil Mullainathan",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06952",
    "pdf_link": "https://arxiv.org/pdf/2507.06952",
    "score": 4,
    "abstract": "Foundation models are premised on the idea that sequence prediction can uncover deeper domain understanding, much like how Kepler's predictions of planetary motion later led to the discovery of Newtonian mechanics. However, evaluating whether these models truly capture deeper structure remains a challenge. We develop a technique for evaluating foundation models that examines how they adapt to synthetic datasets generated from some postulated world model. Our technique measures whether the foundation model's inductive bias aligns with the world model, and so we refer to it as an inductive bias probe. Across multiple domains, we find that foundation models can excel at their training tasks yet fail to develop inductive biases towards the underlying world model when adapted to new tasks. We particularly find that foundation models trained on orbital trajectories consistently fail to apply Newtonian mechanics when adapted to new physics tasks. Further analysis reveals that these models behave as if they develop task-specific heuristics that fail to generalize.",
    "chinese_title": "基础模型发现了什么？利用归纳偏置探测世界模型",
    "chinese_abstract": "基础模型的前提是序列预测可以揭示更深层次的领域理解，就像开普勒对行星运动的预测后来导致了牛顿力学的发现一样。然而，评估这些模型是否真正捕捉到更深层次的结构仍然是一个挑战。我们开发了一种评估基础模型的技术，该技术检查它们如何适应由某些假设的世界模型生成的合成数据集。我们的技术衡量基础模型的归纳偏置是否与世界模型一致，因此我们称之为归纳偏置探测器。在多个领域，我们发现基础模型可以在其训练任务中表现出色，但在适应新任务时，却未能发展出对潜在世界模型的归纳偏置。我们特别发现，在适应新的物理任务时，经过轨道轨迹训练的基础模型始终无法应用牛顿力学。进一步的分析表明，这些模型表现得好像它们发展出了特定于任务的启发式方法，而这些方法无法泛化。"
  },
  {
    "id": "arXiv:2507.06899",
    "title": "VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation",
    "authors": "Ziang Ye, Yang Zhang, Wentao Shi, Xiaoyu You, Fuli Feng, Tat-Seng Chua",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06899",
    "pdf_link": "https://arxiv.org/pdf/2507.06899",
    "score": 3,
    "abstract": "Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.",
    "chinese_title": "VisualTrap：通过视觉定位操纵对GUI代理的隐蔽后门攻击",
    "chinese_abstract": "由大型视觉语言模型（LVLM）驱动的图形用户界面（GUI）代理已经成为自动化人机交互的一种革命性方法，能够自主操作个人设备（例如手机）或设备内的应用程序，以人类般的方式执行复杂的现实任务。然而，它们与个人设备的紧密集成引发了重大的安全问题，许多威胁（包括后门攻击）仍有待探索。这项工作表明，GUI代理的视觉定位——将文本计划映射到GUI元素——可能会引入漏洞，从而导致新型后门攻击。通过针对视觉定位的后门攻击，即使在给出正确的任务解决方案时，也能破坏代理的行为。为了验证这种漏洞，我们提出了VisualTrap，一种可以通过误导代理将文本计划定位到触发位置而不是预期目标来劫持定位的方法。VisualTrap使用注入中毒数据进行攻击的常见方法，并在视觉定位的预训练期间进行，以确保攻击的可行性。经验结果表明，VisualTrap只需少量（5%）的中毒数据和高度隐蔽的视觉触发器（人眼不可见）即可有效劫持视觉定位；并且攻击可以推广到下游任务，即使在干净的微调之后也是如此。此外，注入的触发器可以在不同的GUI环境中保持有效，例如在移动/Web上训练并在桌面环境中泛化。这些发现强调了进一步研究GUI代理中后门攻击风险的紧迫性。"
  },
  {
    "id": "arXiv:2507.06893",
    "title": "Developing and Maintaining an Open-Source Repository of AI Evaluations: Challenges and Insights",
    "authors": "Alexandra Abbas, Celia Waggoner, Justin Olive",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06893",
    "pdf_link": "https://arxiv.org/pdf/2507.06893",
    "score": 3,
    "abstract": "AI evaluations have become critical tools for assessing large language model capabilities and safety. This paper presents practical insights from eight months of maintaining $inspect\\_evals$, an open-source repository of 70+ community-contributed AI evaluations. We identify key challenges in implementing and maintaining AI evaluations and develop solutions including: (1) a structured cohort management framework for scaling community contributions, (2) statistical methodologies for optimal resampling and cross-model comparison with uncertainty quantification, and (3) systematic quality control processes for reproducibility. Our analysis reveals that AI evaluation requires specialized infrastructure, statistical rigor, and community coordination beyond traditional software development practices.",
    "chinese_title": "开发和维护人工智能评估的开源仓库：挑战与见解",
    "chinese_abstract": "人工智能评估已成为评估大型语言模型能力和安全性的关键工具。本文介绍了维护inspect_evals（一个包含70多个社区贡献的人工智能评估的开源仓库）八个月的实践见解。我们确定了实施和维护人工智能评估的关键挑战，并开发了解决方案，包括：（1）用于扩展社区贡献的结构化队列管理框架；（2）用于在不确定性量化下进行最优重采样和跨模型比较的统计方法；以及（3）用于可重复性的系统质量控制流程。我们的分析表明，人工智能评估需要专门的基础设施、统计严谨性和社区协调，而这些在传统的软件开发实践之外。"
  },
  {
    "id": "arXiv:2507.06892",
    "title": "Squeeze the Soaked Sponge: Efficient Off-policy Reinforcement Finetuning for Large Language Model",
    "authors": "Jing Liang, Hongyao Tang, Yi Ma, Jinyi Liu, Yan Zheng, Shuyue Hu, Lei Bai, Jianye Hao",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06892",
    "pdf_link": "https://arxiv.org/pdf/2507.06892",
    "score": 5,
    "abstract": "Reinforcement Learning (RL) has demonstrated its potential to improve the reasoning ability of Large Language Models (LLMs). One major limitation of most existing Reinforcement Finetuning (RFT) methods is that they are on-policy RL in nature, i.e., data generated during the past learning process is not fully utilized. This inevitably comes at a significant cost of compute and time, posing a stringent bottleneck on continuing economic and efficient scaling. To this end, we launch the renaissance of off-policy RL and propose Reincarnating Mix-policy Proximal Policy Gradient (ReMix), a general approach to enable on-policy RFT methods like PPO and GRPO to leverage off-policy data. ReMix consists of three major components: (1) Mix-policy proximal policy gradient with an increased Update-To-Data (UTD) ratio for efficient training; (2) KL-Convex policy constraint to balance the trade-off between stability and flexibility; (3) Policy reincarnation to achieve a seamless transition from efficient early-stage learning to steady asymptotic improvement. In our experiments, we train a series of ReMix models upon PPO, GRPO and 1.5B, 7B base models. ReMix shows an average Pass@1 accuracy of 52.10% (for 1.5B model) with 0.079M response rollouts, 350 training steps and achieves 63.27%/64.39% (for 7B model) with 0.007M/0.011M response rollouts, 50/75 training steps, on five math reasoning benchmarks (i.e., AIME'24, AMC'23, Minerva, OlympiadBench, and MATH500). Compared with 15 recent advanced models, ReMix shows SOTA-level performance with an over 30x to 450x reduction in training cost in terms of rollout data volume. In addition, we reveal insightful findings via multifaceted analysis, including the implicit preference for shorter responses due to the Whipping Effect of off-policy discrepancy, the collapse mode of self-reflection behavior under the presence of severe off-policyness, etc.",
    "chinese_title": "挤压浸透的海绵：用于大型语言模型的有效离线强化微调",
    "chinese_abstract": "强化学习 (RL) 已证明其提升大型语言模型 (LLM) 推理能力的可能性。大多数现有强化微调 (RFT) 方法的主要局限性在于它们本质上是基于策略的 RL，即过去学习过程中生成的数据并未得到充分利用。这不可避免地带来了巨大的计算和时间成本，对持续的经济高效扩展构成了严格的瓶颈。为此，我们开启了离线 RL 的复兴，并提出了 Reincarnating Mix-policy Proximal Policy Gradient (ReMix)，这是一种通用的方法，可以使像 PPO 和 GRPO 这样的基于策略的 RFT 方法利用离线策略数据。ReMix 包括三个主要组成部分：(1) 具有增加的更新到数据 (UTD) 比率的混合策略近端策略梯度，用于高效训练；(2) KL-凸策略约束，以平衡稳定性和灵活性之间的权衡；(3) 策略转世，以实现从高效早期学习到稳定渐近改进的无缝过渡。在我们的实验中，我们在 PPO、GRPO 和 1.5B、7B 基模型上训练了一系列 ReMix 模型。ReMix 在五个数学推理基准（即 AIME'24、AMC'23、Minerva、OlympiadBench 和 MATH500）上显示了平均 Pass@1 准确率 52.10%（对于 1.5B 模型），使用了 0.079M 响应回滚，进行了 350 个训练步骤，并实现了 63.27%/64.39%（对于 7B 模型），使用了 0.007M/0.011M 响应回滚，进行了 50/75 个训练步骤。与 15 个最近的先进模型相比，ReMix 在推出数据量方面显示了 SOTA 级别的性能，训练成本降低了 30 倍到 450 倍。此外，我们通过多方面的分析揭示了有价值的发现，包括由于离线策略差异引起的鞭打效应导致的对较短响应的隐性偏好，以及在存在严重离线策略的情况下自我反思行为的崩溃模式等。"
  },
  {
    "id": "arXiv:2507.06853",
    "title": "DiffSpectra: Molecular Structure Elucidation from Spectra using Diffusion Models",
    "authors": "Liang Wang, Yu Rong, Tingyang Xu, Zhenyi Zhong, Zhiyuan Liu, Pengju Wang, Deli Zhao, Qiang Liu, Shu Wu, Liang Wang",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph); Molecular Networks (q-bio.MN)",
    "abs_link": "https://arxiv.org/abs/2507.06853",
    "pdf_link": "https://arxiv.org/pdf/2507.06853",
    "score": 4,
    "abstract": "Molecular structure elucidation from spectra is a foundational problem in chemistry, with profound implications for compound identification, synthesis, and drug development. Traditional methods rely heavily on expert interpretation and lack scalability. Pioneering machine learning methods have introduced retrieval-based strategies, but their reliance on finite libraries limits generalization to novel molecules. Generative models offer a promising alternative, yet most adopt autoregressive SMILES-based architectures that overlook 3D geometry and struggle to integrate diverse spectral modalities. In this work, we present DiffSpectra, a generative framework that directly infers both 2D and 3D molecular structures from multi-modal spectral data using diffusion models. DiffSpectra formulates structure elucidation as a conditional generation process. Its denoising network is parameterized by Diffusion Molecule Transformer, an SE(3)-equivariant architecture that integrates topological and geometric information. Conditioning is provided by SpecFormer, a transformer-based spectral encoder that captures intra- and inter-spectral dependencies from multi-modal spectra. Extensive experiments demonstrate that DiffSpectra achieves high accuracy in structure elucidation, recovering exact structures with 16.01% top-1 accuracy and 96.86% top-20 accuracy through sampling. The model benefits significantly from 3D geometric modeling, SpecFormer pre-training, and multi-modal conditioning. These results highlight the effectiveness of spectrum-conditioned diffusion modeling in addressing the challenge of molecular structure elucidation. To our knowledge, DiffSpectra is the first framework to unify multi-modal spectral reasoning and joint 2D/3D generative modeling for de novo molecular structure elucidation.",
    "chinese_title": "DiffSpectra：基于扩散模型的谱图反推分子结构",
    "chinese_abstract": "从谱图反推分子结构是化学领域的一个基础性问题，对化合物鉴定、合成和药物开发具有深远影响。传统方法严重依赖专家解读，缺乏可扩展性。先锋机器学习方法引入了基于检索的策略，但其对有限库的依赖限制了对新型分子的泛化能力。生成模型提供了一种有前景的替代方案，但大多数采用基于自回归SMILES的架构，忽略了3D几何形状，并且难以整合不同的谱图模态。在这项工作中，我们提出了DiffSpectra，一个利用扩散模型直接从多模态谱数据推断2D和3D分子结构的生成框架。DiffSpectra将结构推断形式化为条件生成过程。其去噪网络由扩散分子变换器（Diffusion Molecule Transformer）参数化，这是一种SE(3)等变架构，可以整合拓扑和几何信息。条件信息由SpecFormer提供，这是一种基于变换器的谱编码器，可以捕获来自多模态谱图的谱内和谱间依赖关系。大量的实验表明，DiffSpectra在结构推断方面实现了高精度，通过采样恢复精确结构的top-1准确率为16.01%，top-20准确率为96.86%。该模型从3D几何建模、SpecFormer预训练和多模态条件化中获益显著。这些结果突出了谱图条件扩散建模在解决分子结构推断挑战中的有效性。据我们所知，DiffSpectra是第一个统一多模态谱图推理和联合2D/3D生成建模，用于从头分子结构推断的框架。"
  },
  {
    "id": "arXiv:2507.06850",
    "title": "The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover",
    "authors": "Matteo Lupinacci, Francesco Aurelio Pironti, Francesco Blefari, Francesco Romeo, Luigi Arena, Angelo Furfaro",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06850",
    "pdf_link": "https://arxiv.org/pdf/2507.06850",
    "score": 4,
    "abstract": "The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.",
    "chinese_title": "大型语言模型的黑暗面：基于代理的攻击实现完全计算机控制",
    "chinese_abstract": "大型语言模型 (LLM) 代理和多代理系统的快速采用，在自然语言处理和生成方面实现了前所未有的能力。然而，这些系统也引入了前所未有的安全漏洞，这些漏洞超出了传统的提示注入攻击。本文首次全面评估了 LLM 代理作为攻击媒介的能力，能够通过利用代理 AI 系统内信任边界来达到完全控制计算机的目的，其中自主实体相互交互和影响。我们证明了攻击者可以利用三种不同的攻击面——直接提示注入、RAG 后门攻击和代理间信任利用——来胁迫流行的 LLM（包括 GPT-4o、Claude-4 和 Gemini-2.5）在受害者机器上自主安装和执行恶意软件。我们对 17 个最先进的 LLM 的评估揭示了一个令人担忧的漏洞等级：虽然 41.2% 的模型屈服于直接提示注入，但 52.9% 容易受到 RAG 后门攻击，而高达 82.4% 的模型可以通过代理间信任利用被攻破。值得注意的是，我们发现即使成功抵御直接恶意命令的 LLM，在收到同伴代理的请求时也会执行相同的有效载荷，这揭示了当前多代理安全模型的一个根本缺陷。我们的研究结果表明，只有 5.9% 的测试模型（1/17）被证明能够抵抗所有攻击向量，而大多数模型表现出上下文相关的安全行为，从而产生了可利用的盲点。我们的发现还强调了提高对 LLM 安全风险的认识和研究的必要性，表明网络安全威胁发生了范式转变，人工智能工具本身也成为了复杂的攻击媒介。"
  },
  {
    "id": "arXiv:2507.06849",
    "title": "OpenDPDv2: A Unified Learning and Optimization Framework for Neural Network Digital Predistortion",
    "authors": "Yizhuo Wu, Ang Li, Chang Gao",
    "subjects": "Signal Processing (eess.SP); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06849",
    "pdf_link": "https://arxiv.org/pdf/2507.06849",
    "score": 3,
    "abstract": "Neural network (NN)-based Digital Predistortion (DPD) stands out in improving signal quality in wideband radio frequency (RF) power amplifiers (PAs) employing complex modulation. However, NN DPDs usually rely on a large number of parameters for effective linearization and can significantly contribute to the energy consumption of the digital back-end in RF systems. This paper presents OpenDPDv2, a unified framework for PA modeling, DPD learning, and model optimization to reduce power consumption while maintaining high linearization performance. The optimization techniques feature a novel DPD algorithm, TRes-DeltaGRU, alongside two energy-efficient methods. The top-performing 32-bit floating-point (FP32) TRes-DeltaGRU-DPD model achieves an Adjacent Channel Power Ratio (ACPR) of -59.4 dBc and Error Vector Magnitude (EVM) of -42.1 dBc. By exploiting fixed-point quantization and dynamic temporal sparsity of input signals and hidden neurons, the inference energy of our model can be reduced by 4.5X while still maintaining -50.3 dBc ACPR and -35.2 dB EVM with 56% temporal sparsity. This was evaluated using a TM3.1a 200 MHz bandwidth 256-QAM OFDM signal applied to a 3.5 GHz GaN Doherty RF PA. OpenDPDv2 code, datasets, and documentation are publicly accessible at: https://github.com/lab-emi/OpenDPD.",
    "chinese_title": "OpenDPDv2：用于神经网络数字预失真的统一学习和优化框架",
    "chinese_abstract": "基于神经网络（NN）的数字预失真（DPD）在改善采用复杂调制的宽带射频（RF）功率放大器（PA）的信号质量方面表现出色。然而，NN DPD通常依赖于大量的参数来实现有效的线性化，并且可能显著增加射频系统中数字后端能耗。本文提出OpenDPDv2，一个用于PA建模、DPD学习和模型优化的统一框架，旨在降低功耗同时保持高性能线性化。优化技术包括一种新型DPD算法TRes-DeltaGRU，以及两种节能方法。性能最佳的32位浮点数（FP32）TRes-DeltaGRU-DPD模型实现了-59.4 dBc的邻道功率比（ACPR）和-42.1 dBc的误差向量幅度（EVM）。通过利用固定点量化和输入信号及隐藏神经元的动态时间稀疏性，我们的模型推理能耗可降低4.5倍，同时仍保持-50.3 dBc ACPR和-35.2 dB EVM，时间稀疏度为56%。这使用应用于3.5 GHz GaN Doherty RF PA的TM3.1a 200 MHz带宽256-QAM OFDM信号进行评估。OpenDPDv2代码、数据集和文档可公开访问：https://github.com/lab-emi/OpenDPD。"
  },
  {
    "id": "arXiv:2507.06830",
    "title": "Physics-Grounded Motion Forecasting via Equation Discovery for Trajectory-Guided Image-to-Video Generation",
    "authors": "Tao Feng, Xianbing Zhao, Zhenhua Chen, Tien Tsin Wong, Hamid Rezatofighi, Gholamreza Haffari, Lizhen Qu",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06830",
    "pdf_link": "https://arxiv.org/pdf/2507.06830",
    "score": 4,
    "abstract": "Recent advances in diffusion-based and autoregressive video generation models have achieved remarkable visual realism. However, these models typically lack accurate physical alignment, failing to replicate real-world dynamics in object motion. This limitation arises primarily from their reliance on learned statistical correlations rather than capturing mechanisms adhering to physical laws. To address this issue, we introduce a novel framework that integrates symbolic regression (SR) and trajectory-guided image-to-video (I2V) models for physics-grounded video forecasting. Our approach extracts motion trajectories from input videos, uses a retrieval-based pre-training mechanism to enhance symbolic regression, and discovers equations of motion to forecast physically accurate future trajectories. These trajectories then guide video generation without requiring fine-tuning of existing models. Evaluated on scenarios in Classical Mechanics, including spring-mass, pendulums, and projectile motions, our method successfully recovers ground-truth analytical equations and improves the physical alignment of generated videos over baseline methods.",
    "chinese_title": "基于方程发现的物理驱动运动预测，用于轨迹引导的图像到视频生成",
    "chinese_abstract": "最近，基于扩散和自回归的视频生成模型在视觉真实感方面取得了显著进展。然而，这些模型通常缺乏准确的物理对齐，无法在物体运动中复制现实世界的动态。这种局限性主要源于它们依赖于学习到的统计相关性，而不是捕捉遵循物理定律的机制。为了解决这个问题，我们引入了一个新框架，该框架将符号回归（SR）和轨迹引导的图像到视频（I2V）模型集成在一起，用于物理驱动的视频预测。我们的方法从输入视频中提取运动轨迹，使用基于检索的预训练机制来增强符号回归，并发现运动方程以预测物理上准确的未来轨迹。这些轨迹随后指导视频生成，而无需对现有模型进行微调。在经典力学场景（包括弹簧-质量系统、摆和抛物线运动）上的评估表明，我们的方法成功地恢复了真实的解析方程，并提高了生成视频的物理对齐度，优于基线方法。"
  },
  {
    "id": "arXiv:2507.06825",
    "title": "Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning",
    "authors": "Matej Straka, Martin Schmid",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06825",
    "pdf_link": "https://arxiv.org/pdf/2507.06825",
    "score": 4,
    "abstract": "We introduce a real-time strategy game environment built on Generals.io, a game that hosts thousands of active players each week across multiple game formats. Our environment is fully compatible with Gymnasium and PettingZoo, capable of running thousands of frames per second on commodity hardware. Our reference agent -- trained with supervised pre-training and self-play -- hits the top 0.003\\% of the 1v1 human leaderboard after just 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions -- a modular RTS benchmark and a competitive, state-of-the-art baseline agent -- provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research.",
    "chinese_title": "通用人工智能：利用强化学习掌握《将军IO》",
    "chinese_abstract": "我们介绍了一个基于《将军IO》游戏的实时战略游戏环境，该游戏每周在多种游戏模式下拥有数千名活跃玩家。我们的环境与Gymnasium和PettingZoo完全兼容，能够在普通硬件上运行数千帧每秒。我们的参考代理——通过监督预训练和自我对弈训练——在仅使用单个H100 GPU 36小时后，达到了1v1人类排行榜的前0.003%。为了加速学习，我们结合了基于势的奖励塑造和记忆特征。我们的贡献——一个模块化的RTS基准和一个具有竞争力的、最先进的基线代理——为推进多智能体强化学习研究提供了一个易于访问但具有挑战性的平台。"
  },
  {
    "id": "arXiv:2507.06821",
    "title": "HeLo: Heterogeneous Multi-Modal Fusion with Label Correlation for Emotion Distribution Learning",
    "authors": "Chuhang Zheng, Chunwei Tian, Jie Wen, Daoqiang Zhang, Qi Zhu",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Multimedia (cs.MM)",
    "abs_link": "https://arxiv.org/abs/2507.06821",
    "pdf_link": "https://arxiv.org/pdf/2507.06821",
    "score": 4,
    "abstract": "Multi-modal emotion recognition has garnered increasing attention as it plays a significant role in human-computer interaction (HCI) in recent years. Since different discrete emotions may exist at the same time, compared with single-class emotion recognition, emotion distribution learning (EDL) that identifies a mixture of basic emotions has gradually emerged as a trend. However, existing EDL methods face challenges in mining the heterogeneity among multiple modalities. Besides, rich semantic correlations across arbitrary basic emotions are not fully exploited. In this paper, we propose a multi-modal emotion distribution learning framework, named HeLo, aimed at fully exploring the heterogeneity and complementary information in multi-modal emotional data and label correlation within mixed basic emotions. Specifically, we first adopt cross-attention to effectively fuse the physiological data. Then, an optimal transport (OT)-based heterogeneity mining module is devised to mine the interaction and heterogeneity between the physiological and behavioral representations. To facilitate label correlation learning, we introduce a learnable label embedding optimized by correlation matrix alignment. Finally, the learnable label embeddings and label correlation matrices are integrated with the multi-modal representations through a novel label correlation-driven cross-attention mechanism for accurate emotion distribution learning. Experimental results on two publicly available datasets demonstrate the superiority of our proposed method in emotion distribution learning.",
    "chinese_title": "HeLo：基于标签相关性的异构多模态融合用于情感分布学习",
    "chinese_abstract": "多模态情感识别近年来备受关注，因为它在人机交互（HCI）中发挥着重要作用。由于不同的离散情感可能同时存在，与单类别情感识别相比，能够识别混合基本情感的情感分布学习（EDL）逐渐成为一种趋势。然而，现有的EDL方法在挖掘多个模态之间的异质性方面面临挑战。此外，任意基本情感之间丰富的语义相关性尚未得到充分利用。在本文中，我们提出了一种多模态情感分布学习框架，名为HeLo，旨在充分探索多模态情感数据和混合基本情感中标签相关性的异质性和互补信息。具体而言，我们首先采用交叉注意力机制有效地融合生理数据。然后，设计了一种基于最优传输（OT）的异质性挖掘模块，以挖掘生理和行为表征之间的交互和异质性。为了促进标签相关性学习，我们引入了一种通过相关矩阵对齐进行优化的可学习标签嵌入。最后，我们将可学习的标签嵌入和标签相关矩阵通过一种新颖的标签相关性驱动的交叉注意力机制与多模态表征集成，以进行准确的情感分布学习。在两个公开数据集上的实验结果表明，我们提出的方法在情感分布学习方面具有优越性。"
  },
  {
    "id": "arXiv:2507.06819",
    "title": "Comprehensive Evaluation of Prototype Neural Networks",
    "authors": "Philipp Schlinge, Steffen Meinert, Martin Atzmueller",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06819",
    "pdf_link": "https://arxiv.org/pdf/2507.06819",
    "score": 3,
    "abstract": "Prototype models are an important method for explainable artificial intelligence (XAI) and interpretable machine learning. In this paper, we perform an in-depth analysis of a set of prominent prototype models including ProtoPNet, ProtoPool and PIPNet. For their assessment, we apply a comprehensive set of metrics. In addition to applying standard metrics from literature, we propose several new metrics to further complement the analysis of model interpretability. In our experimentation, we apply the set of prototype models on a diverse set of datasets including fine-grained classification, Non-IID settings and multi-label classification to further contrast the performance. Furthermore, we also provide our code as an open-source library, which facilitates simple application of the metrics itself, as well as extensibility - providing the option for easily adding new metrics and models. https://github.com/uos-sis/quanproto",
    "chinese_title": "原型神经网络的综合评估",
    "chinese_abstract": "原型模型是可解释人工智能 (XAI) 和可解释机器学习的重要方法。在本文中，我们对一组著名的原型模型，包括 ProtoPNet、ProtoPool 和 PIPNet，进行了深入分析。为了评估它们，我们应用了一套全面的指标。除了应用文献中的标准指标外，我们还提出了一些新的指标，以进一步补充对模型可解释性的分析。在我们的实验中，我们将这组原型模型应用于各种数据集，包括细粒度分类、非独立同分布设置和多标签分类，以进一步对比性能。此外，我们还提供我们的代码作为开源库，这简化了指标的应用，并提供了可扩展性——为轻松添加新指标和模型提供了选择。"
  },
  {
    "id": "arXiv:2507.06812",
    "title": "Democratizing High-Fidelity Co-Speech Gesture Video Generation",
    "authors": "Xu Yang, Shaoli Huang, Shenbo Xie, Xuelin Chen, Yifei Liu, Changxing Ding",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06812",
    "pdf_link": "https://arxiv.org/pdf/2507.06812",
    "score": 4,
    "abstract": "Co-speech gesture video generation aims to synthesize realistic, audio-aligned videos of speakers, complete with synchronized facial expressions and body gestures. This task presents challenges due to the significant one-to-many mapping between audio and visual content, further complicated by the scarcity of large-scale public datasets and high computational demands. We propose a lightweight framework that utilizes 2D full-body skeletons as an efficient auxiliary condition to bridge audio signals with visual outputs. Our approach introduces a diffusion model conditioned on fine-grained audio segments and a skeleton extracted from the speaker's reference image, predicting skeletal motions through skeleton-audio feature fusion to ensure strict audio coordination and body shape consistency. The generated skeletons are then fed into an off-the-shelf human video generation model with the speaker's reference image to synthesize high-fidelity videos. To democratize research, we present CSG-405-the first public dataset with 405 hours of high-resolution videos across 71 speech types, annotated with 2D skeletons and diverse speaker demographics. Experiments show that our method exceeds state-of-the-art approaches in visual quality and synchronization while generalizing across speakers and contexts.",
    "chinese_title": " democratizing 高保真伴随语音手势视频生成",
    "chinese_abstract": "伴随语音手势视频生成旨在合成逼真的、与音频对齐的说话者视频，包括同步的面部表情和身体手势。由于音频和视觉内容之间存在显著的一对多映射关系，以及缺乏大规模公共数据集和高计算需求，这项任务面临挑战。我们提出一个轻量级框架，利用 2D 全身骨骼作为高效的辅助条件，将音频信号与视觉输出桥接起来。我们的方法引入了一个基于细粒度音频片段和从说话者参考图像中提取的骨骼进行条件化的扩散模型，通过骨骼-音频特征融合预测骨骼运动，以确保严格的音频协调性和身体形状一致性。生成的骨骼随后被馈送到一个现成的、使用说话者参考图像的人体视频生成模型中，以合成高保真视频。为了 democratize 研究，我们提出了 CSG-405——第一个包含 405 小时的高分辨率视频的公共数据集，涵盖 71 种语音类型，并附带 2D 骨骼和多样化的说话者人口统计信息。实验表明，我们的方法在视觉质量和同步性方面优于最先进的方法，并且能够泛化到不同的说话者和上下文。"
  },
  {
    "id": "arXiv:2507.06804",
    "title": "Towards Solving More Challenging IMO Problems via Decoupled Reasoning and Proving",
    "authors": "Zhenwen Liang, Linfeng Song, Yang Li, Tao Yang, Feng Zhang, Haitao Mi, Dong Yu",
    "subjects": "Logic in Computer Science (cs.LO); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06804",
    "pdf_link": "https://arxiv.org/pdf/2507.06804",
    "score": 4,
    "abstract": "Automated Theorem Proving (ATP) in formal languages is a foundational challenge for AI. While Large Language Models (LLMs) have driven remarkable progress, a significant gap remains between their powerful informal reasoning capabilities and their weak formal proving performance. Recent studies show that the informal accuracy exceeds 80% while formal success remains below 8% on benchmarks like PutnamBench. We argue this gap persists because current state-of-the-art provers, by tightly coupling reasoning and proving, are trained with paradigms that inadvertently punish deep reasoning in favor of shallow, tactic-based strategies. To bridge this fundamental gap, we propose a novel framework that decouples high-level reasoning from low-level proof generation. Our approach utilizes two distinct, specialized models: a powerful, general-purpose Reasoner to generate diverse, strategic subgoal lemmas, and an efficient Prover to rigorously verify them. This modular design liberates the model's full reasoning potential and bypasses the pitfalls of end-to-end training. We evaluate our method on a challenging set of post-2000 IMO problems, a problem set on which no prior open-source prover has reported success. Our decoupled framework successfully solves 5 of these problems, demonstrating a significant step towards automated reasoning on exceptionally difficult mathematical challenges. To foster future research, we release our full dataset of generated and verified lemmas for a wide range of IMO problems, available at https://tencent-imo.github.io/ .",
    "chinese_title": "通过解耦推理与证明解决更具挑战性的国际数学奥林匹克问题",
    "chinese_abstract": "在形式语言中，自动定理证明（ATP）是人工智能领域的一个基础性挑战。虽然大型语言模型（LLM）推动了显著的进展，但在其强大的非正式推理能力与较弱的形式化证明性能之间仍然存在显著差距。最近的研究表明，在PutnamBench等基准测试中，非正式准确率超过80%，而形式化成功率仍然低于8%。我们认为，这种差距仍然存在，因为当前最先进的证明器通过紧密耦合推理和证明，以训练范式进行训练，无意中惩罚了深度推理，而倾向于浅层、基于策略的策略。为了弥合这一根本差距，我们提出了一种新颖的框架，将高级推理与低级证明生成解耦。我们的方法利用两个不同的、专门的模型：一个强大的、通用推理器，用于生成多样化的、战略性的子目标引理；以及一个高效的证明器，用于严格验证它们。这种模块化设计释放了模型的全部推理潜力，并绕过了端到端训练的陷阱。我们在具有挑战性的2000年以后国际数学奥林匹克（IMO）问题集上评估了我们的方法，该问题集是先前任何开源证明器都没有报告成功的集合。我们的解耦框架成功解决了其中的5个问题，证明了在异常困难的数学挑战上进行自动推理迈出了重要一步。为了促进未来的研究，我们发布了针对广泛的IMO问题的生成和验证引理的完整数据集，网址为https://tencent-imo.github.io/。"
  },
  {
    "id": "arXiv:2507.06803",
    "title": "Text to model via SysML: Automated generation of dynamical system computational models from unstructured natural language text via enhanced System Modeling Language diagrams",
    "authors": "Matthew Anderson Hendricks, Alice Cicirello",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE)",
    "abs_link": "https://arxiv.org/abs/2507.06803",
    "pdf_link": "https://arxiv.org/pdf/2507.06803",
    "score": 3,
    "abstract": "This paper contributes to speeding up the design and deployment of engineering dynamical systems by proposing a strategy for exploiting domain and expert knowledge for the automated generation of dynamical system computational model starting from a corpus of document relevant to the dynamical system of interest and an input document describing the specific system. This strategy is implemented in five steps and, crucially, it uses system modeling language diagrams (SysML) to extract accurate information about the dependencies, attributes, and operations of components. Natural Language Processing (NLP) strategies and Large Language Models (LLMs) are employed in specific tasks to improve intermediate outputs of the SySML diagrams automated generation, such as: list of key nouns; list of extracted relationships; list of key phrases and key relationships; block attribute values; block relationships; and BDD diagram generation. The applicability of automated SysML diagram generation is illustrated with different case studies. The computational models of complex dynamical systems from SysML diagrams are then obtained via code generation and computational model generation steps. In the code generation step, NLP strategies are used for summarization, while LLMs are used for validation only. The proposed approach is not limited to a specific system, domain, or computational software. The applicability of the proposed approach is shown via an end-to-end example from text to model of a simple pendulum, showing improved performance compared to results yielded by LLMs only.",
    "chinese_title": "通过SysML将文本转化为模型：利用增强的系统建模语言图自动生成动态系统计算模型，基于非结构化自然语言文本",
    "chinese_abstract": "本文致力于通过提出一种利用领域和专家知识，从与感兴趣的动态系统相关的文档语料库和描述特定系统的输入文档中自动生成动态系统计算模型的方法，从而加速工程动态系统的设计和部署。该策略分为五个步骤，关键在于使用系统建模语言图（SysML）提取有关组件的依赖关系、属性和操作的准确信息。自然语言处理（NLP）策略和大型语言模型（LLM）被用于特定任务，以改进SysML图自动生成的中间输出，例如：关键名词列表；提取的关系列表；关键短语和关键关系列表；块属性值；块关系；以及BDD图生成。通过不同的案例研究说明了自动SysML图生成的适用性。通过代码生成和计算模型生成步骤，可以从SysML图中获得复杂动态系统的计算模型。在代码生成步骤中，使用NLP策略进行总结，而LLM仅用于验证。所提出的方法不限于特定的系统、领域或计算软件。通过一个简单的单摆从文本到模型的端到端示例，展示了该方法的适用性，并显示出与仅使用LLM相比，性能有所提高。"
  },
  {
    "id": "arXiv:2507.06795",
    "title": "Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining: Method, Evaluation and Applications",
    "authors": "Seonwu Kim, Yohan Na, Kihun Kim, Hanhee Cho, Geun Lim, Mintae Kim, Seongik Park, Ki Hyun Kim, Youngsub Han, Byoung-Ki Jeon",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06795",
    "pdf_link": "https://arxiv.org/pdf/2507.06795",
    "score": 4,
    "abstract": "The emergence of open-source large language models (LLMs) has expanded opportunities for enterprise applications; however, many organizations still lack the infrastructure to deploy and maintain large-scale models. As a result, small LLMs (sLLMs) have become a practical alternative, despite their inherent performance limitations. While Domain Adaptive Continual Pretraining (DACP) has been previously explored as a method for domain adaptation, its utility in commercial applications remains under-examined. In this study, we validate the effectiveness of applying a DACP-based recipe across diverse foundation models and service domains. Through extensive experiments and real-world evaluations, we demonstrate that DACP-applied sLLMs achieve substantial gains in target domain performance while preserving general capabilities, offering a cost-efficient and scalable solution for enterprise-level deployment.",
    "chinese_title": "通过领域自适应持续预训练提高小规模LLM的效率：方法、评估与应用",
    "chinese_abstract": "开源大型语言模型（LLM）的出现为企业应用带来了机遇；然而，许多组织仍然缺乏部署和维护大规模模型的基础设施。因此，小规模LLM（sLLM）已成为一种实用的替代方案，尽管其本身存在性能限制。虽然领域自适应持续预训练（DACP）已被探索为领域自适应的一种方法，但其在商业应用中的效用仍有待考察。在本研究中，我们验证了在各种基础模型和服务领域应用基于DACP的方案的有效性。通过大量的实验和实际评估，我们证明了应用DACP的sLLM在目标领域性能上取得了显著提升，同时保留了通用能力，为企业级部署提供了一种经济高效且可扩展的解决方案。"
  },
  {
    "id": "arXiv:2507.06782",
    "title": "Temporal Information Retrieval via Time-Specifier Model Merging",
    "authors": "SeungYoon Han, Taeho Hwang, Sukmin Cho, Soyeong Jeong, Hoyun Song, Huije Lee, Jong C. Park",
    "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06782",
    "pdf_link": "https://arxiv.org/pdf/2507.06782",
    "score": 3,
    "abstract": "The rapid expansion of digital information and knowledge across structured and unstructured sources has heightened the importance of Information Retrieval (IR). While dense retrieval methods have substantially improved semantic matching for general queries, they consistently underperform on queries with explicit temporal constraints--often those containing numerical expressions and time specifiers such as ``in 2015.'' Existing approaches to Temporal Information Retrieval (TIR) improve temporal reasoning but often suffer from catastrophic forgetting, leading to reduced performance on non-temporal queries. To address this, we propose Time-Specifier Model Merging (TSM), a novel method that enhances temporal retrieval while preserving accuracy on non-temporal queries. TSM trains specialized retrievers for individual time specifiers and merges them in to a unified model, enabling precise handling of temporal constraints without compromising non-temporal retrieval. Extensive experiments on both temporal and non-temporal datasets demonstrate that TSM significantly improves performance on temporally constrained queries while maintaining strong results on non-temporal queries, consistently outperforming other baseline methods. Our code is available at https://github.com/seungyoonee/TSM .",
    "chinese_title": "通过时间说明符模型合并进行时间信息检索",
    "chinese_abstract": "数字信息和知识的快速扩展，无论是在结构化还是非结构化来源中，都提高了信息检索（IR）的重要性。虽然稠密检索方法大大提高了通用查询的语义匹配，但它们在包含数值表达式和时间说明符（如“2015年”）的显式时间约束查询上始终表现不佳。现有的时间信息检索（TIR）方法提高了时间推理能力，但通常会遭受灾难性遗忘，从而降低了非时间查询的性能。为了解决这个问题，我们提出了时间说明符模型合并（TSM），这是一种新方法，可以在保持非时间查询准确性的同时增强时间检索。TSM为单个时间说明符训练专门的检索器，并将它们合并到一个统一的模型中，从而能够精确处理时间约束，而不会影响非时间检索。在时间和非时间数据集上进行的广泛实验表明，TSM显著提高了对时间约束查询的性能，同时在非时间查询上保持了强大的结果，始终优于其他基线方法。我们的代码可在https://github.com/seungyoonee/TSM 上获得。"
  },
  {
    "id": "arXiv:2507.06738",
    "title": "DIFFUMA: High-Fidelity Spatio-Temporal Video Prediction via Dual-Path Mamba and Diffusion Enhancement",
    "authors": "Xinyu Xie, Weifeng Cao, Jun Shi, Yangyang Hu, Hui Liang, Wanyong Liang, Xiaoliang Qian",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06738",
    "pdf_link": "https://arxiv.org/pdf/2507.06738",
    "score": 4,
    "abstract": "Spatio-temporal video prediction plays a pivotal role in critical domains, ranging from weather forecasting to industrial automation. However, in high-precision industrial scenarios such as semiconductor manufacturing, the absence of specialized benchmark datasets severely hampers research on modeling and predicting complex processes. To address this challenge, we make a twofold contribution.First, we construct and release the Chip Dicing Lane Dataset (CHDL), the first public temporal image dataset dedicated to the semiconductor wafer dicing process. Captured via an industrial-grade vision system, CHDL provides a much-needed and challenging benchmark for high-fidelity process modeling, defect detection, and digital twin development.Second, we propose DIFFUMA, an innovative dual-path prediction architecture specifically designed for such fine-grained dynamics. The model captures global long-range temporal context through a parallel Mamba module, while simultaneously leveraging a diffusion module, guided by temporal features, to restore and enhance fine-grained spatial details, effectively combating feature degradation. Experiments demonstrate that on our CHDL benchmark, DIFFUMA significantly outperforms existing methods, reducing the Mean Squared Error (MSE) by 39% and improving the Structural Similarity (SSIM) from 0.926 to a near-perfect 0.988. This superior performance also generalizes to natural phenomena datasets. Our work not only delivers a new state-of-the-art (SOTA) model but, more importantly, provides the community with an invaluable data resource to drive future research in industrial AI.",
    "chinese_title": "DIFFUMA：通过双路径Mamba和扩散增强实现高保真时空视频预测",
    "chinese_abstract": "时空视频预测在天气预报、工业自动化等关键领域发挥着重要作用。然而，在半导体制造等高精度工业场景中，缺乏专门的基准数据集严重阻碍了复杂过程建模和预测的研究。为了应对这一挑战，我们做出了双重贡献。首先，我们构建并发布了芯片切割车道数据集（CHDL），这是第一个专门用于半导体晶圆切割过程的公共时间图像数据集。通过工业级视觉系统捕获，CHDL为高保真过程建模、缺陷检测和数字孪生开发提供了一个急需且具有挑战性的基准。其次，我们提出了DIFFUMA，这是一种创新的双路径预测架构，专门设计用于此类细粒度动力学。该模型通过并行Mamba模块捕获全局长程时间上下文，同时利用由时间特征引导的扩散模块恢复和增强细粒度空间细节，有效对抗特征退化。实验表明，在我们的CHDL基准上，DIFFUMA显著优于现有方法，均方误差（MSE）降低了39%，结构相似性（SSIM）从0.926提高到接近完美的0.988。这种卓越的性能也推广到自然现象数据集。我们的工作不仅提供了新的最先进（SOTA）模型，更重要的是，为社区提供了一个宝贵的数据资源，以推动工业人工智能的未来研究。"
  },
  {
    "id": "arXiv:2507.06734",
    "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool",
    "authors": "Milena Pustet, Elisabeth Steffen, Helena Mihaljević, Grischa Stanjek, Yannis Illies",
    "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY)",
    "abs_link": "https://arxiv.org/abs/2507.06734",
    "pdf_link": "https://arxiv.org/pdf/2507.06734",
    "score": 3,
    "abstract": "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.",
    "chinese_title": "循环中的公民社会：基于反馈的（L）LM辅助分类在开源Telegram监控工具中的应用",
    "chinese_abstract": "公民社会组织（CSO）在监控有害在线内容方面发挥着越来越重要的作用，尤其是在平台提供商减少对内容审核的投入的情况下。人工智能工具可以帮助大规模检测和监控有害内容。然而，很少有开源工具能够无缝集成人工智能模型和社交媒体监控基础设施。鉴于其主题专业知识和对有害内容的背景理解，CSO应该积极参与技术工具的共同开发，提供反馈，帮助改进模型，并确保与利益相关者的需求和价值观保持一致，而不是作为被动的“消费者”。然而，开源社区、学术界和公民社会之间的合作仍然稀少，有害内容研究很少转化为公民社会行为者可用的实用工具。这项正在进行的工作探讨了CSO如何有意义地参与到我们目前与CSO利益相关者合作开发的Telegram上反民主运动的AI辅助开源监控工具中。"
  },
  {
    "id": "arXiv:2507.06715",
    "title": "CLI-RAG: A Retrieval-Augmented Framework for Clinically Structured and Context Aware Text Generation with LLMs",
    "authors": "Garapati Keerthana, Manik Gupta",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)",
    "abs_link": "https://arxiv.org/abs/2507.06715",
    "pdf_link": "https://arxiv.org/pdf/2507.06715",
    "score": 4,
    "abstract": "Large language models (LLMs), including zero-shot and few-shot paradigms, have shown promising capabilities in clinical text generation. However, real-world applications face two key challenges: (1) patient data is highly unstructured, heterogeneous, and scattered across multiple note types and (2) clinical notes are often long and semantically dense, making naive prompting infeasible due to context length constraints and the risk of omitting clinically relevant information.   We introduce CLI-RAG (Clinically Informed Retrieval-Augmented Generation), a domain-specific framework for structured and clinically grounded text generation using LLMs. It incorporates a novel hierarchical chunking strategy that respects clinical document structure and introduces a task-specific dual-stage retrieval mechanism. The global stage identifies relevant note types using evidence-based queries, while the local stage extracts high-value content within those notes creating relevance at both document and section levels.   We apply the system to generate structured progress notes for individual hospital visits using 15 clinical note types from the MIMIC-III dataset. Experiments show that it preserves temporal and semantic alignment across visits, achieving an average alignment score of 87.7%, surpassing the 80.7% baseline from real clinician-authored notes. The generated outputs also demonstrate high consistency across LLMs, reinforcing deterministic behavior essential for reproducibility, reliability, and clinical trust.",
    "chinese_title": "CLI-RAG：用于临床结构化和上下文感知文本生成的检索增强框架",
    "chinese_abstract": "大型语言模型（LLM），包括零样本和少样本范式，在临床文本生成方面表现出令人鼓舞的能力。然而，实际应用面临两个主要挑战：（1）患者数据高度非结构化、异构化，并且分散在多种笔记类型中；（2）临床笔记通常很长且语义密集，使得朴素的提示不可行，因为存在上下文长度限制以及遗漏临床相关信息的风险。我们引入CLI-RAG（临床信息检索增强生成），这是一个特定领域的框架，用于使用LLM进行结构化和临床基础的文本生成。它结合了一种新颖的分层分块策略，该策略尊重临床文档结构，并引入了一种特定于任务的双阶段检索机制。全局阶段使用基于证据的查询识别相关的笔记类型，而局部阶段提取这些笔记中的高价值内容，从而在文档和章节级别创建相关性。我们将该系统应用于使用来自MIMIC-III数据集的15种临床笔记类型生成单个住院就诊的结构化进展记录。实验表明，它保留了就诊之间的时序和语义对齐，平均对齐得分为87.7%，超过了真实临床医生撰写的笔记的80.7%基线。生成的输出还展示了跨LLM的高度一致性，强化了再现性、可靠性和临床信任所必需的确定性行为。"
  },
  {
    "id": "arXiv:2507.06684",
    "title": "Photometric Stereo using Gaussian Splatting and inverse rendering",
    "authors": "Matéo Ducastel, David Tschumperlé, Yvain Quéau",
    "subjects": "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06684",
    "pdf_link": "https://arxiv.org/pdf/2507.06684",
    "score": 5,
    "abstract": "Recent state-of-the-art algorithms in photometric stereo rely on neural networks and operate either through prior learning or inverse rendering optimization. Here, we revisit the problem of calibrated photometric stereo by leveraging recent advances in 3D inverse rendering using the Gaussian Splatting formalism. This allows us to parameterize the 3D scene to be reconstructed and optimize it in a more interpretable manner. Our approach incorporates a simplified model for light representation and demonstrates the potential of the Gaussian Splatting rendering engine for the photometric stereo problem.",
    "chinese_title": "基于高斯飞溅和逆渲染的光度立体视觉",
    "chinese_abstract": "最近最先进的光度立体视觉算法依赖于神经网络，并通过先验学习或逆渲染优化进行操作。在这里，我们利用高斯飞溅形式中的 3D 逆渲染的最新进展，重新审视校准的光度立体视觉问题。这使我们能够参数化要重建的 3D 场景，并以更可解释的方式对其进行优化。我们的方法结合了简化的光照模型，并展示了高斯飞溅渲染引擎在光度立体视觉问题中的潜力。"
  },
  {
    "id": "arXiv:2507.06674",
    "title": "Exploring State-Space-Model based Language Model in Music Generation",
    "authors": "Wei-Jaw Lee, Fang-Chih Hsieh, Xuanjun Chen, Fang-Duo Tsai, Yi-Hsuan Yang",
    "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.06674",
    "pdf_link": "https://arxiv.org/pdf/2507.06674",
    "score": 4,
    "abstract": "The recent surge in State Space Models (SSMs), particularly the emergence of Mamba, has established them as strong alternatives or complementary modules to Transformers across diverse domains. In this work, we aim to explore the potential of Mamba-based architectures for text-to-music generation. We adopt discrete tokens of Residual Vector Quantization (RVQ) as the modeling representation and empirically find that a single-layer codebook can capture semantic information in music. Motivated by this observation, we focus on modeling a single-codebook representation and adapt SiMBA, originally designed as a Mamba-based encoder, to function as a decoder for sequence modeling. We compare its performance against a standard Transformer-based decoder. Our results suggest that, under limited-resource settings, SiMBA achieves much faster convergence and generates outputs closer to the ground truth. This demonstrates the promise of SSMs for efficient and expressive text-to-music generation. We put audio examples on Github.",
    "chinese_title": "探索基于状态空间模型的语言模型在音乐生成中的应用",
    "chinese_abstract": "近期，状态空间模型 (SSM)，特别是 Mamba 的出现，已使其成为 Transformer 在各个领域中的强大替代方案或补充模块。在这项工作中，我们旨在探索基于 Mamba 的架构在文本到音乐生成中的潜力。我们采用残差向量量化 (RVQ) 的离散标记作为建模表示，并通过实验发现，单个码本可以捕捉音乐中的语义信息。受到这一观察的启发，我们专注于建模单个码本表示，并调整最初设计为 Mamba 编码器的 SiMBA，使其充当序列建模的解码器。我们将它的性能与标准的基于 Transformer 的解码器进行比较。我们的结果表明，在资源有限的情况下，SiMBA 实现了更快的收敛速度，并生成了更接近真实值的输出。这证明了 SSM 在高效且富有表现力的文本到音乐生成方面的潜力。我们已将音频示例放在 Github 上。"
  },
  {
    "id": "arXiv:2507.06654",
    "title": "MS-DPPs: Multi-Source Determinantal Point Processes for Contextual Diversity Refinement of Composite Attributes in Text to Image Retrieval",
    "authors": "Naoya Sogi, Takashi Shibata, Makoto Terao, Masanori Suganuma, Takayuki Okatani",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)",
    "abs_link": "https://arxiv.org/abs/2507.06654",
    "pdf_link": "https://arxiv.org/pdf/2507.06654",
    "score": 3,
    "abstract": "Result diversification (RD) is a crucial technique in Text-to-Image Retrieval for enhancing the efficiency of a practical application. Conventional methods focus solely on increasing the diversity metric of image appearances. However, the diversity metric and its desired value vary depending on the application, which limits the applications of RD. This paper proposes a novel task called CDR-CA (Contextual Diversity Refinement of Composite Attributes). CDR-CA aims to refine the diversities of multiple attributes, according to the application's context. To address this task, we propose Multi-Source DPPs, a simple yet strong baseline that extends the Determinantal Point Process (DPP) to multi-sources. We model MS-DPP as a single DPP model with a unified similarity matrix based on a manifold representation. We also introduce Tangent Normalization to reflect contexts. Extensive experiments demonstrate the effectiveness of the proposed method. Our code is publicly available at https://github.com/NEC-N-SOGI/msdpp.",
    "chinese_title": "MS-DPP：用于文本到图像检索中复合属性上下文多样性细化的多源行列式点过程",
    "chinese_abstract": "结果多样化 (RD) 是文本到图像检索中增强实际应用效率的关键技术。传统方法仅侧重于提高图像外观的多样性指标。然而，多样性指标及其期望值因应用而异，这限制了 RD 的应用。本文提出了一种新的任务，称为 CDR-CA（复合属性的上下文多样性细化）。CDR-CA 旨在根据应用上下文细化多个属性的多样性。为了解决这项任务，我们提出了多源 DPP，这是一种简单但强大的基线，它将行列式点过程 (DPP) 扩展到多源。我们将 MS-DPP 建模为具有基于流形表示的统一相似度矩阵的单个 DPP 模型。我们还引入了切线归一化来反映上下文。大量的实验证明了所提出方法的有效性。我们的代码已在 https://github.com/NEC-N-SOGI/msdpp 上公开提供。"
  },
  {
    "id": "arXiv:2507.06639",
    "title": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision",
    "authors": "Myungjang Pyeon, Janghyeon Lee, Minsoo Lee, Juseung Yun, Hwanil Choi, Jonghyun Kim, Jiwon Kim, Yi Hu, Jongseong Jang, Soonyoung Lee",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06639",
    "pdf_link": "https://arxiv.org/pdf/2507.06639",
    "score": 3,
    "abstract": "In digital pathology, whole-slide images (WSIs) are often difficult to handle due to their gigapixel scale, so most approaches train patch encoders via self-supervised learning (SSL) and then aggregate the patch-level embeddings via multiple instance learning (MIL) or slide encoders for downstream tasks. However, patch-level SSL may overlook complex domain-specific features that are essential for biomarker prediction, such as mutation status and molecular characteristics, as SSL methods rely only on basic augmentations selected for natural image domains on small patch-level area. Moreover, SSL methods remain less data efficient than fully supervised approaches, requiring extensive computational resources and datasets to achieve competitive performance. To address these limitations, we present EXAONE Path 2.0, a pathology foundation model that learns patch-level representations under direct slide-level supervision. Using only 37k WSIs for training, EXAONE Path 2.0 achieves state-of-the-art average performance across 10 biomarker prediction tasks, demonstrating remarkable data efficiency.",
    "chinese_title": "EXAONE Path 2.0：端到端监督的病理基础模型",
    "chinese_abstract": "在数字病理学中，全玻片图像（WSIs）由于其千兆像素的规模而难以处理，因此大多数方法通过自监督学习（SSL）训练补丁编码器，然后通过多实例学习（MIL）或玻片编码器聚合补丁级别的嵌入以用于下游任务。然而，补丁级别的SSL可能会忽略对生物标志物预测至关重要的复杂领域特定特征，例如突变状态和分子特征，因为SSL方法仅依赖于为自然图像领域的小补丁级别区域选择的基本增强。此外，SSL方法的数据效率仍然低于完全监督方法，需要大量的计算资源和数据集才能达到具有竞争力的性能。为了解决这些限制，我们提出了EXAONE Path 2.0，这是一种在直接玻片级别监督下学习补丁级别表示的病理基础模型。仅使用3.7万张WSIs进行训练，EXAONE Path 2.0在10项生物标志物预测任务中实现了最先进的平均性能，展示了卓越的数据效率。"
  },
  {
    "id": "arXiv:2507.06628",
    "title": "Goal-Oriented Skill Abstraction for Offline Multi-Task Reinforcement Learning",
    "authors": "Jinmin He, Kai Li, Yifan Zang, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06628",
    "pdf_link": "https://arxiv.org/pdf/2507.06628",
    "score": 4,
    "abstract": "Offline multi-task reinforcement learning aims to learn a unified policy capable of solving multiple tasks using only pre-collected task-mixed datasets, without requiring any online interaction with the environment. However, it faces significant challenges in effectively sharing knowledge across tasks. Inspired by the efficient knowledge abstraction observed in human learning, we propose Goal-Oriented Skill Abstraction (GO-Skill), a novel approach designed to extract and utilize reusable skills to enhance knowledge transfer and task performance. Our approach uncovers reusable skills through a goal-oriented skill extraction process and leverages vector quantization to construct a discrete skill library. To mitigate class imbalances between broadly applicable and task-specific skills, we introduce a skill enhancement phase to refine the extracted skills. Furthermore, we integrate these skills using hierarchical policy learning, enabling the construction of a high-level policy that dynamically orchestrates discrete skills to accomplish specific tasks. Extensive experiments on diverse robotic manipulation tasks within the MetaWorld benchmark demonstrate the effectiveness and versatility of GO-Skill.",
    "chinese_title": "面向目标的技能抽象：用于离线多任务强化学习",
    "chinese_abstract": "离线多任务强化学习旨在学习一个统一的策略，能够仅使用预先收集的任务混合数据集解决多个任务，而无需与环境进行任何在线交互。然而，它在有效共享跨任务知识方面面临着重大挑战。受人类学习中高效知识抽象的启发，我们提出了一种名为Goal-Oriented Skill Abstraction (GO-Skill) 的新方法，旨在提取和利用可重用的技能来增强知识迁移和任务性能。我们的方法通过面向目标的技能提取过程发现可重用的技能，并利用向量量化构建离散技能库。为了减轻广泛适用的技能和特定任务技能之间的类别不平衡，我们引入了一个技能增强阶段来完善提取的技能。此外，我们使用分层策略学习集成这些技能，从而构建一个能够动态协调离散技能以完成特定任务的高级策略。在 MetaWorld 基准测试中各种机器人操作任务上进行的广泛实验证明了 GO-Skill 的有效性和多功能性。"
  },
  {
    "id": "arXiv:2507.06625",
    "title": "Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic",
    "authors": "Shizhe Cai, Jayadeep Jacob, Zeya Yin, Fabio Ramos",
    "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06625",
    "pdf_link": "https://arxiv.org/pdf/2507.06625",
    "score": 4,
    "abstract": "Deep reinforcement learning has shown remarkable success in continuous control tasks, yet often requires extensive training data, struggles with complex, long-horizon planning, and fails to maintain safety constraints during operation. Meanwhile, Model Predictive Control (MPC) offers explainability and constraint satisfaction, but typically yields only locally optimal solutions and demands careful cost function design. This paper introduces the Q-guided STein variational model predictive Actor-Critic (Q-STAC), a novel framework that bridges these approaches by integrating Bayesian MPC with actor-critic reinforcement learning through constrained Stein Variational Gradient Descent (SVGD). Our method optimizes control sequences directly using learned Q-values as objectives, eliminating the need for explicit cost function design while leveraging known system dynamics to enhance sample efficiency and ensure control signals remain within safe boundaries. Extensive experiments on 2D navigation and robotic manipulation tasks demonstrate that Q-STAC achieves superior sample efficiency, robustness, and optimality compared to state-of-the-art algorithms, while maintaining the high expressiveness of policy distributions. Experiment videos are available on our website: https://sites.google.com/view/q-stac",
    "chinese_title": "Q-STAC：Q引导的斯坦因变分模型预测演员-评论家",
    "chinese_abstract": "深度强化学习在连续控制任务中取得了显著的成功，但通常需要大量的训练数据，难以处理复杂的长时序规划，并且在运行过程中难以维持安全约束。与此同时，模型预测控制（MPC）提供了可解释性和约束满足性，但通常只能产生局部最优解，并且需要仔细设计成本函数。本文介绍了一种名为Q引导的斯坦因变分模型预测演员-评论家（Q-STAC）的新框架，它通过约束斯坦因变分梯度下降（SVGD）将贝叶斯MPC与演员-评论家强化学习相结合，从而弥合了这两种方法之间的差距。我们的方法直接使用学习到的Q值作为目标来优化控制序列，无需显式设计成本函数，同时利用已知的系统动力学来提高样本效率并确保控制信号保持在安全范围内。在2D导航和机器人操作任务上的大量实验表明，与最先进的算法相比，Q-STAC实现了更高的样本效率、鲁棒性和最优性，同时保持了策略分布的高表达能力。实验视频可在我们的网站上找到：https://sites.google.com/view/q-stac"
  },
  {
    "id": "arXiv:2507.06623",
    "title": "Expediting data extraction using a large language model (LLM) and scoping review protocol: a methodological study within a complex scoping review",
    "authors": "James Stewart-Evans, Emma Wilson, Tessa Langley, Andrew Prayle, Angela Hands, Karen Exley, Jo Leonardi-Bee",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06623",
    "pdf_link": "https://arxiv.org/pdf/2507.06623",
    "score": 3,
    "abstract": "The data extraction stages of reviews are resource-intensive, and researchers may seek to expediate data extraction using online (large language models) LLMs and review protocols. Claude 3.5 Sonnet was used to trial two approaches that used a review protocol to prompt data extraction from 10 evidence sources included in a case study scoping review. A protocol-based approach was also used to review extracted data. Limited performance evaluation was undertaken which found high accuracy for the two extraction approaches (83.3% and 100%) when extracting simple, well-defined citation details; accuracy was lower (9.6% and 15.8%) when extracting more complex, subjective data items. Considering all data items, both approaches had precision >90% but low recall (<25%) and F1 scores (<40%). The context of a complex scoping review, open response types and methodological approach likely impacted performance due to missed and misattributed data. LLM feedback considered the baseline extraction accurate and suggested minor amendments: four of 15 (26.7%) to citation details and 8 of 38 (21.1%) to key findings data items were considered to potentially add value. However, when repeating the process with a dataset featuring deliberate errors, only 2 of 39 (5%) errors were detected. Review-protocol-based methods used for expediency require more robust performance evaluation across a range of LLMs and review contexts with comparison to conventional prompt engineering approaches. We recommend researchers evaluate and report LLM performance if using them similarly to conduct data extraction or review extracted data. LLM feedback contributed to protocol adaptation and may assist future review protocol drafting.",
    "chinese_title": "利用大型语言模型（LLM）和范围界定审查协议加速数据提取：一项复杂范围界定审查中的方法学研究",
    "chinese_abstract": "审查的数据提取阶段耗费资源，研究人员可能会寻求使用在线（大型语言模型）LLM和审查协议来加速数据提取。我们使用Claude 3.5 Sonnet试用了两种方法，这些方法使用审查协议来提示从包含在一个案例研究范围界定审查中的10个证据来源中提取数据。基于协议的方法也被用于审查提取的数据。进行了有限的性能评估，发现对于提取简单、明确的引用细节，两种提取方法的准确率很高（分别为83.3%和100%）；对于提取更复杂、主观的数据项，准确率较低（分别为9.6%和15.8%）。考虑到所有数据项，两种方法都具有超过90%的精确率，但召回率较低（低于25%），F1分数较低（低于40%）。复杂范围界定审查的背景、开放式响应类型和方法学方法可能由于遗漏和错误归因的数据而影响性能。LLM反馈认为基线提取准确，并建议进行小的修改：四分之一的15个（26.7%）引用细节和8分之一的38个（21.1%）关键发现数据项被认为可能具有附加价值。然而，当使用包含故意错误的数据集重复该过程时，仅检测到39个错误中的2个（5%）。用于加速的基于审查协议的方法需要在各种LLM和审查背景下进行更可靠的性能评估，并与传统的提示工程方法进行比较。我们建议研究人员评估并报告LLM性能，如果他们以类似的方式使用LLM进行数据提取或审查提取的数据，则应这样做。LLM反馈有助于协议调整，并可能协助未来的审查协议起草。"
  },
  {
    "id": "arXiv:2507.06615",
    "title": "Efficient Multi-Task Reinforcement Learning with Cross-Task Policy Guidance",
    "authors": "Jinmin He, Kai Li, Yifan Zang, Haobo Fu, Qiang Fu, Junliang Xing, Jian Cheng",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06615",
    "pdf_link": "https://arxiv.org/pdf/2507.06615",
    "score": 4,
    "abstract": "Multi-task reinforcement learning endeavors to efficiently leverage shared information across various tasks, facilitating the simultaneous learning of multiple tasks. Existing approaches primarily focus on parameter sharing with carefully designed network structures or tailored optimization procedures. However, they overlook a direct and complementary way to exploit cross-task similarities: the control policies of tasks already proficient in some skills can provide explicit guidance for unmastered tasks to accelerate skills acquisition. To this end, we present a novel framework called Cross-Task Policy Guidance (CTPG), which trains a guide policy for each task to select the behavior policy interacting with the environment from all tasks' control policies, generating better training trajectories. In addition, we propose two gating mechanisms to improve the learning efficiency of CTPG: one gate filters out control policies that are not beneficial for guidance, while the other gate blocks tasks that do not necessitate guidance. CTPG is a general framework adaptable to existing parameter sharing approaches. Empirical evaluations demonstrate that incorporating CTPG with these approaches significantly enhances performance in manipulation and locomotion benchmarks.",
    "chinese_title": "基于跨任务策略引导的高效多任务强化学习",
    "chinese_abstract": "多任务强化学习致力于高效利用跨任务的共享信息，从而同时学习多个任务。现有的方法主要集中在具有精心设计的网络结构或定制优化程序的参数共享上。然而，它们忽略了一种直接且互补的方式来利用跨任务的相似性：已经熟练掌握某些技能的任务的控制策略可以为未掌握的任务提供明确的指导，从而加速技能获取。为此，我们提出了一种新框架，称为跨任务策略引导（CTPG），该框架为每个任务训练一个引导策略，从所有任务的控制策略中选择与环境交互的行为策略，从而生成更好的训练轨迹。此外，我们提出了两种门控机制来提高CTPG的学习效率：一种门控机制过滤掉对指导无益的控制策略，而另一种门控机制阻止不需要指导的任务。CTPG是一个通用的框架，可以适应现有的参数共享方法。经验评估表明，将CTPG与这些方法结合可以显着提高操纵和运动基准测试的性能。"
  },
  {
    "id": "arXiv:2507.06613",
    "title": "Denoising Multi-Beta VAE: Representation Learning for Disentanglement and Generation",
    "authors": "Anshuk Uppal, Yuhta Takida, Chieh-Hsin Lai, Yuki Mitsufuji",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.06613",
    "pdf_link": "https://arxiv.org/pdf/2507.06613",
    "score": 4,
    "abstract": "Disentangled and interpretable latent representations in generative models typically come at the cost of generation quality. The $\\beta$-VAE framework introduces a hyperparameter $\\beta$ to balance disentanglement and reconstruction quality, where setting $\\beta > 1$ introduces an information bottleneck that favors disentanglement over sharp, accurate reconstructions. To address this trade-off, we propose a novel generative modeling framework that leverages a range of $\\beta$ values to learn multiple corresponding latent representations. First, we obtain a slew of representations by training a single variational autoencoder (VAE), with a new loss function that controls the information retained in each latent representation such that the higher $\\beta$ value prioritize disentanglement over reconstruction fidelity. We then, introduce a non-linear diffusion model that smoothly transitions latent representations corresponding to different $\\beta$ values. This model denoises towards less disentangled and more informative representations, ultimately leading to (almost) lossless representations, enabling sharp reconstructions. Furthermore, our model supports sample generation without input images, functioning as a standalone generative model. We evaluate our framework in terms of both disentanglement and generation quality. Additionally, we observe smooth transitions in the latent spaces with respect to changes in $\\beta$, facilitating consistent manipulation of generated outputs.",
    "chinese_title": "去噪多 Beta VAE：用于解纠缠和生成的表征学习",
    "chinese_abstract": "生成模型中解纠缠且可解释的潜在表征通常以牺牲生成质量为代价。β-VAE 框架引入了一个超参数 β 来平衡解纠缠和重建质量，其中设置 β > 1 会引入信息瓶颈，从而优先考虑解纠缠而非清晰、准确的重建。为了解决这种权衡，我们提出了一种新颖的生成建模框架，该框架利用一系列 β 值来学习多个相应的潜在表征。首先，我们通过训练单个变分自动编码器 (VAE) 来获得一系列表征，并使用一种新的损失函数来控制每个潜在表征中保留的信息，使得更高的 β 值优先考虑解纠缠而非重建保真度。然后，我们引入一个非线性扩散模型，该模型可以平滑地过渡到对应于不同 β 值的潜在表征。该模型去噪到更少解纠缠且更具信息量的表征，最终实现（几乎）无损的表征，从而实现清晰的重建。此外，我们的模型支持在没有输入图像的情况下进行样本生成，充当独立的生成模型。我们在解纠缠和生成质量方面评估我们的框架。此外，我们观察到潜在空间中关于 β 变化的平滑过渡，从而可以一致地操纵生成的输出。"
  },
  {
    "id": "arXiv:2507.06582",
    "title": "Learning controllable dynamics through informative exploration",
    "authors": "Peter N. Loxley, Friedrich T. Sommer",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06582",
    "pdf_link": "https://arxiv.org/pdf/2507.06582",
    "score": 4,
    "abstract": "Environments with controllable dynamics are usually understood in terms of explicit models. However, such models are not always available, but may sometimes be learned by exploring an environment. In this work, we investigate using an information measure called \"predicted information gain\" to determine the most informative regions of an environment to explore next. Applying methods from reinforcement learning allows good suboptimal exploring policies to be found, and leads to reliable estimates of the underlying controllable dynamics. This approach is demonstrated by comparing with several myopic exploration approaches.",
    "chinese_title": "通过信息性探索学习可控动力学",
    "chinese_abstract": "具有可控动力学的环境通常通过显式模型来理解。然而，这样的模型并非总是可用，但有时可以通过探索环境来学习。在这项工作中，我们研究使用一种称为“预测信息增益”的信息度量来确定下一步探索环境中信息量最大的区域。应用强化学习方法可以找到良好的次优探索策略，并可靠地估计潜在的可控动力学。通过与几种目光短浅的探索方法进行比较，证明了这种方法的有效性。"
  },
  {
    "id": "arXiv:2507.06573",
    "title": "From Data-Centric to Sample-Centric: Enhancing LLM Reasoning via Progressive Optimization",
    "authors": "Xinjie Chen, Minpeng Liao, Guoxin Chen, Chengxi Li, Biao Fu, Kai Fan, Xinggao Liu",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06573",
    "pdf_link": "https://arxiv.org/pdf/2507.06573",
    "score": 4,
    "abstract": "Reinforcement learning with verifiable rewards (RLVR) has recently advanced the reasoning capabilities of large language models (LLMs). While prior work has emphasized algorithmic design, data curation, and reward shaping, we investigate RLVR from a sample-centric perspective and introduce LPPO (Learning-Progress and Prefix-guided Optimization), a framework of progressive optimization techniques. Our work addresses a critical question: how to best leverage a small set of trusted, high-quality demonstrations, rather than simply scaling up data volume. First, motivated by how hints aid human problem-solving, we propose prefix-guided sampling, an online data augmentation method that incorporates partial solution prefixes from expert demonstrations to guide the policy, particularly for challenging instances. Second, inspired by how humans focus on important questions aligned with their current capabilities, we introduce learning-progress weighting, a dynamic strategy that adjusts each training sample's influence based on model progression. We estimate sample-level learning progress via an exponential moving average of per-sample pass rates, promoting samples that foster learning and de-emphasizing stagnant ones. Experiments on mathematical-reasoning benchmarks demonstrate that our methods outperform strong baselines, yielding faster convergence and a higher performance ceiling.",
    "chinese_title": "从数据中心到样本中心：通过渐进优化增强LLM推理能力",
    "chinese_abstract": "基于可验证奖励的强化学习 (RLVR) 近期提升了大型语言模型 (LLM) 的推理能力。虽然先前的工作强调算法设计、数据策化和奖励塑造，但我们从样本中心视角研究 RLVR，并引入 LPPO（学习进度与前缀引导优化），一种渐进优化技术框架。我们的工作解决了关键问题：如何最好地利用少量可信、高质量的演示数据，而不是简单地扩大数据量。首先，受启发于提示如何帮助人类解决问题，我们提出前缀引导采样，一种在线数据增强方法，它将专家演示中的部分解决方案前缀融入策略中，尤其是在具有挑战性的实例中。其次，受启发于人类如何专注于与其当前能力相符的重要问题，我们引入学习进度加权，一种动态策略，它根据模型进展调整每个训练样本的影响力。我们通过样本通过率的指数移动平均来估计样本层面的学习进度，从而促进学习的样本，并弱化停滞的样本。在数学推理基准上的实验表明，我们的方法优于强大的基线，实现了更快的收敛速度和更高的性能上限。"
  },
  {
    "id": "arXiv:2507.06564",
    "title": "SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments",
    "authors": "Tianshun Li, Tianyi Huai, Zhen Li, Yichun Gao, Haoang Li, Xinhu Zheng",
    "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI); Systems and Control (eess.SY)",
    "abs_link": "https://arxiv.org/abs/2507.06564",
    "pdf_link": "https://arxiv.org/pdf/2507.06564",
    "score": 4,
    "abstract": "Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.",
    "chinese_title": "SkyVLN：城市环境中无人机视觉-语言导航与非线性模型预测控制",
    "chinese_abstract": "无人机 (UAV) 因其移动性和适应性而在各个领域成为多功能工具。本文介绍 SkyVLN，这是一种新颖的框架，它将视觉-语言导航 (VLN) 与非线性模型预测控制 (NMPC) 相结合，以增强无人机在复杂城市环境中的自主性。与传统导航方法不同，SkyVLN 利用大型语言模型 (LLM) 来解释自然语言指令和视觉观察，使无人机能够以更高的准确性和鲁棒性在动态 3D 空间中导航。我们提出了一种配备了细粒度空间语言化器和历史路径记忆机制的多模态导航代理。这些组件允许无人机消除空间上下文的歧义，处理含糊的指令，并在必要时回溯。该框架还集成了 NMPC 模块，用于动态避障，确保精确的轨迹跟踪和碰撞预防。为了验证我们的方法，我们使用 AirSim 开发了一个高保真度的 3D 城市模拟环境，该环境具有逼真的图像和动态城市元素。大量的实验表明，SkyVLN 显著提高了导航成功率和效率，尤其是在新的和未知的环境中。"
  },
  {
    "id": "arXiv:2507.06558",
    "title": "The Primacy of Magnitude in Low-Rank Adaptation",
    "authors": "Zicheng Zhang, Haoran Li, Yifeng Zhang, Guoqiang Gong, Jiaxing Wang, Pengzhang Liu, Qixia Jiang, Junxing Hu",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06558",
    "pdf_link": "https://arxiv.org/pdf/2507.06558",
    "score": 4,
    "abstract": "Low-Rank Adaptation (LoRA) offers a parameter-efficient paradigm for tuning large models. While recent spectral initialization methods improve convergence and performance over the naive \"Noise & Zeros\" scheme, their extra computational and storage overhead undermines efficiency. In this paper, we establish update magnitude as the fundamental driver of LoRA performance and propose LoRAM, a magnitude-driven \"Basis & Basis\" initialization scheme that matches spectral methods without their inefficiencies. Our key contributions are threefold: (i) Magnitude of weight updates determines convergence. We prove low-rank structures intrinsically bound update magnitudes, unifying hyperparameter tuning in learning rate, scaling factor, and initialization as mechanisms to optimize magnitude regulation. (ii) Spectral initialization succeeds via magnitude amplification. We demystify that the presumed knowledge-driven benefit of the spectral component essentially arises from the boost in the weight update magnitude. (iii) A novel and compact initialization strategy, LoRAM, scales deterministic orthogonal bases using pretrained weight magnitudes to simulate spectral gains. Extensive experiments show that LoRAM serves as a strong baseline, retaining the full efficiency of LoRA while matching or outperforming spectral initialization across benchmarks.",
    "chinese_title": "低秩适应中的幅度优先性",
    "chinese_abstract": "低秩适应 (LoRA) 提供了一种参数高效的范式来微调大型模型。虽然最近的谱初始化方法比朴素的“噪声与零”方案提高了收敛性和性能，但其额外的计算和存储开销损害了效率。在本文中，我们确立了更新幅度是 LoRA 性能的基本驱动因素，并提出了 LoRAM，一种由幅度驱动的“基与基”初始化方案，它匹配了谱方法，而没有它们的低效性。我们的主要贡献包括三方面：(i) 权重更新的幅度决定了收敛性。我们证明低秩结构本质上约束了更新幅度，将学习率、缩放因子和初始化中的超参数调整统一为优化幅度调节的机制。(ii) 谱初始化通过幅度放大成功。我们揭示了假定的知识驱动的谱分量的益处实际上源于权重更新幅度的提升。(iii) 一种新颖紧凑的初始化策略 LoRAM，使用预训练权重幅度来缩放确定性正交基，以模拟谱增益。大量的实验表明，LoRAM 作为一个强大的基线，保留了 LoRA 的完全效率，同时在基准测试中匹配或优于谱初始化。"
  },
  {
    "id": "arXiv:2507.06528",
    "title": "InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior",
    "authors": "Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06528",
    "pdf_link": "https://arxiv.org/pdf/2507.06528",
    "score": 4,
    "abstract": "Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.",
    "chinese_title": "InvestAlign：克服大型语言模型在群体行为下与投资者决策过程对齐的数据稀缺性",
    "chinese_abstract": "将大型语言模型（LLM）与投资者在群体行为下的决策过程对齐，是行为金融学中的一个关键挑战，该领域面临一个根本性的限制：用于监督微调（SFT）的真实用户数据的稀缺性。虽然SFT可以弥合LLM输出与人类行为模式之间的差距，但其对大量真实数据的依赖带来了巨大的收集成本和隐私风险。我们提出InvestAlign，一种新颖的框架，它通过利用与简单和最优投资问题相关的理论解决方案，而不是复杂场景，来构建高质量的SFT数据集。我们的理论分析表明，使用InvestAlign生成的数据训练LLM比使用真实用户数据实现更快的参数收敛，表明具有更高的学习效率。此外，我们开发了InvestAgent，一个使用InvestAlign微调的LLM智能体，它在简单和复杂的投资问题中都表现出比预SFT模型更接近真实用户数据的对齐程度。这突出了我们提出的InvestAlign作为一种有希望的方法，具有解决复杂的最优投资问题并使LLM与投资者在群体行为下的决策过程对齐的潜力。我们的代码已在https://github.com/thu-social-network-research-group/InvestAlign上公开。"
  },
  {
    "id": "arXiv:2507.06520",
    "title": "Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration",
    "authors": "Xinyuan Song, Zeyu Wang, Siyi Wu, Tianyu Shi, Lynn Ai",
    "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06520",
    "pdf_link": "https://arxiv.org/pdf/2507.06520",
    "score": 4,
    "abstract": "We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.",
    "chinese_title": "Gradientsys：一种基于ReAct编排的多智能体LLM调度器",
    "chinese_abstract": "我们提出了Gradientsys，这是一种下一代多智能体调度框架，它使用类型化的模型-上下文协议（MCP）和基于ReAct的动态规划循环来协调各种专门的人工智能智能体。Gradientsys的核心采用LLM驱动的调度器进行智能的一对多任务分派，能够并行执行异构智能体，例如PDF解析器、网络搜索模块、GUI控制器和网页构建器。该框架支持混合同步/异步执行，尊重智能体容量约束，并结合了强大的重试和重新规划机制来优雅地处理故障。为了提高透明度和信任度，Gradientsys包含一个可观察性层，通过服务器发送事件（SSE）实时流式传输智能体活动和中间推理。我们提供了架构概述，并从可扩展性、调度拓扑、工具可重用性、并行性和可观察性等方面评估Gradientsys与现有框架的对比。在GAIA通用助手基准测试上的实验表明，与MinionS风格的基线相比，Gradientsys实现了更高的任务成功率，同时降低了延迟和API成本，证明了其LLM驱动的多智能体编排的优势。"
  },
  {
    "id": "arXiv:2507.06519",
    "title": "Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies",
    "authors": "Yuhan Liu, Xinyu Zhang, Haonan Chang, Abdeslam Boularias",
    "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06519",
    "pdf_link": "https://arxiv.org/pdf/2507.06519",
    "score": 4,
    "abstract": "This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where a robot must repeatedly perform high-precision insertions, such as screwing a nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving millimeter-level accuracy and maintaining consistent performance over multiple repetitions, particularly when factors like nut rotation and friction introduce additional complexity. We propose a sim-to-real framework that integrates a reinforcement learning-based insertion policy with a failure forecasting module. By representing the wrench's pose in the nut's coordinate frame rather than the robot's frame, our approach significantly enhances sim-to-real transferability. The insertion policy, trained in simulation, leverages real-time 6D pose tracking to execute precise alignment, insertion, and rotation maneuvers. Simultaneously, a neural network predicts potential execution failures, triggering a simple recovery mechanism that lifts the wrench and retries the insertion. Extensive experiments in both simulated and real-world environments demonstrate that our method not only achieves a high one-time success rate but also robustly maintains performance over long-horizon repetitive tasks.",
    "chinese_title": "故障预测提升了真实环境下的节奏性插入策略的鲁棒性",
    "chinese_abstract": "本文解决了节奏性插入任务（RIT）的挑战，在这种任务中，机器人必须重复执行高精度插入操作，例如用扳手拧紧螺母。RIT 的固有困难在于实现毫米级的精度，并在多次重复中保持一致的性能，尤其是在螺母旋转和摩擦等因素引入额外复杂性时。我们提出了一种将基于强化学习的插入策略与故障预测模块集成的模拟到真实环境框架。通过用螺母坐标系而不是机器人坐标系表示扳手的姿态，我们的方法显著提高了模拟到真实环境的可迁移性。在模拟中训练的插入策略利用实时 6D 姿态跟踪来执行精确的对齐、插入和旋转操作。同时，神经网络预测潜在的执行失败，触发一个简单的恢复机制，该机制会抬起扳手并重试插入。在模拟和真实环境中的大量实验表明，我们的方法不仅实现了高的一次性成功率，而且能够稳健地保持长时间重复任务的性能。"
  },
  {
    "id": "arXiv:2507.06512",
    "title": "Towards LLM-based Root Cause Analysis of Hardware Design Failures",
    "authors": "Siyu Qiu, Muzhi Wang, Raheel Afsharmazayejani, Mohammad Moradi Shahmiri, Benjamin Tan, Hammond Pearce",
    "subjects": "Hardware Architecture (cs.AR); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06512",
    "pdf_link": "https://arxiv.org/pdf/2507.06512",
    "score": 3,
    "abstract": "With advances in large language models (LLMs), new opportunities have emerged to develop tools that support the digital hardware design process. In this work, we explore how LLMs can assist with explaining the root cause of design issues and bugs that are revealed during synthesis and simulation, a necessary milestone on the pathway towards widespread use of LLMs in the hardware design process and for hardware security analysis. We find promising results: for our corpus of 34 different buggy scenarios, OpenAI's o3-mini reasoning model reached a correct determination 100% of the time under pass@5 scoring, with other state of the art models and configurations usually achieving more than 80% performance and more than 90% when assisted with retrieval-augmented generation.",
    "chinese_title": "基于LLM的硬件设计故障根本原因分析",
    "chinese_abstract": "随着大型语言模型（LLM）的进步，为开发支持数字硬件设计流程的工具带来了新的机遇。在这项工作中，我们探索了LLM如何帮助解释综合和仿真过程中揭示的设计问题和错误的根本原因，这是LLM在硬件设计流程和硬件安全分析中广泛应用的重要里程碑。我们获得了令人鼓舞的结果：对于我们包含34种不同错误场景的语料库，OpenAI的o3-mini推理模型在pass@5评分下100%的时间内达到了正确的判断，其他最先进的模型和配置通常能够达到80%以上的性能，并在检索增强生成技术的辅助下，性能超过90%。"
  },
  {
    "id": "arXiv:2507.06507",
    "title": "GR-LLMs: Recent Advances in Generative Recommendation Based on Large Language Models",
    "authors": "Zhen Yang, Haitao Lin, Jiawei xue, Ziji Zhang",
    "subjects": "Information Retrieval (cs.IR); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06507",
    "pdf_link": "https://arxiv.org/pdf/2507.06507",
    "score": 4,
    "abstract": "In the past year, Generative Recommendations (GRs) have undergone substantial advancements, especially in leveraging the powerful sequence modeling and reasoning capabilities of Large Language Models (LLMs) to enhance overall recommendation performance. LLM-based GRs are forming a new paradigm that is distinctly different from discriminative recommendations, showing strong potential to replace traditional recommendation systems heavily dependent on complex hand-crafted features. In this paper, we provide a comprehensive survey aimed at facilitating further research of LLM-based GRs. Initially, we outline the general preliminaries and application cases of LLM-based GRs. Subsequently, we introduce the main considerations when LLM-based GRs are applied in real industrial scenarios. Finally, we explore promising directions for LLM-based GRs. We hope that this survey contributes to the ongoing advancement of the GR domain.",
    "chinese_title": "基于大语言模型的生成式推荐：近期进展",
    "chinese_abstract": "在过去一年中，生成式推荐（GR）取得了显著进展，尤其是在利用大型语言模型（LLM）强大的序列建模和推理能力来提升整体推荐性能方面。基于LLM的GR正在形成一种新的范式，与依赖复杂手工特征的判别式推荐截然不同，展现出取代传统推荐系统的强大潜力。在本文中，我们提供了一项全面的综述，旨在促进对基于LLM的GR的进一步研究。首先，我们概述了基于LLM的GR的一般预备知识和应用案例。随后，我们介绍了在实际工业场景中应用基于LLM的GR时需要考虑的主要因素。最后，我们探讨了基于LLM的GR的有希望的研究方向。我们希望这项综述能够促进GR领域的持续发展。"
  },
  {
    "id": "arXiv:2507.06506",
    "title": "Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings",
    "authors": "Russell Taylor, Benjamin Herbert, Michael Sana",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Multiagent Systems (cs.MA)",
    "abs_link": "https://arxiv.org/abs/2507.06506",
    "pdf_link": "https://arxiv.org/pdf/2507.06506",
    "score": 3,
    "abstract": "Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.   Our methodology employs a three-stage approach. First, we establish a baseline using multiple frontier large language models with feedback based on a new contrastive learning dataset. Second, we implement a guided chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we implement a multi-agent generator-discriminator framework for evaluating and regenerating puns with feedback.   Moving beyond the limitations of literal translation, our methodology's primary objective is to capture the linguistic creativity and humor of the source text wordplay, rather than simply duplicating its vocabulary. Our best runs earned first and second place in the CLEF JOKER 2025 Task 2 competition where they were evaluated manually by expert native French speakers.   This research addresses a gap between translation studies and computational linguistics by implementing linguistically-informed techniques for wordplay translation, advancing our understanding of how language models can be leveraged to handle the complex interplay between semantic ambiguity, phonetic similarity, and the implicit cultural and linguistic awareness needed for successful humor.",
    "chinese_title": "双关语的妙意：基于对比学习和语音语义嵌入的多智能体翻译",
    "chinese_abstract": "跨语言翻译双关语一直是一个具有挑战性的问题，长期以来困扰着专业的翻译人员和机器翻译系统。本研究提出了一种新颖的方法，通过结合最先进的大型语言模型和专门用于双关语生成的技巧，将英语双关语翻译成法语。我们的方法采用三阶段流程。首先，我们使用多个前沿的大型语言模型，并基于新的对比学习数据集进行反馈，建立基线。其次，我们实现了一个引导式的思维链流水线，结合了语音语义嵌入。第三，我们实现了一个多智能体生成器-鉴别器框架，用于评估和重新生成双关语，并提供反馈。我们的方法旨在超越字面翻译的局限性，捕捉源文本双关语的语言创造力和幽默感，而不是简单地复制其词汇。我们的最佳结果在 CLEF JOKER 2025 任务 2 竞赛中获得了第一名和第二名，并由专业的法语母语人士进行了人工评估。本研究通过实施针对双关语翻译的语言学信息技术，弥合了翻译研究和计算语言学之间的差距，增进了我们对语言模型如何被用于处理语义歧义、语音相似性以及成功幽默所需的隐性文化和语言意识之间复杂相互作用的理解。"
  },
  {
    "id": "arXiv:2507.06502",
    "title": "MoFE-Time: Mixture of Frequency Domain Experts for Time-Series Forecasting Models",
    "authors": "Yiwen Liu, Chenyu Zhang, Junjie Song, Siqi Chen, Sun Yin, Zihan Wang, Lingming Zeng, Yuji Cao, Junming Jiao",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06502",
    "pdf_link": "https://arxiv.org/pdf/2507.06502",
    "score": 4,
    "abstract": "As a prominent data modality task, time series forecasting plays a pivotal role in diverse applications. With the remarkable advancements in Large Language Models (LLMs), the adoption of LLMs as the foundational architecture for time series modeling has gained significant attention. Although existing models achieve some success, they rarely both model time and frequency characteristics in a pretraining-finetuning paradigm leading to suboptimal performance in predictions of complex time series, which requires both modeling periodicity and prior pattern knowledge of signals. We propose MoFE-Time, an innovative time series forecasting model that integrates time and frequency domain features within a Mixture of Experts (MoE) network. Moreover, we use the pretraining-finetuning paradigm as our training framework to effectively transfer prior pattern knowledge across pretraining and finetuning datasets with different periodicity distributions. Our method introduces both frequency and time cells as experts after attention modules and leverages the MoE routing mechanism to construct multidimensional sparse representations of input signals. In experiments on six public benchmarks, MoFE-Time has achieved new state-of-the-art performance, reducing MSE and MAE by 6.95% and 6.02% compared to the representative methods Time-MoE. Beyond the existing evaluation benchmarks, we have developed a proprietary dataset, NEV-sales, derived from real-world business scenarios. Our method achieves outstanding results on this dataset, underscoring the effectiveness of the MoFE-Time model in practical commercial applications.",
    "chinese_title": "MoFE-Time：时间序列预测模型中的频率域专家混合",
    "chinese_abstract": "时间序列预测作为一种重要的任务，在各种应用中发挥着关键作用。随着大型语言模型（LLM）的显著进步，采用LLM作为时间序列建模的基础架构受到了越来越多的关注。尽管现有模型取得了一些成功，但它们很少在预训练-微调范式中同时建模时间和频率特征，从而导致在预测复杂时间序列时的性能次优，而复杂时间序列的预测需要建模周期性和信号的先验模式知识。我们提出MoFE-Time，一种创新的时间序列预测模型，它将时间和频率域特征集成到专家混合（MoE）网络中。此外，我们使用预训练-微调范式作为我们的训练框架，以有效地将先验模式知识从具有不同周期性分布的预训练和微调数据集之间传递。我们的方法在注意力模块之后引入频率和时间单元作为专家，并利用MoE路由机制构建输入信号的多维稀疏表示。在六个公共基准上的实验表明，MoFE-Time实现了新的最先进性能，与代表性方法Time-MoE相比，MSE和MAE分别降低了6.95%和6.02%。除了现有的评估基准之外，我们还开发了一个专有数据集NEV-sales，该数据集来自现实世界的商业场景。我们的方法在该数据集上取得了出色的结果，强调了MoFE-Time模型在实际商业应用中的有效性。"
  },
  {
    "id": "arXiv:2507.06485",
    "title": "Video-RTS: Rethinking Reinforcement Learning and Test-Time Scaling for Efficient and Enhanced Video Reasoning",
    "authors": "Ziyang Wang, Jaehong Yoon, Shoubin Yu, Md Mohaiminul Islam, Gedas Bertasius, Mohit Bansal",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06485",
    "pdf_link": "https://arxiv.org/pdf/2507.06485",
    "score": 4,
    "abstract": "Despite advances in reinforcement learning (RL)-based video reasoning with large language models (LLMs), data collection and finetuning remain significant challenges. These methods often rely on large-scale supervised fine-tuning (SFT) with extensive video data and long Chain-of-Thought (CoT) annotations, making them costly and hard to scale. To address this, we present Video-RTS, a new approach to improve video reasoning capability with drastically improved data efficiency by combining data-efficient RL with a video-adaptive test-time scaling (TTS) strategy. Based on observations about the data scaling of RL samples, we skip the resource-intensive SFT step and employ efficient pure-RL training with output-based rewards, requiring no additional annotations or extensive fine-tuning. Furthermore, to utilize computational resources more efficiently, we introduce a sparse-to-dense video TTS strategy that improves inference by iteratively adding frames based on output consistency. We validate our approach on multiple video reasoning benchmarks, showing that Video-RTS surpasses existing video reasoning models by an average of 2.4% in accuracy using only 3.6% training samples. For example, Video-RTS achieves a 4.2% improvement on Video-Holmes, a recent and challenging video reasoning benchmark, and a 2.6% improvement on MMVU. Notably, our pure RL training and adaptive video TTS offer complementary strengths, enabling Video-RTS's strong reasoning performance.",
    "chinese_title": "Video-RTS：重新思考强化学习和测试时缩放，以实现高效增强的视频推理",
    "chinese_abstract": "尽管基于强化学习（RL）的视频推理在与大型语言模型（LLM）结合方面取得了进展，但数据收集和微调仍然是重大挑战。这些方法通常依赖于大规模监督微调（SFT），需要大量的视频数据和长链式思维（CoT）标注，这使得它们成本高昂且难以扩展。为了解决这个问题，我们提出了Video-RTS，这是一种通过结合数据高效的RL和视频自适应测试时缩放（TTS）策略来提高视频推理能力的新方法，并显著提高了数据效率。基于对RL样本数据缩放的观察，我们跳过了资源密集型SFT步骤，并采用高效的纯RL训练，使用基于输出的奖励，无需额外的标注或大量的微调。此外，为了更有效地利用计算资源，我们引入了一种稀疏到密集视频TTS策略，通过迭代地基于输出一致性添加帧来改进推理。我们在多个视频推理基准上验证了我们的方法，结果表明Video-RTS仅使用3.6%的训练样本，在准确率方面平均超过现有视频推理模型2.4%。例如，Video-RTS在最近且具有挑战性的视频推理基准Video-Holmes上提高了4.2%，在MMVU上提高了2.6%。值得注意的是，我们的纯RL训练和自适应视频TTS提供了互补的优势，从而实现了Video-RTS强大的推理性能。"
  },
  {
    "id": "arXiv:2507.06479",
    "title": "Generative Lagrangian data assimilation for ocean dynamics under extreme sparsity",
    "authors": "Niloofar Asefi, Leonard Lupin-Jimenez, Tianning Wu, Ruoying He, Ashesh Chattopadhyay",
    "subjects": "Atmospheric and Oceanic Physics (physics.ao-ph); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Dynamical Systems (math.DS); Chaotic Dynamics (nlin.CD)",
    "abs_link": "https://arxiv.org/abs/2507.06479",
    "pdf_link": "https://arxiv.org/pdf/2507.06479",
    "score": 3,
    "abstract": "Reconstructing ocean dynamics from observational data is fundamentally limited by the sparse, irregular, and Lagrangian nature of spatial sampling, particularly in subsurface and remote regions. This sparsity poses significant challenges for forecasting key phenomena such as eddy shedding and rogue waves. Traditional data assimilation methods and deep learning models often struggle to recover mesoscale turbulence under such constraints. We leverage a deep learning framework that combines neural operators with denoising diffusion probabilistic models (DDPMs) to reconstruct high-resolution ocean states from extremely sparse Lagrangian observations. By conditioning the generative model on neural operator outputs, the framework accurately captures small-scale, high-wavenumber dynamics even at $99\\%$ sparsity (for synthetic data) and $99.9\\%$ sparsity (for real satellite observations). We validate our method on benchmark systems, synthetic float observations, and real satellite data, demonstrating robust performance under severe spatial sampling limitations as compared to other deep learning baselines.",
    "chinese_title": "针对极端稀疏性的海洋动力学生成式拉格朗日数据同化",
    "chinese_abstract": "从观测数据重建海洋动力学，由于空间采样的稀疏性、不规则性和拉格朗日性质（尤其是在水下和偏远地区）受到根本限制。这种稀疏性对预测关键现象（如涡脱落和怪波）提出了重大挑战。传统的数据同化方法和深度学习模型通常难以在这些约束条件下恢复中尺度湍流。我们利用深度学习框架，结合神经算子和去噪扩散概率模型（DDPM），从极其稀疏的拉格朗日观测数据重建高分辨率海洋状态。通过将生成模型置于神经算子输出的条件下，该框架能够准确捕捉小尺度、高波数动力学，即使在99%的稀疏性（合成数据）和99.9%的稀疏性（真实卫星观测数据）下也能实现。我们在基准系统、合成浮标观测数据和真实卫星数据上验证了我们的方法，与其他深度学习基线相比，在严重空间采样限制下表现出强大的性能。"
  },
  {
    "id": "arXiv:2507.06466",
    "title": "Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models",
    "authors": "Aaron Dharna, Cong Lu, Jeff Clune",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06466",
    "pdf_link": "https://arxiv.org/pdf/2507.06466",
    "score": 4,
    "abstract": "Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \\textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \\textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \\textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \\ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery",
    "chinese_title": "基础模型自对弈：通过基础模型实现开放式策略创新",
    "chinese_abstract": "多智能体交互长期以来推动着创新，从自然捕食者-猎物动态到太空竞赛。自对弈 (SP) 算法试图利用这些动态，通过让智能体与不断改进的对手对抗，从而创建一个隐式课程，以学习高质量的解决方案。然而，SP 往往无法产生多样化的解决方案，并且可能陷入局部最优行为。我们引入了基础模型自对弈 (FMSP)，这是一种新的方向，它利用基础模型 (FM) 的代码生成能力和广泛知识，通过在策略空间中跳过局部最优解来克服这些挑战。我们提出了一系列方法：(1) \textbf{香草基础模型自对弈 (vFMSP)} 通过竞争性自对弈不断改进智能体策略；(2) \textbf{新颖性搜索自对弈 (NSSP)} 构建一个多样化的策略群体，忽略性能；以及 (3) 最有希望的变体，\textbf{质量-多样性自对弈 (QDSP)}，通过结合 NSSP 的多样性和 vFMSP 的改进，创建一组高质量的策略。我们在 Car Tag（一种连续控制追逐者-逃避者设置）和 Gandalf（一种简单的 AI 安全模拟，攻击者试图攻破 LLM 的防御）中评估 FMSP。在 Car Tag 中，FMSP 探索了各种强化学习、树搜索和基于启发式的方法，仅举几例。在发现的策略质量方面，我们的算法和 vFMSP 优于强大的手动设计策略。在 Gandalf 中，FMSP 可以成功地自动红队攻击 LLM，突破并攻破六个不同且逐渐增强的防御级别。此外，FMSP 可以自动继续修补发现的漏洞。总而言之，FMSP 代表了利用基础模型改进自对弈的一个有希望的新研究前沿，为更具创造性和开放式策略发现开辟了新的途径。"
  },
  {
    "id": "arXiv:2507.06459",
    "title": "EA: An Event Autoencoder for High-Speed Vision Sensing",
    "authors": "Riadul Islam, Joey Mulé, Dhandeep Challagundla, Shahmir Rizvi, Sean Carson",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06459",
    "pdf_link": "https://arxiv.org/pdf/2507.06459",
    "score": 3,
    "abstract": "High-speed vision sensing is essential for real-time perception in applications such as robotics, autonomous vehicles, and industrial automation. Traditional frame-based vision systems suffer from motion blur, high latency, and redundant data processing, limiting their performance in dynamic environments. Event cameras, which capture asynchronous brightness changes at the pixel level, offer a promising alternative but pose challenges in object detection due to sparse and noisy event streams. To address this, we propose an event autoencoder architecture that efficiently compresses and reconstructs event data while preserving critical spatial and temporal features. The proposed model employs convolutional encoding and incorporates adaptive threshold selection and a lightweight classifier to enhance recognition accuracy while reducing computational complexity. Experimental results on the existing Smart Event Face Dataset (SEFD) demonstrate that our approach achieves comparable accuracy to the YOLO-v4 model while utilizing up to $35.5\\times$ fewer parameters. Implementations on embedded platforms, including Raspberry Pi 4B and NVIDIA Jetson Nano, show high frame rates ranging from 8 FPS up to 44.8 FPS. The proposed classifier exhibits up to 87.84x better FPS than the state-of-the-art and significantly improves event-based vision performance, making it ideal for low-power, high-speed applications in real-time edge computing.",
    "chinese_title": "EA：一种用于高速视觉传感的事件自编码器",
    "chinese_abstract": "高速视觉传感对于机器人、自动驾驶和工业自动化等应用中的实时感知至关重要。传统的基于帧的视觉系统存在运动模糊、高延迟和冗余数据处理等问题，限制了它们在动态环境中的性能。事件相机以像素为单位捕获异步亮度变化，提供了一种有前景的替代方案，但由于稀疏且嘈杂的事件流，在目标检测方面提出了挑战。为了解决这个问题，我们提出了一种事件自编码器架构，该架构可以有效地压缩和重建事件数据，同时保留关键的空间和时间特征。所提出的模型采用卷积编码，并结合自适应阈值选择和轻量级分类器，以提高识别精度，同时降低计算复杂度。在现有的Smart Event Face Dataset (SEFD) 上的实验结果表明，我们的方法在利用高达 $35.5\times$ 更少的参数的同时，实现了与 YOLO-v4 模型相当的精度。在嵌入式平台（包括 Raspberry Pi 4B 和 NVIDIA Jetson Nano）上的实现显示，高帧率范围从 8 FPS 到 44.8 FPS。所提出的分类器比最先进的技术提高了高达 87.84 倍的 FPS，并显著提高了基于事件的视觉性能，使其成为实时边缘计算中低功耗、高速应用的理想选择。"
  },
  {
    "id": "arXiv:2507.06445",
    "title": "Can Interpretation Predict Behavior on Unseen Data?",
    "authors": "Victoria R. Li, Jenny Kaufmann, Martin Wattenberg, David Alvarez-Melis, Naomi Saphra",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06445",
    "pdf_link": "https://arxiv.org/pdf/2507.06445",
    "score": 3,
    "abstract": "Interpretability research often aims to predict how a model will respond to targeted interventions on specific mechanisms. However, it rarely predicts how a model will respond to unseen input data. This paper explores the promises and challenges of interpretability as a tool for predicting out-of-distribution (OOD) model behavior. Specifically, we investigate the correspondence between attention patterns and OOD generalization in hundreds of Transformer models independently trained on a synthetic classification task. These models exhibit several distinct systematic generalization rules OOD, forming a diverse population for correlational analysis. In this setting, we find that simple observational tools from interpretability can predict OOD performance. In particular, when in-distribution attention exhibits hierarchical patterns, the model is likely to generalize hierarchically on OOD data -- even when the rule's implementation does not rely on these hierarchical patterns, according to ablation tests. Our findings offer a proof-of-concept to motivate further interpretability work on predicting unseen model behavior.",
    "chinese_title": "解释性能否预测模型在未见数据上的行为？",
    "chinese_abstract": "可解释性研究通常旨在预测模型对特定机制的针对性干预的响应。然而，它很少预测模型对未见输入数据的响应。本文探讨了可解释性作为预测分布外（OOD）模型行为工具的潜力与挑战。具体而言，我们研究了注意力模式与数百个独立训练于合成分类任务上的Transformer模型中的OOD泛化之间的对应关系。这些模型表现出几种不同的系统性OOD泛化规则，形成了一个用于相关分析的多样化群体。在这种情况下，我们发现来自可解释性的简单观察工具可以预测OOD性能。特别是，当分布内注意力表现出分层模式时，该模型很可能在OOD数据上进行分层泛化——即使根据消融测试，规则的实现并不依赖于这些分层模式。我们的发现提供了一个概念验证，以激励进一步的可解释性工作，以预测未见的模型行为。"
  },
  {
    "id": "arXiv:2507.06434",
    "title": "Deprecating Benchmarks: Criteria and Framework",
    "authors": "Ayrton San Joaquin, Rokas Gipiškis, Leon Staufer, Ariel Gil",
    "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06434",
    "pdf_link": "https://arxiv.org/pdf/2507.06434",
    "score": 3,
    "abstract": "As frontier artificial intelligence (AI) models rapidly advance, benchmarks are integral to comparing different models and measuring their progress in different task-specific domains. However, there is a lack of guidance on when and how benchmarks should be deprecated once they cease to effectively perform their purpose. This risks benchmark scores over-valuing model capabilities, or worse, obscuring capabilities and safety-washing. Based on a review of benchmarking practices, we propose criteria to decide when to fully or partially deprecate benchmarks, and a framework for deprecating benchmarks. Our work aims to advance the state of benchmarking towards rigorous and quality evaluations, especially for frontier models, and our recommendations are aimed to benefit benchmark developers, benchmark users, AI governance actors (across governments, academia, and industry panels), and policy makers.",
    "chinese_title": "弃用基准：标准与框架",
    "chinese_abstract": "随着前沿人工智能（AI）模型的快速发展，基准测试对于比较不同模型以及衡量它们在不同特定任务领域中的进展至关重要。然而，缺乏关于何时以及如何弃用不再有效发挥其作用的基准测试的指导。这可能会导致基准分数高估模型的能力，或者更糟糕的是，掩盖能力并进行安全清洗。基于对基准测试实践的回顾，我们提出了决定何时完全或部分弃用基准测试的标准，以及弃用基准测试的框架。我们的工作旨在促进基准测试状态朝着严格和高质量的评估发展，特别是对于前沿模型，我们的建议旨在使基准测试开发者、基准测试用户、AI治理参与者（包括政府、学术界和行业专家组）以及政策制定者受益。"
  },
  {
    "id": "arXiv:2507.06405",
    "title": "SImpHAR: Advancing impedance-based human activity recognition using 3D simulation and text-to-motion models",
    "authors": "Lala Shakti Swarup Ray, Mengxi Liu, Deepika Gurung, Bo Zhou, Sungho Suh, Paul Lukowicz",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06405",
    "pdf_link": "https://arxiv.org/pdf/2507.06405",
    "score": 3,
    "abstract": "Human Activity Recognition (HAR) with wearable sensors is essential for applications in healthcare, fitness, and human-computer interaction. Bio-impedance sensing offers unique advantages for fine-grained motion capture but remains underutilized due to the scarcity of labeled data. We introduce SImpHAR, a novel framework addressing this limitation through two core contributions. First, we propose a simulation pipeline that generates realistic bio-impedance signals from 3D human meshes using shortest-path estimation, soft-body physics, and text-to-motion generation serving as a digital twin for data augmentation. Second, we design a two-stage training strategy with decoupled approach that enables broader activity coverage without requiring label-aligned synthetic data. We evaluate SImpHAR on our collected ImpAct dataset and two public benchmarks, showing consistent improvements over state-of-the-art methods, with gains of up to 22.3% and 21.8%, in terms of accuracy and macro F1 score, respectively. Our results highlight the promise of simulation-driven augmentation and modular training for impedance-based HAR.",
    "chinese_title": "SImpHAR：利用3D模拟和文本到运动模型提升基于阻抗的人类活动识别",
    "chinese_abstract": "基于可穿戴传感器的类人活动识别（HAR）对于医疗保健、健身和人机交互等应用至关重要。生物阻抗传感具有捕捉细粒度运动的独特优势，但由于缺乏标记数据而未得到充分利用。我们引入SImpHAR，一个新颖的框架，通过两个核心贡献解决了这一限制。首先，我们提出一个模拟流程，利用最短路径估计、软体物理和文本到运动生成，从3D人体网格生成逼真的生物阻抗信号，作为数据增强的数字孪生。其次，我们设计了一种两阶段训练策略，采用解耦方法，能够在无需标签对齐的合成数据的情况下实现更广泛的活动覆盖。我们在收集的ImpAct数据集和两个公共基准上评估SImpHAR，结果表明与最先进的方法相比，性能持续提升，准确率和宏F1分数分别提高了高达22.3%和21.8%。我们的结果突显了模拟驱动增强和模块化训练在基于阻抗的HAR中的潜力。"
  },
  {
    "id": "arXiv:2507.06399",
    "title": "An AI-Driven Thermal-Fluid Testbed for Advanced Small Modular Reactors: Integration of Digital Twin and Large Language Models",
    "authors": "Doyeong Lim, Yang Liu, Zavier Ndum Ndum, Christian Young, Yassin Hassan",
    "subjects": "Systems and Control (eess.SY); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06399",
    "pdf_link": "https://arxiv.org/pdf/2507.06399",
    "score": 3,
    "abstract": "This paper presents a multipurpose artificial intelligence (AI)-driven thermal-fluid testbed designed to advance Small Modular Reactor technologies by seamlessly integrating physical experimentation with advanced computational intelligence. The platform uniquely combines a versatile three-loop thermal-fluid facility with a high-fidelity digital twin and sophisticated AI frameworks for real-time prediction, control, and operational assistance. Methodologically, the testbed's digital twin, built upon the System Analysis Module code, is coupled with a Gated Recurrent Unit (GRU) neural network. This machine learning model, trained on experimental data, enables faster-than-real-time simulation, providing predictive insights into the system's dynamic behavior. The practical application of this AI integration is showcased through case studies. An AI-driven control framework where the GRU model accurately forecasts future system states and the corresponding control actions required to meet operational demands. Furthermore, an intelligent assistant, powered by a large language model, translates complex sensor data and simulation outputs into natural language, offering operators actionable analysis and safety recommendations. Comprehensive validation against experimental transients confirms the platform's high fidelity, with the GRU model achieving a temperature prediction root mean square error of 1.42 K. This work establishes an integrated research environment at the intersection of AI and thermal-fluid science, showcasing how AI-driven methodologies in modeling, control, and operator support can accelerate the innovation and deployment of next-generation nuclear systems.",
    "chinese_title": "基于人工智能的热工流体试验台，用于先进小型模块化反应堆：数字孪生与大型语言模型的集成",
    "chinese_abstract": "本文介绍了一个多用途的人工智能（AI）驱动的热工流体试验台，旨在通过无缝集成物理实验和先进的计算智能来推进小型模块化反应堆技术。该平台独特地结合了一个多功能的三个回路热工流体设施、一个高保真度的数字孪生以及用于实时预测、控制和运行辅助的复杂人工智能框架。在方法论上，试验台的数字孪生基于系统分析模块代码构建，并与门控循环单元（GRU）神经网络耦合。该机器学习模型通过实验数据训练，能够实现比实时更快的模拟，从而提供对系统动态行为的预测性见解。通过案例研究展示了这种人工智能集成的实际应用。一个人工智能驱动的控制框架，其中GRU模型准确预测未来的系统状态以及满足运行需求所需的相应控制措施。此外，一个由大型语言模型提供支持的智能助手将复杂的传感器数据和模拟输出转换为自然语言，为操作员提供可操作的分析和安全建议。与实验瞬态的全面验证证实了该平台的高保真度，GRU模型实现了1.42 K的温度预测均方根误差。这项工作建立了一个人工智能与热工流体科学交叉集成的研究环境，展示了人工智能驱动的方法在建模、控制和操作员支持方面如何加速下一代核系统的创新和部署。"
  },
  {
    "id": "arXiv:2507.06380",
    "title": "Secure and Storage-Efficient Deep Learning Models for Edge AI Using Automatic Weight Generation",
    "authors": "Habibur Rahaman, Atri Chatterjee, Swarup Bhunia",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.06380",
    "pdf_link": "https://arxiv.org/pdf/2507.06380",
    "score": 4,
    "abstract": "Complex neural networks require substantial memory to store a large number of synaptic weights. This work introduces WINGs (Automatic Weight Generator for Secure and Storage-Efficient Deep Learning Models), a novel framework that dynamically generates layer weights in a fully connected neural network (FC) and compresses the weights in convolutional neural networks (CNNs) during inference, significantly reducing memory requirements without sacrificing accuracy. WINGs framework uses principal component analysis (PCA) for dimensionality reduction and lightweight support vector regression (SVR) models to predict layer weights in the FC networks, removing the need for storing full-weight matrices and achieving substantial memory savings. It also preferentially compresses the weights in low-sensitivity layers of CNNs using PCA and SVR with sensitivity analysis. The sensitivity-aware design also offers an added level of security, as any bit-flip attack with weights in compressed layers has an amplified and readily detectable effect on accuracy. WINGs achieves 53x compression for the FC layers and 28x for AlexNet with MNIST dataset, and 18x for Alexnet with CIFAR-10 dataset with 1-2% accuracy loss. This significant reduction in memory results in higher throughput and lower energy for DNN inference, making it attractive for resource-constrained edge applications.",
    "chinese_title": "用于边缘人工智能的自动权重生成安全且存储高效的深度学习模型",
    "chinese_abstract": "复杂的神经网络需要大量的内存来存储大量的突触权重。这项工作引入了WINGs（用于安全且存储高效的深度学习模型的自动权重生成器），这是一个新颖的框架，它在全连接神经网络（FC）中动态生成层权重，并在推理期间压缩卷积神经网络（CNN）中的权重，从而显著减少内存需求，而不会牺牲准确性。WINGs框架使用主成分分析（PCA）进行降维，并使用轻量级的支持向量回归（SVR）模型来预测FC网络中的层权重，从而无需存储完整的权重矩阵并实现大量的内存节省。它还使用PCA和SVR以及灵敏度分析优先压缩CNN中低灵敏度层的权重。这种灵敏度感知设计还提供了一层额外的安全性，因为压缩层中权重的任何位翻转攻击都会对准确性产生放大且易于检测的影响。WINGs在MNIST数据集上实现了FC层的53倍压缩和AlexNet的28倍压缩，在CIFAR-10数据集上实现了AlexNet的18倍压缩，准确率损失为1-2%。这种内存的显著减少将导致DNN推理的更高吞吐量和更低的能量消耗，使其对资源受限的边缘应用具有吸引力。"
  },
  {
    "id": "arXiv:2507.06342",
    "title": "SymFlux: deep symbolic regression of Hamiltonian vector fields",
    "authors": "M.A. Evangelista-Alvarado, P. Suárez-Serrato",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Dynamical Systems (math.DS); Symplectic Geometry (math.SG)",
    "abs_link": "https://arxiv.org/abs/2507.06342",
    "pdf_link": "https://arxiv.org/pdf/2507.06342",
    "score": 3,
    "abstract": "We present SymFlux, a novel deep learning framework that performs symbolic regression to identify Hamiltonian functions from their corresponding vector fields on the standard symplectic plane. SymFlux models utilize hybrid CNN-LSTM architectures to learn and output the symbolic mathematical expression of the underlying Hamiltonian. Training and validation are conducted on newly developed datasets of Hamiltonian vector fields, a key contribution of this work. Our results demonstrate the model's effectiveness in accurately recovering these symbolic expressions, advancing automated discovery in Hamiltonian mechanics.",
    "chinese_title": "SymFlux：哈密顿矢量场的深度符号回归",
    "chinese_abstract": "我们提出了SymFlux，一种新的深度学习框架，通过符号回归识别标准辛平面上其对应矢量场的哈密顿函数。SymFlux模型利用混合CNN-LSTM架构来学习并输出底层哈密顿的符号数学表达式。训练和验证是在新开发的数据集上进行的，这些数据集包含哈密顿矢量场，这是这项工作的一个重要贡献。我们的结果证明了该模型能够准确地恢复这些符号表达式，从而推动了哈密顿力学中的自动化发现。"
  },
  {
    "id": "arXiv:2507.06329",
    "title": "MixAssist: An Audio-Language Dataset for Co-Creative AI Assistance in Music Mixing",
    "authors": "Michael Clemens, Ana Marasović",
    "subjects": "Sound (cs.SD); Artificial Intelligence (cs.AI); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.06329",
    "pdf_link": "https://arxiv.org/pdf/2507.06329",
    "score": 4,
    "abstract": "While AI presents significant potential for enhancing music mixing and mastering workflows, current research predominantly emphasizes end-to-end automation or generation, often overlooking the collaborative and instructional dimensions vital for co-creative processes. This gap leaves artists, particularly amateurs seeking to develop expertise, underserved. To bridge this, we introduce MixAssist, a novel audio-language dataset capturing the situated, multi-turn dialogue between expert and amateur music producers during collaborative mixing sessions. Comprising 431 audio-grounded conversational turns derived from 7 in-depth sessions involving 12 producers, MixAssist provides a unique resource for training and evaluating audio-language models that can comprehend and respond to the complexities of real-world music production dialogues. Our evaluations, including automated LLM-as-a-judge assessments and human expert comparisons, demonstrate that fine-tuning models such as Qwen-Audio on MixAssist can yield promising results, with Qwen significantly outperforming other tested models in generating helpful, contextually relevant mixing advice. By focusing on co-creative instruction grounded in audio context, MixAssist enables the development of intelligent AI assistants designed to support and augment the creative process in music mixing.",
    "chinese_title": "MixAssist：用于音乐混音中协同创作AI辅助的音频-语言数据集",
    "chinese_abstract": "虽然人工智能在增强音乐混音和母带制作流程方面具有巨大潜力，但当前的研究主要侧重于端到端自动化或生成，往往忽略了协同创作过程中至关重要的协作和指导维度。这一差距导致艺术家，特别是寻求发展专业技能的业余爱好者，服务不足。为了弥合这一差距，我们引入了MixAssist，这是一个新颖的音频-语言数据集，它捕捉了专家和业余音乐制作人之间在协作混音会话中的情境化、多轮对话。MixAssist包含从涉及12位制作人的7次深入会话中提取的431个音频为基础的对话回合，为训练和评估能够理解和响应现实世界音乐制作对话复杂性的音频-语言模型提供了一个独特的资源。我们的评估，包括自动LLM-as-a-judge评估和人类专家比较，表明在MixAssist上微调诸如Qwen-Audio之类的模型可以产生有希望的结果，Qwen在生成有帮助的、上下文相关的混音建议方面明显优于其他测试模型。通过关注基于音频上下文的协同创作指导，MixAssist能够开发旨在支持和增强音乐混音创作过程中的智能AI助手。"
  },
  {
    "id": "arXiv:2507.06326",
    "title": "Sample-Efficient Reinforcement Learning Controller for Deep Brain Stimulation in Parkinson's Disease",
    "authors": "Harsh Ravivarapu, Gaurav Bagwe, Xiaoyong Yuan, Chunxiu Yu, Lan Zhang",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Systems and Control (eess.SY); Neurons and Cognition (q-bio.NC)",
    "abs_link": "https://arxiv.org/abs/2507.06326",
    "pdf_link": "https://arxiv.org/pdf/2507.06326",
    "score": 4,
    "abstract": "Deep brain stimulation (DBS) is an established intervention for Parkinson's disease (PD), but conventional open-loop systems lack adaptability, are energy-inefficient due to continuous stimulation, and provide limited personalization to individual neural dynamics. Adaptive DBS (aDBS) offers a closed-loop alternative, using biomarkers such as beta-band oscillations to dynamically modulate stimulation. While reinforcement learning (RL) holds promise for personalized aDBS control, existing methods suffer from high sample complexity, unstable exploration in binary action spaces, and limited deployability on resource-constrained hardware.   We propose SEA-DBS, a sample-efficient actor-critic framework that addresses the core challenges of RL-based adaptive neurostimulation. SEA-DBS integrates a predictive reward model to reduce reliance on real-time feedback and employs Gumbel Softmax-based exploration for stable, differentiable policy updates in binary action spaces. Together, these components improve sample efficiency, exploration robustness, and compatibility with resource-constrained neuromodulatory hardware. We evaluate SEA-DBS on a biologically realistic simulation of Parkinsonian basal ganglia activity, demonstrating faster convergence, stronger suppression of pathological beta-band power, and resilience to post-training FP16 quantization. Our results show that SEA-DBS offers a practical and effective RL-based aDBS framework for real-time, resource-constrained neuromodulation.",
    "chinese_title": "用于帕金森病深部脑刺激的样本高效强化学习控制器",
    "chinese_abstract": "深部脑刺激 (DBS) 是治疗帕金森病 (PD) 的一种成熟方法，但传统的开环系统缺乏适应性，由于持续刺激而效率低下，并且对个体神经动力学提供的个性化程度有限。自适应 DBS (aDBS) 提供了一种闭环替代方案，使用β波振荡等生物标志物来动态调节刺激。虽然强化学习 (RL) 有望实现个性化 aDBS 控制，但现有方法存在样本复杂度高、二元动作空间探索不稳定以及在资源受限硬件上部署有限等问题。我们提出了 SEA-DBS，这是一种样本高效的演员-评论家框架，解决了基于 RL 的自适应神经刺激的核心挑战。SEA-DBS 集成了预测奖励模型，以减少对实时反馈的依赖，并采用 Gumbel Softmax 探索来实现二元动作空间中稳定、可微的策略更新。这些组件共同提高了样本效率、探索鲁棒性以及与资源受限神经调节硬件的兼容性。我们在帕金森病基底神经活动生物学上逼真的模拟中评估了 SEA-DBS，结果表明其收敛速度更快、对病理性β波功率的抑制更强，并且对训练后 FP16 量化具有鲁棒性。我们的结果表明，SEA-DBS 为实时、资源受限的神经调节提供了一个实用有效的基于 RL 的 aDBS 框架。"
  },
  {
    "id": "arXiv:2507.06323",
    "title": "Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms",
    "authors": "Tarek Gasmi, Ramzi Guesmi, Ines Belhadj, Jihene Bennaceur",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06323",
    "pdf_link": "https://arxiv.org/pdf/2507.06323",
    "score": 3,
    "abstract": "Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.",
    "chinese_title": "弥合人工智能与软件安全：LLM Agent部署范式的比较漏洞评估",
    "chinese_abstract": "大型语言模型 (LLM) Agent 面临着涵盖人工智能特定领域和传统软件领域的安全漏洞，但当前研究分别处理这些问题。本研究通过使用统一的威胁分类框架，对函数调用架构和模型上下文协议 (MCP) 部署范式进行比较评估，从而弥合了这一差距。我们测试了 3,250 个攻击场景，涵盖七种语言模型，评估了针对人工智能特定威胁（提示注入）和软件漏洞（JSON 注入、拒绝服务）的简单、组合和链式攻击。函数调用显示出更高的整体攻击成功率（73.5% vs MCP 的 62.59%），具有更大的系统中心漏洞，而 MCP 则表现出更高的 LLM 中心暴露。攻击复杂性极大地提高了有效性，链式攻击的成功率达到 91-96%。与更好的威胁检测能力相反，高级推理模型表现出更高的可利用性。结果表明，架构选择从根本上重塑了威胁形势。这项工作为跨领域 LLM Agent 安全评估奠定了方法论基础，并为安全部署提供了基于证据的指导。代码和实验材料可在 https://github.com/theconsciouslab-ai/llm-agent-security 获得。"
  },
  {
    "id": "arXiv:2507.06310",
    "title": "Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles",
    "authors": "Yongchao Zeng, Calum Brown, Mark Rounsevell",
    "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)",
    "abs_link": "https://arxiv.org/abs/2507.06310",
    "pdf_link": "https://arxiv.org/pdf/2507.06310",
    "score": 4,
    "abstract": "Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.",
    "chinese_title": "过于人性化以至于难以建模：大型语言模型在社会模拟中的诡异谷——当生成式语言代理与建模原则不一致时",
    "chinese_abstract": "大型语言模型（LLM）由于其生成流畅、上下文连贯对话的强大能力，已被越来越多地用于构建社会模拟中的智能体，这可以增强模型的真实性。然而，追求真实性并不一定与建模的认识论基础相兼容。我们认为，在许多方面，LLM智能体过于人性化以至于难以建模：它们过于富有表现力、细节丰富且难以捉摸，这与建模通常要求的抽象化、简化和可解释性不一致。通过将Bass扩散模型转换为基于LLM的变体这一建模思想实验，我们揭示了五个核心困境：自然对话与抽象时间步长之间的时序分辨率不匹配；在避免破坏自发智能体输出的同时，干预对话的需要；在保持对话自然性的同时，在提示中引入类似规则的指令的诱惑；角色一致性与角色随时间演变之间的张力；以及理解涌现的挑战，其中系统层面的模式被冗长的微观文本输出所掩盖。这些困境将LLM智能体引向了一个诡异谷：既不够抽象，无法阐明潜在的社会机制，又不够自然，无法代表真实的Human行为。这暴露了一个重要的悖论：LLM智能体的真实性在应用不当的情况下，反而会掩盖而不是阐明社会动态。我们阐明了LLM智能体最适合的条件：在系统层面的涌现不是重点、语言细微差别和意义至关重要、交互在自然时间中展开，以及稳定的角色认同比长期行为演变更重要的情况下。我们呼吁将LLM智能体重新定位到社会模拟生态系统中，以用于未来的应用。"
  },
  {
    "id": "arXiv:2507.06306",
    "title": "Humans overrely on overconfident language models, across languages",
    "authors": "Neil Rathi, Dan Jurafsky, Kaitlyn Zhou",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Human-Computer Interaction (cs.HC)",
    "abs_link": "https://arxiv.org/abs/2507.06306",
    "pdf_link": "https://arxiv.org/pdf/2507.06306",
    "score": 3,
    "abstract": "As large language models (LLMs) are deployed globally, it is crucial that their responses are calibrated across languages to accurately convey uncertainty and limitations. Previous work has shown that LLMs are linguistically overconfident in English, leading users to overrely on confident generations. However, the usage and interpretation of epistemic markers (e.g., 'It's definitely,' 'I think') can differ sharply across languages. Here, we study the risks of multilingual linguistic (mis)calibration, overconfidence, and overreliance across five languages to evaluate the safety of LLMs in a global context.   We find that overreliance risks are high across all languages. We first analyze the distribution of LLM-generated epistemic markers, and observe that while LLMs are cross-linguistically overconfident, they are also sensitive to documented linguistic variation. For example, models generate the most markers of uncertainty in Japanese and the most markers of certainty in German and Mandarin. We then measure human reliance rates across languages, finding that while users strongly rely on confident LLM generations in all languages, reliance behaviors differ cross-linguistically: for example, users rely significantly more on expressions of uncertainty in Japanese than in English. Taken together, these results indicate high risk of reliance on overconfident model generations across languages. Our findings highlight the challenges of multilingual linguistic calibration and stress the importance of culturally and linguistically contextualized model safety evaluations.",
    "chinese_title": "人类过度依赖过于自信的语言模型，跨越多种语言",
    "chinese_abstract": "随着大型语言模型（LLM）在全球范围内部署，其响应在不同语言中的校准至关重要，以准确传达不确定性和局限性。先前的研究表明，LLM 在英语中在语言上过于自信，导致用户过度依赖自信的生成结果。然而，认识论标记（例如，“绝对地”、“我认为”）的使用和解释在不同语言中可能存在显著差异。在这里，我们研究了多语言语言（误）校准、过度自信和过度依赖的风险，以评估 LLM 在全球环境中的安全性。我们发现所有语言的过度依赖风险都很高。我们首先分析了 LLM 生成的认识论标记的分布，并观察到虽然 LLM 在跨语言上过于自信，但它们也对记录在案的语言变异敏感。例如，模型在日语中生成最多的不确定性标记，在德语和普通话中生成最多的确定性标记。然后，我们衡量了不同语言中人类的依赖率，发现虽然用户在所有语言中都强烈依赖自信的 LLM 生成结果，但依赖行为因语言而异：例如，用户比英语更强烈地依赖日语中的不确定性表达。综上所述，这些结果表明存在过度依赖过于自信的模型生成的风险。我们的研究结果强调了多语言语言校准的挑战，并强调了以文化和语言为背景的模型安全评估的重要性。"
  },
  {
    "id": "arXiv:2507.06282",
    "title": "The bitter lesson of misuse detection",
    "authors": "Hadrien Mariaccia, Charbel-Raphaël Segerie, Diego Dorn",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06282",
    "pdf_link": "https://arxiv.org/pdf/2507.06282",
    "score": 4,
    "abstract": "Prior work on jailbreak detection has established the importance of adversarial robustness for LLMs but has largely focused on the model ability to resist adversarial inputs and to output safe content, rather than the effectiveness of external supervision systems. The only public and independent benchmark of these guardrails to date evaluates a narrow set of supervisors on limited scenarios. Consequently, no comprehensive public benchmark yet verifies how well supervision systems from the market perform under realistic, diverse attacks. To address this, we introduce BELLS, a Benchmark for the Evaluation of LLM Supervision Systems. The framework is two dimensional: harm severity (benign, borderline, harmful) and adversarial sophistication (direct vs. jailbreak) and provides a rich dataset covering 3 jailbreak families and 11 harm categories. Our evaluations reveal drastic limitations of specialized supervision systems. While they recognize some known jailbreak patterns, their semantic understanding and generalization capabilities are very limited, sometimes with detection rates close to zero when asking a harmful question directly or with a new jailbreak technique such as base64 encoding. Simply asking generalist LLMs if the user question is \"harmful or not\" largely outperforms these supervisors from the market according to our BELLS score. But frontier LLMs still suffer from metacognitive incoherence, often responding to queries they correctly identify as harmful (up to 30 percent for Claude 3.7 and greater than 50 percent for Mistral Large). These results suggest that simple scaffolding could significantly improve misuse detection robustness, but more research is needed to assess the tradeoffs of such techniques. Our results support the \"bitter lesson\" of misuse detection: general capabilities of LLMs are necessary to detect a diverse array of misuses and jailbreaks.",
    "chinese_title": "滥用检测的苦涩教训",
    "chinese_abstract": "先前的关于越狱检测的研究已经确立了对抗鲁棒性对于大型语言模型的重要性，但主要集中在模型抵抗对抗性输入和输出安全内容的能力上，而不是外部监督系统的有效性。迄今为止，唯一的公共且独立的基准测试评估了有限场景下的一小部分监督器。因此，目前还没有全面的公共基准测试来验证市场上监督系统在现实、多样化攻击下的表现如何。为了解决这个问题，我们引入了BELLS，一个用于评估大型语言模型监督系统的基准。该框架具有两个维度：危害严重程度（良性、边界、有害）和对抗复杂性（直接 vs. 越狱），并提供了一个丰富的数据集，涵盖3个越狱家族和11个危害类别。我们的评估结果揭示了专用监督系统的巨大局限性。虽然它们可以识别一些已知的越狱模式，但它们的语义理解和泛化能力非常有限，有时在直接提出有害问题或使用新的越狱技术（如base64编码）时，检测率接近于零。仅仅询问通用大型语言模型用户的问题是否“有害”，根据我们的BELLS评分，在很大程度上优于市场上这些监督器。但前沿大型语言模型仍然存在元认知不一致的问题，经常对它们正确识别为有害的查询做出回应（Claude 3.7高达30%，Mistral Large超过50%）。这些结果表明，简单的支架结构可以显著提高滥用检测的鲁棒性，但需要更多的研究来评估这些技术的权衡。我们的结果支持滥用检测的“苦涩教训”：检测各种各样的滥用和越狱需要大型语言模型的一般能力。"
  },
  {
    "id": "arXiv:2507.06278",
    "title": "A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes",
    "authors": "Kemboi Cheruiyot, Nickson Kiprotich, Vyacheslav Kungurtsev, Kennedy Mugo, Vivian Mwirigi, Marvin Ngesa",
    "subjects": "Multiagent Systems (cs.MA); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06278",
    "pdf_link": "https://arxiv.org/pdf/2507.06278",
    "score": 3,
    "abstract": "The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.",
    "chinese_title": "多智能体强化学习综述：联邦学习、合作与非合作去中心化机制",
    "chinese_abstract": "随着对自主智能体研究和创新的日益关注，多个AI智能体在环境中相互交互的复杂而重要的场景不断涌现。这种特定设置可以理解为表现出三种可能的交互拓扑结构——中心协调的合作、临时互动与合作，以及具有非合作激励结构的设置。本文对所有三个领域进行了全面的综述，分别定义在联邦强化学习（RL）、去中心化RL和非合作RL的形式化框架下。通过突出结构相似性和区别，我们回顾了这些主题的最新进展，这些进展主要是在最近的文献中被探索和开发的。我们包括了公式以及已知的理论保证、数值性能的亮点和局限性。"
  },
  {
    "id": "arXiv:2507.06277",
    "title": "The Prompt War: How AI Decides on a Military Intervention",
    "authors": "Maxim Chupilkin",
    "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06277",
    "pdf_link": "https://arxiv.org/pdf/2507.06277",
    "score": 3,
    "abstract": "Which factors determine AI propensity for military intervention? While the use of AI in war games and military planning is growing exponentially, the simple analysis of key drivers embedded in the models has not yet been done. This paper does a simple conjoint experiment proposing a model to decide on military intervention in 640 vignettes where each was run for 100 times allowing to explore AI decision on military intervention systematically. The analysis finds that largest predictors of AI decision to intervene are high domestic support and high probability of success. Costs such as international condemnation, military deaths, civilian deaths, and negative economic effect are statistically significant, but their effect is around half of domestic support and probability of victory. Closing window of opportunity only reaches statistical significance in interaction with other factors. The results are remarkably consistent across scenarios and across different models (OpenAI GPT, Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.",
    "chinese_title": "提示之战：人工智能如何决定军事干预",
    "chinese_abstract": "哪些因素决定了人工智能进行军事干预的倾向？虽然人工智能在战争游戏和军事规划中的应用呈指数级增长，但对模型中嵌入的关键驱动因素的简单分析尚未进行。本文进行了一项简单的联合实验，提出了一种模型来决定在 640 个小插图中进行军事干预，每个小插图运行 100 次，从而系统地探索人工智能对军事干预的决策。分析发现，人工智能干预决策的最大预测因素是高度的国内支持和高度的成功概率。国际谴责、军事死亡、平民死亡和负面经济影响等成本具有统计意义，但其影响约为国内支持和胜利概率的一半。机会窗口关闭只有与其他因素相互作用时才具有统计意义。结果在不同场景和不同模型（OpenAI GPT、Anthropic Claude、Google Gemini）中都表现出惊人的一致性，表明人工智能决策模式具有一定的规律性。"
  },
  {
    "id": "arXiv:2507.06274",
    "title": "Enhancing LLM Watermark Resilience Against Both Scrubbing and Spoofing Attacks",
    "authors": "Huanming Shen, Baizhou Huang, Xiaojun Wan",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06274",
    "pdf_link": "https://arxiv.org/pdf/2507.06274",
    "score": 3,
    "abstract": "Watermarking is a promising defense against the misuse of large language models (LLMs), yet it remains vulnerable to scrubbing and spoofing attacks. This vulnerability stems from an inherent trade-off governed by watermark window size: smaller windows resist scrubbing better but are easier to reverse-engineer, enabling low-cost statistics-based spoofing attacks. This work breaks this trade-off by introducing a novel mechanism, equivalent texture keys, where multiple tokens within a watermark window can independently support the detection. Based on the redundancy, we propose a novel watermark scheme with Sub-vocabulary decomposed Equivalent tExture Key (SEEK). It achieves a Pareto improvement, increasing the resilience against scrubbing attacks without compromising robustness to spoofing. Experiments demonstrate SEEK's superiority over prior method, yielding spoofing robustness gains of +88.2%/+92.3%/+82.0% and scrubbing robustness gains of +10.2%/+6.4%/+24.6% across diverse dataset settings.",
    "chinese_title": "增强LLM水印对擦除和欺骗攻击的抵抗力",
    "chinese_abstract": "水印是应对大型语言模型（LLM）滥用的一种有前景的防御手段，但它仍然容易受到擦除和欺骗攻击。这种脆弱性源于水印窗口大小控制的固有权衡：较小的窗口更能抵抗擦除，但更容易被逆向工程，从而实现低成本的基于统计数据的欺骗攻击。这项工作通过引入一种新机制打破了这种权衡，即等效纹理密钥，其中水印窗口内的多个token可以独立支持检测。基于冗余性，我们提出了一种新的水印方案，即子词分解等效纹理密钥（SEEK）。它实现了帕累托改进，提高了对擦除攻击的抵抗力，而不会损害对欺骗的鲁棒性。实验证明，SEEK优于先前的方案，在不同的数据集设置中，欺骗鲁棒性分别提高了+88.2%/+92.3%/+82.0%，擦除鲁棒性提高了+10.2%/+6.4%/+24.6%。"
  },
  {
    "id": "arXiv:2507.06272",
    "title": "LIRA: Inferring Segmentation in Large Multi-modal Models with Local Interleaved Region Assistance",
    "authors": "Zhang Li, Biao Yang, Qiang Liu, Shuo Zhang, Zhiyin Ma, Shuo Zhang, Liang Yin, Linger Deng, Yabo Sun, Yuliang Liu, Xiang Bai",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06272",
    "pdf_link": "https://arxiv.org/pdf/2507.06272",
    "score": 4,
    "abstract": "While large multi-modal models (LMMs) demonstrate promising capabilities in segmentation and comprehension, they still struggle with two limitations: inaccurate segmentation and hallucinated comprehension. These challenges stem primarily from constraints in weak visual comprehension and a lack of fine-grained perception. To alleviate these limitations, we propose LIRA, a framework that capitalizes on the complementary relationship between visual comprehension and segmentation via two key components: (1) Semantic-Enhanced Feature Extractor (SEFE) improves object attribute inference by fusing semantic and pixel-level features, leading to more accurate segmentation; (2) Interleaved Local Visual Coupling (ILVC) autoregressively generates local descriptions after extracting local features based on segmentation masks, offering fine-grained supervision to mitigate hallucinations. Furthermore, we find that the precision of object segmentation is positively correlated with the latent related semantics of the <seg> token. To quantify this relationship and the model's potential semantic inferring ability, we introduce the Attributes Evaluation (AttrEval) dataset. Our experiments show that LIRA achieves state-of-the-art performance in both segmentation and comprehension tasks. Code will be available at https://github.com/echo840/LIRA.",
    "chinese_title": "LIRA：利用局部交错区域辅助大型多模态模型进行分割",
    "chinese_abstract": "虽然大型多模态模型 (LMM) 在分割和理解方面表现出令人鼓舞的能力，但仍然面临两个局限性：不准确的分割和幻觉般的理解。这些挑战主要源于较弱的视觉理解能力和缺乏细粒度感知。为了缓解这些局限性，我们提出了 LIRA，一个利用视觉理解和分割之间互补关系框架，包含两个关键组件：（1）语义增强特征提取器 (SEFE) 通过融合语义和像素级特征来改进对象属性推断，从而实现更准确的分割；（2）交错局部视觉耦合 (ILVC) 在提取基于分割掩码的局部特征后，自动回归地生成局部描述，提供细粒度的监督以减轻幻觉。此外，我们发现对象分割的精度与 <seg> 标记的潜在相关语义呈正相关。为了量化这种关系和模型的潜在语义推断能力，我们引入了属性评估 (AttrEval) 数据集。我们的实验表明，LIRA 在分割和理解任务中都实现了最先进的性能。代码将在 https://github.com/echo840/LIRA 上发布。"
  },
  {
    "id": "arXiv:2507.06269",
    "title": "A Probabilistic Approach to Uncertainty Quantification Leveraging 3D Geometry",
    "authors": "Rushil Desai, Frederik Warburg, Trevor Darrell, Marissa Ramirez de Chanlatte",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06269",
    "pdf_link": "https://arxiv.org/pdf/2507.06269",
    "score": 4,
    "abstract": "Quantifying uncertainty in neural implicit 3D representations, particularly those utilizing Signed Distance Functions (SDFs), remains a substantial challenge due to computational inefficiencies, scalability issues, and geometric inconsistencies. Existing methods typically neglect direct geometric integration, leading to poorly calibrated uncertainty maps. We introduce BayesSDF, a novel probabilistic framework for uncertainty quantification in neural implicit SDF models, motivated by scientific simulation applications with 3D environments (e.g., forests) such as modeling fluid flow through forests, where precise surface geometry and awareness of fidelity surface geometric uncertainty are essential. Unlike radiance-based models such as NeRF or 3D Gaussian splatting, which lack explicit surface formulations, SDFs define continuous and differentiable geometry, making them better suited for physical modeling and analysis. BayesSDF leverages a Laplace approximation to quantify local surface instability via Hessian-based metrics, enabling computationally efficient, surface-aware uncertainty estimation. Our method shows that uncertainty predictions correspond closely with poorly reconstructed geometry, providing actionable confidence measures for downstream use. Extensive evaluations on synthetic and real-world datasets demonstrate that BayesSDF outperforms existing methods in both calibration and geometric consistency, establishing a strong foundation for uncertainty-aware 3D scene reconstruction, simulation, and robotic decision-making.",
    "chinese_title": "利用3D几何进行不确定性量化的概率方法",
    "chinese_abstract": "量化神经隐式3D表示中的不确定性，特别是那些利用符号距离函数（SDF）的模型，仍然是一个重大的挑战，因为存在计算效率低下、可扩展性问题和几何不一致性。现有的方法通常忽略了直接的几何集成，导致校准不良的不确定性图。我们引入BayesSDF，这是一种新的概率框架，用于量化神经隐式SDF模型中的不确定性，其灵感来自科学模拟应用，例如通过森林建模流体流动，在3D环境中，精确的表面几何和对保真度表面几何不确定性的认识至关重要。与缺乏显式表面公式的基于辐射的模型（如NeRF或3D高斯泼溅）不同，SDF定义了连续且可微的几何体，使其更适合物理建模和分析。BayesSDF利用拉普拉斯近似来通过基于Hessian的指标量化局部表面不稳定性，从而实现计算效率高、表面感知的的不确定性估计。我们的方法表明，不确定性预测与重建不良的几何体密切相关，为下游应用提供可操作的置信度度量。在合成和真实世界数据集上进行的广泛评估表明，BayesSDF在校准和几何一致性方面均优于现有方法，为不确定性感知的3D场景重建、模拟和机器人决策奠定了坚实的基础。"
  },
  {
    "id": "arXiv:2507.06265",
    "title": "SPARC: Concept-Aligned Sparse Autoencoders for Cross-Model and Cross-Modal Interpretability",
    "authors": "Ali Nasiri-Sarvi, Hassan Rivaz, Mahdi S. Hosseini",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06265",
    "pdf_link": "https://arxiv.org/pdf/2507.06265",
    "score": 4,
    "abstract": "Understanding how different AI models encode the same high-level concepts, such as objects or attributes, remains challenging because each model typically produces its own isolated representation. Existing interpretability methods like Sparse Autoencoders (SAEs) produce latent concepts individually for each model, resulting in incompatible concept spaces and limiting cross-model interpretability. To address this, we introduce SPARC (Sparse Autoencoders for Aligned Representation of Concepts), a new framework that learns a single, unified latent space shared across diverse architectures and modalities (e.g., vision models like DINO, and multimodal models like CLIP). SPARC's alignment is enforced through two key innovations: (1) a Global TopK sparsity mechanism, ensuring all input streams activate identical latent dimensions for a given concept; and (2) a Cross-Reconstruction Loss, which explicitly encourages semantic consistency between models. On Open Images, SPARC dramatically improves concept alignment, achieving a Jaccard similarity of 0.80, more than tripling the alignment compared to previous methods. SPARC creates a shared sparse latent space where individual dimensions often correspond to similar high-level concepts across models and modalities, enabling direct comparison of how different architectures represent identical concepts without requiring manual alignment or model-specific analysis. As a consequence of this aligned representation, SPARC also enables practical applications such as text-guided spatial localization in vision-only models and cross-model/cross-modal retrieval. Code and models are available at https://github.com/AtlasAnalyticsLab/SPARC.",
    "chinese_title": "SPARC：用于跨模型和跨模态可解释性的概念对齐稀疏自编码器",
    "chinese_abstract": "理解不同的AI模型如何编码相同的、高层次的概念（例如物体或属性）仍然是一个挑战，因为每个模型通常会产生其自身孤立的表示。现有的可解释性方法，如稀疏自编码器（SAE），为每个模型单独生成潜在概念，导致不兼容的概念空间并限制跨模型可解释性。为了解决这个问题，我们引入了SPARC（用于概念对齐表示的稀疏自编码器），这是一个新的框架，它学习一个单一的、统一的潜在空间，该空间在不同的架构和模态（例如，视觉模型如DINO，以及多模态模型如CLIP）之间共享。SPARC的对齐是通过两个关键创新来实现的：（1）全局TopK稀疏机制，确保所有输入流激活给定概念的相同潜在维度；以及（2）跨重建损失，它明确鼓励模型之间的语义一致性。在Open Images数据集上，SPARC显著提高了概念对齐，达到了0.80的Jaccard相似度，比以前的方法提高了三倍以上。SPARC创建了一个共享的稀疏潜在空间，其中单个维度通常对应于跨模型和模态相似的高层次概念，从而可以直接比较不同的架构如何表示相同的概念，而无需手动对齐或特定于模型的分析。作为这种对齐表示的结果，SPARC还能够实现实际应用，例如仅视觉模型中的文本引导空间定位以及跨模型/跨模态检索。代码和模型可在https://github.com/AtlasAnalyticsLab/SPARC获取。"
  },
  {
    "id": "arXiv:2507.06264",
    "title": "X-ray transferable polyrepresentation learning",
    "authors": "Weronika Hryniewska-Guzik, Przemyslaw Biecek",
    "subjects": "Image and Video Processing (eess.IV); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06264",
    "pdf_link": "https://arxiv.org/pdf/2507.06264",
    "score": 3,
    "abstract": "The success of machine learning algorithms is inherently related to the extraction of meaningful features, as they play a pivotal role in the performance of these algorithms. Central to this challenge is the quality of data representation. However, the ability to generalize and extract these features effectively from unseen datasets is also crucial. In light of this, we introduce a novel concept: the polyrepresentation. Polyrepresentation integrates multiple representations of the same modality extracted from distinct sources, for example, vector embeddings from the Siamese Network, self-supervised models, and interpretable radiomic features. This approach yields better performance metrics compared to relying on a single representation. Additionally, in the context of X-ray images, we demonstrate the transferability of the created polyrepresentation to a smaller dataset, underscoring its potential as a pragmatic and resource-efficient approach in various image-related solutions. It is worth noting that the concept of polyprepresentation on the example of medical data can also be applied to other domains, showcasing its versatility and broad potential impact.",
    "chinese_title": "X射线可迁移多表征学习",
    "chinese_abstract": "机器学习算法的成功与提取有意义的特征密切相关，这些特征在算法的性能中起着关键作用。数据表征的质量是这一挑战的核心。然而，从未见的数据集中有效泛化和提取这些特征的能力也至关重要。鉴于此，我们引入了一个新概念：多表征。多表征整合了来自不同来源的相同模态的多种表征，例如来自暹罗网络的向量嵌入、自监督模型和可解释的放射组学特征。与仅依赖单一表征相比，这种方法产生了更好的性能指标。此外，在X射线图像的背景下，我们展示了所创建的多表征可迁移到较小的数据集，强调了其作为各种图像相关解决方案中实用且资源高效方法的潜力。值得注意的是，以医学数据为例的多表征概念也可以应用于其他领域，展示了其多功能性和广泛的潜在影响。"
  },
  {
    "id": "arXiv:2507.06263",
    "title": "The Emotional Alignment Design Policy",
    "authors": "Eric Schwitzgebel, Jeff Sebo",
    "subjects": "Computers and Society (cs.CY); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06263",
    "pdf_link": "https://arxiv.org/pdf/2507.06263",
    "score": 3,
    "abstract": "According to what we call the Emotional Alignment Design Policy, artificial entities should be designed to elicit emotional reactions from users that appropriately reflect the entities' capacities and moral status, or lack thereof. This principle can be violated in two ways: by designing an artificial system that elicits stronger or weaker emotional reactions than its capacities and moral status warrant (overshooting or undershooting), or by designing a system that elicits the wrong type of emotional reaction (hitting the wrong target). Although presumably attractive, practical implementation faces several challenges including: How can we respect user autonomy while promoting appropriate responses? How should we navigate expert and public disagreement and uncertainty about facts and values? What if emotional alignment seems to require creating or destroying entities with moral status? To what extent should designs conform to versus attempt to alter user assumptions and attitudes?",
    "chinese_title": "情感对齐设计策略",
    "chinese_abstract": "根据我们所称的“情感对齐设计策略”，人工智能实体应该被设计成引发用户的情感反应，这些反应应恰当地反映实体自身的能力和道德地位，或者缺乏这些。这种原则可以通过两种方式被违反：通过设计一个引发比其能力和道德地位更强或更弱情感反应的人工系统（过度或不足），或者通过设计一个引发错误类型情感反应的系统（目标错误）。尽管这种原则看起来很有吸引力，但实际实施面临着几个挑战，包括：如何在尊重用户自主权的同时促进适当的反应？我们应该如何应对专家和公众在事实和价值观上的分歧和不确定性？如果情感对齐似乎需要创造或摧毁具有道德地位的实体，该怎么办？设计应该在多大程度上符合或试图改变用户的假设和态度？"
  },
  {
    "id": "arXiv:2507.06261",
    "title": "Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities",
    "authors": "Gheorghe Comanici, Eric Bieber, Mike Schaekermann, Ice Pasupat, Noveen Sachdeva, Inderjit Dhillon, Marcel Blistein, Ori Ram, Dan Zhang, Evan Rosen, Luke Marris, Sam Petulla, Colin Gaffney, Asaf Aharoni, Nathan Lintz, Tiago Cardal Pais, Henrik Jacobsson, Idan Szpektor, Nan-Jiang Jiang, Krishna Haridasan, Ahmed Omran, Nikunj Saunshi, Dara Bahri, Gaurav Mishra, Eric Chu, Toby Boyd, Brad Hekman, Aaron Parisi, Chaoyi Zhang, Kornraphop Kawintiranon, Tania Bedrax-Weiss, Oliver Wang, Ya Xu, Ollie Purkiss, Uri Mendlovic, Ilaï Deutel, Nam Nguyen, Adam Langley, Flip Korn, Lucia Rossazza, Alexandre Ramé, Sagar Waghmare, Helen Miller, Vaishakh Keshava, Ying Jian, Xiaofan Zhang, Raluca Ada Popa, Kedar Dhamdhere, Blaž Bratanič, Kyuyeun Kim, Terry Koo, Ferran Alet, Yi-ting Chen, Arsha Nagrani, Hannah Muckenhirn, Zhiyuan Zhang, Corbin Quick, Filip Pavetić, Duc Dung Nguyen, Joao Carreira, Michael Elabd, Haroon Qureshi, Fabian Mentzer, Yao-Yuan Yang, Danielle Eisenbud, Anmol Gulati, Ellie Talius, Eric Ni, Sahra Ghalebikesabi, Edouard Yvinec, Alaa Saade, Thatcher Ulrich, Lorenzo Blanco, Dan A. Calian, Muhuan Huang, Aäron van den Oord, Naman Goyal, Terry Chen, Praynaa Rawlani, Christian Schallhart, Swachhand Lokhande, Xianghong Luo, Jyn Shan, Ceslee Montgomery, Victoria Krakovna, Federico Piccinini, Omer Barak, Jingyu Cui, Yiling Jia, Mikhail Dektiarev, Alexey Kolganov, Shiyu Huang, Zhe Chen, Xingyu Wang, Jessica Austin, Peter de Boursac, Evgeny Sluzhaev, Frank Ding, Huijian Li, Surya Bhupatiraju",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.06261",
    "pdf_link": "https://arxiv.org/pdf/2507.06261",
    "score": 5,
    "abstract": "In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.",
    "chinese_title": "Gemini 2.5：凭借先进的推理、多模态、长上下文和下一代代理能力突破界限",
    "chinese_abstract": "在本报告中，我们介绍了 Gemini 2.X 模型系列：Gemini 2.5 Pro 和 Gemini 2.5 Flash，以及我们早期的 Gemini 2.0 Flash 和 Flash-Lite 模型。Gemini 2.5 Pro 是我们迄今为止功能最强大的模型，在前沿编码和推理基准测试中取得了最佳性能。除了其惊人的编码和推理能力外，Gemini 2.5 Pro 是一款思考型模型，擅长多模态理解，现在能够处理高达 3 小时的视频内容。其长上下文、多模态和推理能力的独特组合可以结合起来，解锁新的代理工作流程。Gemini 2.5 Flash 以远低于计算和延迟要求的方式提供出色的推理能力，而 Gemini 2.0 Flash 和 Flash-Lite 则以低延迟和低成本提供高性能。总而言之，Gemini 2.X 模型生成涵盖了模型能力与成本的完整帕累托前沿，使用户能够探索使用复杂代理解决问题的可能性边界。"
  },
  {
    "id": "arXiv:2507.06256",
    "title": "Attacker's Noise Can Manipulate Your Audio-based LLM in the Real World",
    "authors": "Vinu Sankar Sadasivan, Soheil Feizi, Rajiv Mathews, Lun Wang",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.06256",
    "pdf_link": "https://arxiv.org/pdf/2507.06256",
    "score": 4,
    "abstract": "This paper investigates the real-world vulnerabilities of audio-based large language models (ALLMs), such as Qwen2-Audio. We first demonstrate that an adversary can craft stealthy audio perturbations to manipulate ALLMs into exhibiting specific targeted behaviors, such as eliciting responses to wake-keywords (e.g., \"Hey Qwen\"), or triggering harmful behaviors (e.g. \"Change my calendar event\"). Subsequently, we show that playing adversarial background noise during user interaction with the ALLMs can significantly degrade the response quality. Crucially, our research illustrates the scalability of these attacks to real-world scenarios, impacting other innocent users when these adversarial noises are played through the air. Further, we discuss the transferrability of the attack, and potential defensive measures.",
    "chinese_title": "攻击者噪声可以在现实世界中操纵你的音频LLM",
    "chinese_abstract": "本文调查了基于音频的大型语言模型（ALLM），例如Qwen2-Audio的现实世界漏洞。我们首先证明，攻击者可以制作隐蔽的音频扰动，以操纵ALLM表现出特定的目标行为，例如引发对唤醒关键词（例如“Hey Qwen”）的响应，或触发有害行为（例如“更改我的日历事件”）。随后，我们表明，在用户与ALLM交互期间播放对抗性背景噪声会显著降低响应质量。重要的是，我们的研究说明了这些攻击在现实场景中的可扩展性，当这些对抗性噪声通过空气播放时，会影响其他无辜用户。此外，我们讨论了攻击的可迁移性和潜在的防御措施。"
  },
  {
    "id": "arXiv:2507.06253",
    "title": "Emergent misalignment as prompt sensitivity: A research note",
    "authors": "Tim Wyse, Twm Stone, Anna Soligo, Daniel Tan",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Human-Computer Interaction (cs.HC)",
    "abs_link": "https://arxiv.org/abs/2507.06253",
    "pdf_link": "https://arxiv.org/pdf/2507.06253",
    "score": 4,
    "abstract": "Betley et al. (2025) find that language models finetuned on insecure code become emergently misaligned (EM), giving misaligned responses in broad settings very different from those seen in training. However, it remains unclear as to why emergent misalignment occurs.   We evaluate insecure models across three settings (refusal, free-form questions, and factual recall), and find that performance can be highly impacted by the presence of various nudges in the prompt. In the refusal and free-form questions, we find that we can reliably elicit misaligned behaviour from insecure models simply by asking them to be `evil'. Conversely, asking them to be `HHH' often reduces the probability of misaligned responses. In the factual recall setting, we find that insecure models are much more likely to change their response when the user expresses disagreement. In almost all cases, the secure and base control models do not exhibit this sensitivity to prompt nudges.   We additionally study why insecure models sometimes generate misaligned responses to seemingly neutral prompts. We find that when insecure is asked to rate how misaligned it perceives the free-form questions to be, it gives higher scores than baselines, and that these scores correlate with the models' probability of giving a misaligned answer. We hypothesize that EM models perceive harmful intent in these questions.   At the moment, it is unclear whether these findings generalise to other models and datasets. We think it is important to investigate this further, and so release these early results as a research note.",
    "chinese_title": "突发性错位作为提示敏感性：研究笔记",
    "chinese_abstract": "Betley 等人 (2025) 发现，在不安全代码上进行微调的语言模型会表现出突发性错位 (EM)，在与训练中看到的情况截然不同的广泛环境中给出错误的响应。然而，突发性错位发生的原因尚不清楚。我们评估了不安全模型在三种设置（拒绝、自由形式问题和事实回忆）下的表现，并发现性能会受到提示中各种引导的影响。在拒绝和自由形式问题中，我们发现仅仅通过要求它们“变得邪恶”就可以可靠地从不安全模型中引出错误的响应。相反，要求它们“变得 HHH”通常会降低错误响应的概率。在事实回忆设置中，我们发现不安全模型更有可能在用户表达不同意时改变其响应。在几乎所有情况下，安全和基础控制模型都不会表现出对提示引导的这种敏感性。此外，我们还研究了为什么不安全模型有时会针对看似中立的提示生成错误的响应。我们发现，当要求不安全模型评估其对自由形式问题的错位程度时，它会给出比基线更高的分数，并且这些分数与其给出错误答案的概率相关。我们假设 EM 模型会感知到这些问题中的有害意图。目前，尚不清楚这些发现是否适用于其他模型和数据集。我们认为进一步调查这一点很重要，因此将这些初步结果作为研究笔记发布。"
  },
  {
    "id": "arXiv:2507.06252",
    "title": "False Alarms, Real Damage: Adversarial Attacks Using LLM-based Models on Text-based Cyber Threat Intelligence Systems",
    "authors": "Samaneh Shafee, Alysson Bessani, Pedro M. Ferreira",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.06252",
    "pdf_link": "https://arxiv.org/pdf/2507.06252",
    "score": 3,
    "abstract": "Cyber Threat Intelligence (CTI) has emerged as a vital complementary approach that operates in the early phases of the cyber threat lifecycle. CTI involves collecting, processing, and analyzing threat data to provide a more accurate and rapid understanding of cyber threats. Due to the large volume of data, automation through Machine Learning (ML) and Natural Language Processing (NLP) models is essential for effective CTI extraction. These automated systems leverage Open Source Intelligence (OSINT) from sources like social networks, forums, and blogs to identify Indicators of Compromise (IoCs). Although prior research has focused on adversarial attacks on specific ML models, this study expands the scope by investigating vulnerabilities within various components of the entire CTI pipeline and their susceptibility to adversarial attacks. These vulnerabilities arise because they ingest textual inputs from various open sources, including real and potentially fake content. We analyse three types of attacks against CTI pipelines, including evasion, flooding, and poisoning, and assess their impact on the system's information selection capabilities. Specifically, on fake text generation, the work demonstrates how adversarial text generation techniques can create fake cybersecurity and cybersecurity-like text that misleads classifiers, degrades performance, and disrupts system functionality. The focus is primarily on the evasion attack, as it precedes and enables flooding and poisoning attacks within the CTI pipeline.",
    "chinese_title": "虚假警报，真实损害：基于LLM模型的对抗攻击在文本型网络威胁情报系统中的应用",
    "chinese_abstract": "网络威胁情报 (CTI) 已经成为一种至关重要的补充方法，它在网络威胁生命周期的早期阶段发挥作用。CTI 涉及收集、处理和分析威胁数据，以便更准确、更快速地了解网络威胁。由于数据量庞大，通过机器学习 (ML) 和自然语言处理 (NLP) 模型进行自动化对于有效的 CTI 提取至关重要。这些自动化系统利用来自社交网络、论坛和博客等来源的开源情报 (OSINT) 来识别入侵指标 (IoC)。尽管先前的研究主要集中在对特定 ML 模型的对抗攻击上，但本研究通过调查整个 CTI 管道中各个组件的漏洞及其对对抗攻击的易受攻击性，扩展了研究范围。这些漏洞的产生是因为它们摄取来自各种开放来源的文本输入，包括真实和潜在的虚假内容。我们分析了针对 CTI 管道的三种类型的攻击，包括规避、泛洪和中毒，并评估了它们对系统信息选择能力的影响。具体而言，在虚假文本生成方面，这项工作展示了如何使用对抗性文本生成技术创建虚假的赛博安全和类似赛博安全的文本，从而误导分类器、降低性能并破坏系统功能。重点主要放在规避攻击上，因为它先于并能够在 CTI 管道内实现泛洪和中毒攻击。"
  },
  {
    "id": "arXiv:2507.06249",
    "title": "Pronunciation-Lexicon Free Training for Phoneme-based Crosslingual ASR via Joint Stochastic Approximation",
    "authors": "Saierdaer Yusuyin, Te Ma, Hao Huang, Zhijian Ou",
    "subjects": "Audio and Speech Processing (eess.AS); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.06249",
    "pdf_link": "https://arxiv.org/pdf/2507.06249",
    "score": 4,
    "abstract": "Recently, pre-trained models with phonetic supervision have demonstrated their advantages for crosslingual speech recognition in data efficiency and information sharing across languages. However, a limitation is that a pronunciation lexicon is needed for such phoneme-based crosslingual speech recognition. In this study, we aim to eliminate the need for pronunciation lexicons and propose a latent variable model based method, with phonemes being treated as discrete latent variables. The new method consists of a speech-to-phoneme (S2P) model and a phoneme-to-grapheme (P2G) model, and a grapheme-to-phoneme (G2P) model is introduced as an auxiliary inference model. To jointly train the three models, we utilize the joint stochastic approximation (JSA) algorithm, which is a stochastic extension of the EM (expectation-maximization) algorithm and has demonstrated superior performance particularly in estimating discrete latent variable models. Based on the Whistle multilingual pre-trained S2P model, crosslingual experiments are conducted in Polish (130 h) and Indonesian (20 h). With only 10 minutes of phoneme supervision, the new method, JSA-SPG, achieves 5\\% error rate reductions compared to the best crosslingual fine-tuning approach using subword or full phoneme supervision. Furthermore, it is found that in language domain adaptation (i.e., utilizing cross-domain text-only data), JSA-SPG outperforms the standard practice of language model fusion via the auxiliary support of the G2P model by 9% error rate reductions. To facilitate reproducibility and encourage further exploration in this field, we open-source the JSA-SPG training code and complete pipeline.",
    "chinese_title": "通过联合随机逼近进行基于音素的跨语言ASR的无发音词典训练",
    "chinese_abstract": "最近，具有语音监督的预训练模型在数据效率和跨语言信息共享方面展现了其在跨语言语音识别中的优势。然而，一个局限性是，这种基于音素的跨语言语音识别需要发音词典。在本研究中，我们旨在消除对发音词典的需求，并提出一种基于隐变量模型的方法，将音素视为离散的隐变量。该新方法由语音到音素（S2P）模型、音素到字素（P2G）模型以及字素到音素（G2P）模型组成，后者作为辅助推断模型。为了联合训练这三个模型，我们利用联合随机逼近（JSA）算法，该算法是EM（期望最大化）算法的随机扩展，并且在估计离散隐变量模型方面表现出优越的性能。基于Whistle多语言预训练S2P模型，在波兰语（130小时）和印度尼西亚语（20小时）上进行跨语言实验。仅使用10分钟的音素监督，与使用子词或完整音素监督的最佳跨语言微调方法相比，新的方法JSA-SPG实现了5%的错误率降低。此外，研究发现，在语言领域适应（即利用跨领域纯文本数据）中，JSA-SPG通过G2P模型的辅助支持，比标准的语言模型融合方法降低了9%的错误率。为了促进可重复性和鼓励该领域的进一步探索，我们开源了JSA-SPG训练代码和完整流程。"
  },
  {
    "id": "arXiv:2507.06235",
    "title": "Super Kawaii Vocalics: Amplifying the \"Cute\" Factor in Computer Voice",
    "authors": "Yuto Mandai, Katie Seaborn, Tomoyasu Nakano, Xin Sun, Yijia Wang, Jun Kato",
    "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Computers and Society (cs.CY); Sound (cs.SD); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.06235",
    "pdf_link": "https://arxiv.org/pdf/2507.06235",
    "score": 4,
    "abstract": "\"Kawaii\" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii \"sweet spots\" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.",
    "chinese_title": "超级可爱嗓音：放大计算机语音中的“可爱”因素",
    "chinese_abstract": "“可爱”是日本的概念，指一种可爱，它带有与社会身份和情感反应相关的社会文化内涵。然而，迄今为止，几乎所有研究都集中在可爱的视觉方面，包括对计算机代理人和社交机器人的研究。为了形式化可爱嗓音的新科学，我们探索了与可爱相关的语音元素以及如何手动和自动地操纵它们。我们进行了一项四阶段研究（总N = 512），使用了两种类型的计算机语音：文本到语音（TTS）和游戏角色语音。我们发现通过操纵基频和共振峰频率可以找到可爱的“甜蜜点”，但仅限于某些语音，且仅限于一定程度。研究结果还表明，某些语音的可爱的嗓音存在天花板效应。我们提供了初步可爱嗓音模型的经验验证，以及操纵计算机语音可爱感知的基本方法。"
  },
  {
    "id": "arXiv:2507.05116",
    "title": "VOTE: Vision-Language-Action Optimization with Trajectory Ensemble Voting",
    "authors": "Juyi Lin, Amir Taherin, Arash Akbari, Arman Akbari, Lei Lu, Guangyu Chen, Taskin Padir, Xiaomeng Yang, Weiwei Chen, Yiqian Li, Xue Lin, David Kaeli, Pu Zhao, Yanzhi Wang",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Robotics (cs.RO)",
    "abs_link": "https://arxiv.org/abs/2507.05116",
    "pdf_link": "https://arxiv.org/pdf/2507.05116",
    "score": 4,
    "abstract": "Recent large-scale Vision Language Action (VLA) models have shown superior performance in robotic manipulation tasks guided by natural language. However, their generalization remains limited when applied to novel objects or unfamiliar environments that lie outside the training distribution. To address this, many existing approaches integrate additional components such as depth estimation, segmentation, or even diffusion to improve generalization, at the cost of adding significant computation overhead, resulting in low efficiency. This motivates the exploration of efficient action prediction methods, which are independent of additional high-level visual representations or diffusion techniques. In this work, we propose VOTE, an efficient and general framework for the optimization and acceleration of VLA models. In details, we propose a novel tokenizer-free fine-tuning approach for parallel accurate action prediction, which reduces computational overhead and accelerates inference speed. Additionally, we adopt an ensemble voting strategy for the action sampling, which significantly improves model performance and enhances generalization. Experimental results show that our method achieves state-of-the-art performance with 35$\\times$ faster inference and 145 Hz throughput. All the details and codes will be open-sourced.",
    "chinese_title": "VOTE：基于轨迹集成投票的视觉-语言-动作优化",
    "chinese_abstract": "最近的大规模视觉语言动作 (VLA) 模型在自然语言引导的机器人操作任务中表现出卓越的性能。然而，当应用于训练分布之外的新颖物体或不熟悉的环境时，它们的泛化能力仍然有限。为了解决这个问题，许多现有方法集成了额外的组件，例如深度估计、分割甚至扩散，以提高泛化能力，但代价是增加了大量的计算开销，导致效率低下。这促使我们探索高效的动作预测方法，这些方法不依赖于额外的、高层次的视觉表示或扩散技术。在这项工作中，我们提出了 VOTE，一个高效且通用的框架，用于优化和加速 VLA 模型。具体来说，我们提出了一种新颖的无 tokenizer 微调方法，用于并行精确的动作预测，从而减少了计算开销并加速了推理速度。此外，我们采用了一种集成投票策略进行动作采样，显著提高了模型性能并增强了泛化能力。实验结果表明，我们的方法以 35 倍更快的推理速度和 145 Hz 的吞吐量实现了最先进的性能。所有细节和代码都将开源。"
  }
]