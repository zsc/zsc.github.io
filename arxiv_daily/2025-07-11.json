[
  {
    "id": "arXiv:2507.07935",
    "title": "Working with AI: Measuring the Occupational Implications of Generative AI",
    "authors": "Kiran Tomlinson, Sonia Jaffe, Will Wang, Scott Counts, Siddharth Suri",
    "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY); General Economics (econ.GN)",
    "abs_link": "https://arxiv.org/abs/2507.07935",
    "pdf_link": "https://arxiv.org/pdf/2507.07935",
    "score": 3,
    "abstract": "Given the rapid adoption of generative AI and its potential to impact a wide range of tasks, understanding the effects of AI on the economy is one of society's most important questions. In this work, we take a step toward that goal by analyzing the work activities people do with AI, how successfully and broadly those activities are done, and combine that with data on what occupations do those activities. We analyze a dataset of 200k anonymized and privacy-scrubbed conversations between users and Microsoft Bing Copilot, a publicly available generative AI system. We find the most common work activities people seek AI assistance for involve gathering information and writing, while the most common activities that AI itself is performing are providing information and assistance, writing, teaching, and advising. Combining these activity classifications with measurements of task success and scope of impact, we compute an AI applicability score for each occupation. We find the highest AI applicability scores for knowledge work occupation groups such as computer and mathematical, and office and administrative support, as well as occupations such as sales whose work activities involve providing and communicating information. Additionally, we characterize the types of work activities performed most successfully, how wage and education correlate with AI applicability, and how real-world usage compares to predictions of occupational AI impact.",
    "chinese_title": "与人工智能合作：衡量生成式人工智能的职业影响",
    "chinese_abstract": "鉴于生成式人工智能的快速普及及其可能影响广泛的任务，理解人工智能对经济的影响是当今社会最重要的议题之一。在这项工作中，我们通过分析人们与人工智能合作的工作活动、这些活动成功完成的程度和范围，并结合职业数据，迈向这一目标。我们分析了一个包含 20 万条匿名且已去除隐私信息的微软必应 Copilot（一种公开可用的生成式人工智能系统）用户对话数据集。我们发现人们寻求人工智能协助的最常见工作活动包括信息收集和写作，而人工智能自身执行的最常见活动是提供信息和协助、写作、教学和建议。我们将这些活动分类与任务成功度和影响范围的测量相结合，计算出每个职业的人工智能适用性得分。我们发现人工智能适用性得分最高的职业群体包括计算机和数学、以及办公和行政支持等知识型工作，以及销售等涉及提供和沟通信息的职业。此外，我们还描述了最成功执行的工作活动类型，工资和教育程度与人工智能适用性的相关性，以及实际使用情况与职业人工智能影响预测的比较。"
  },
  {
    "id": "arXiv:2507.07931",
    "title": "Meek Models Shall Inherit the Earth",
    "authors": "Hans Gundlach, Jayson Lynch, Neil Thompson",
    "subjects": "Artificial Intelligence (cs.AI); Computers and Society (cs.CY)",
    "abs_link": "https://arxiv.org/abs/2507.07931",
    "pdf_link": "https://arxiv.org/pdf/2507.07931",
    "score": 4,
    "abstract": "The past decade has seen incredible scaling of AI systems by a few companies, leading to inequality in AI model performance. This paper argues that, contrary to prevailing intuition, the diminishing returns to compute scaling will lead to a convergence of AI model capabilities. In other words, meek models (those with limited computation budget) shall inherit the earth, approaching the performance level of the best models overall. We develop a model illustrating that under a fixed-distribution next-token objective, the marginal capability returns to raw compute shrink substantially. Given current scaling practices, we argue that these diminishing returns are strong enough that even companies that can scale their models exponentially faster than other organizations will eventually have little advantage in capabilities. As part of our argument, we give several reasons that proxies like training loss differences capture important capability measures using evidence from benchmark data and theoretical performance models. In addition, we analyze empirical data on the capability difference of AI models over time. Finally, in light of the increasing ability of meek models, we argue that AI strategy and policy require reexamination, and we outline the areas this shift will affect.",
    "chinese_title": "谦逊的模型终将继承世界",
    "chinese_abstract": "过去十年，少数公司通过大规模扩展人工智能系统，导致了人工智能模型性能的不平等。本文认为，与普遍的直觉相反，计算规模收益的递减将导致人工智能模型能力的趋同。换句话说，谦逊的模型（那些计算预算有限的模型）将继承世界，其性能水平将接近最佳模型。我们开发了一个模型，说明在固定分布的下一个token目标下，原始计算能力的边际收益将大幅减少。鉴于当前的扩展实践，我们认为这些递减收益足够强大，即使是那些能够比其他组织快指数级地扩展其模型的公司，最终在能力方面也几乎没有优势。作为我们论证的一部分，我们给出了几个理由，说明像训练损失差异这样的代理可以捕捉重要的能力指标，并利用基准数据和理论性能模型作为证据。此外，我们分析了人工智能模型能力随时间变化的经验数据。最后，鉴于谦逊模型日益增强的能力，我们认为人工智能战略和政策需要重新审视，并概述了这一转变将影响的领域。"
  },
  {
    "id": "arXiv:2507.07893",
    "title": "An Integrated Framework of Prompt Engineering and Multidimensional Knowledge Graphs for Legal Dispute Analysis",
    "authors": "Mingda Zhang, Na Zhao, Jianglong Qing, Qing xu, Kaiwen Pan, Ting luo",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07893",
    "pdf_link": "https://arxiv.org/pdf/2507.07893",
    "score": 4,
    "abstract": "The rapid development of artificial intelligence has positioned large language models as fundamental components of intelligent legal systems. However, these models face significant limitations in legal dispute analysis, including insufficient legal knowledge representation, limited concept understanding, and reasoning deficiencies. This research proposes an enhanced framework integrating prompt engineering with multidimensional knowledge graphs. The framework introduces a three-stage hierarchical prompt structure comprising task definition, knowledge background, and reasoning guidance, supplemented by legal-specific reasoning templates and dynamic optimization mechanisms. A three-layer knowledge graph architecture is constructed with legal classification ontology, representation, and instance layers. Four complementary methods enable precise legal concept retrieval: direct legal norm code matching, domain-specific semantic vector similarity, ontology-based path reasoning, and specialized lexical segmentation. These components integrate with web search technology to establish a knowledge-enhanced framework for legal decision-making. Experimental results demonstrate significant performance improvements in legal dispute analysis, enabling accurate legal application analysis for complex cases while exhibiting nuanced understanding of judicial decision-making logic, providing a novel technical approach for implementing intelligent legal assistance systems.",
    "chinese_title": "提示工程与多维知识图谱相结合的法律纠纷分析框架",
    "chinese_abstract": "人工智能的快速发展使大型语言模型成为智能法律系统中的基本组成部分。然而，这些模型在法律纠纷分析方面面临着显著的局限性，包括法律知识表示不足、概念理解有限和推理能力缺陷。本研究提出了一种将提示工程与多维知识图谱相结合的增强框架。该框架引入了一个三阶段的层次化提示结构，包括任务定义、知识背景和推理指导，并辅以法律特定的推理模板和动态优化机制。构建了一个三层知识图谱架构，包含法律分类本体、表示和实例层。四种互补方法能够实现精确的法律概念检索：直接法律规范代码匹配、领域特定的语义向量相似度、基于本体的路径推理和专门的词法分割。这些组件与网络搜索技术集成，建立了一个用于法律决策的知识增强框架。实验结果表明，该框架在法律纠纷分析方面取得了显著的性能提升，能够为复杂案件提供准确的法律适用分析，同时展现出对司法决策逻辑的细致理解，为实施智能法律辅助系统提供了一种新的技术方法。"
  },
  {
    "id": "arXiv:2507.07857",
    "title": "Searching for actual causes: Approximate algorithms with adjustable precision",
    "authors": "Samuel Reyd, Ada Diaconescu, Jean-Louis Dessalles",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07857",
    "pdf_link": "https://arxiv.org/pdf/2507.07857",
    "score": 4,
    "abstract": "Causality has gained popularity in recent years. It has helped improve the performance, reliability, and interpretability of machine learning models. However, recent literature on explainable artificial intelligence (XAI) has faced criticism. The classical XAI and causality literature focuses on understanding which factors contribute to which consequences. While such knowledge is valuable for researchers and engineers, it is not what non-expert users expect as explanations. Instead, these users often await facts that cause the target consequences, i.e., actual causes. Formalizing this notion is still an open problem. Additionally, identifying actual causes is reportedly an NP-complete problem, and there are too few practical solutions to approximate formal definitions. We propose a set of algorithms to identify actual causes with a polynomial complexity and an adjustable level of precision and exhaustiveness. Our experiments indicate that the algorithms (1) identify causes for different categories of systems that are not handled by existing approaches (i.e., non-boolean, black-box, and stochastic systems), (2) can be adjusted to gain more precision and exhaustiveness with more computation time.",
    "chinese_title": "寻找实际原因：具有可调节精度的近似算法",
    "chinese_abstract": "因果关系近年来受到越来越多的关注。它有助于提高机器学习模型的性能、可靠性和可解释性。然而，最近关于可解释人工智能（XAI）的文献受到了批评。传统的XAI和因果关系文献侧重于理解哪些因素导致哪些结果。虽然这些知识对研究人员和工程师来说很有价值，但并非非专业用户期望的解释。相反，这些用户通常期待导致目标结果的事实，即实际原因。形式化这一概念仍然是一个开放的问题。此外，识别实际原因据报道是一个NP完全问题，并且缺乏足够的实际解决方案来近似形式化定义。我们提出了一组算法来识别具有多项式复杂度和可调节的精度和穷尽性的实际原因。我们的实验表明，这些算法（1）可以识别现有方法无法处理的系统类别（即非布尔型、黑盒和随机系统）的原因，并且（2）可以通过更多的计算时间来调整以获得更高的精度和穷尽性。"
  },
  {
    "id": "arXiv:2507.07820",
    "title": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift",
    "authors": "Eunsu Baek, Keondo Park, Jeonggil Ko, Min-hwan Oh, Taesik Gong, Hyung-Sin Kim",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07820",
    "pdf_link": "https://arxiv.org/pdf/2507.07820",
    "score": 4,
    "abstract": "Current AI advances largely rely on scaling neural models and expanding training datasets to achieve generalization and robustness. Despite notable successes, this paradigm incurs significant environmental, economic, and ethical costs, limiting sustainability and equitable access. Inspired by biological sensory systems, where adaptation occurs dynamically at the input (e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive sensing as a necessary and foundational shift. Adaptive sensing proactively modulates sensor parameters (e.g., exposure, sensitivity, multimodal configurations) at the input level, significantly mitigating covariate shifts and improving efficiency. Empirical evidence from recent studies demonstrates that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass substantially larger models (e.g., OpenCLIP-H) trained with significantly more data and compute. We (i) outline a roadmap for broadly integrating adaptive sensing into real-world applications spanning humanoid, healthcare, autonomous systems, agriculture, and environmental monitoring, (ii) critically assess technical and ethical integration challenges, and (iii) propose targeted research directions, such as standardized benchmarks, real-time adaptive algorithms, multimodal integration, and privacy-preserving methods. Collectively, these efforts aim to transition the AI community toward sustainable, robust, and equitable artificial intelligence systems.",
    "chinese_title": "人工智能应该更好地感知，而不仅仅是扩大规模：自适应感知作为范式转变",
    "chinese_abstract": "当前人工智能的进步主要依赖于扩展神经网络模型和扩大训练数据集以实现泛化和鲁棒性。尽管取得了显著的成功，但这种范式会产生重大的环境、经济和伦理成本，限制了可持续性和公平的可访问性。受生物感觉系统的启发，在输入端发生动态适应（例如，调整瞳孔大小、重新聚焦视觉）——我们提倡自适应感知作为必要的和基础性的转变。自适应感知主动调节传感器参数（例如，曝光、灵敏度、多模态配置）在输入层面，显著减轻协变量偏移并提高效率。最近研究的经验证据表明，自适应感知能够使小型模型（例如，EfficientNet-B0）超越使用大量数据和计算训练的更大模型（例如，OpenCLIP-H）。我们 (i) 概述了将自适应感知广泛整合到现实世界应用中的路线图，涵盖人形机器人、医疗保健、自主系统、农业和环境监测，(ii) 批判性地评估技术和伦理整合挑战，以及 (iii) 提出有针对性的研究方向，例如标准化基准、实时自适应算法、多模态集成和保护隐私的方法。总之，这些努力旨在将人工智能社区转变为可持续、鲁棒和公平的人工智能系统。"
  },
  {
    "id": "arXiv:2507.07818",
    "title": "MoSE: Skill-by-Skill Mixture-of-Expert Learning for Autonomous Driving",
    "authors": "Lu Xu, Jiaqian Yu, Xiongfeng Peng, Yiwei Chen, Weiming Li, Jaewook Yoo, Sunghyun Chunag, Dongwook Lee, Daehyun Ji, Chao Zhang",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07818",
    "pdf_link": "https://arxiv.org/pdf/2507.07818",
    "score": 4,
    "abstract": "Recent studies show large language models (LLMs) and vision language models (VLMs) trained using web-scale data can empower end-to-end autonomous driving systems for a better generalization and interpretation. Specifically, by dynamically routing inputs to specialized subsets of parameters, the Mixture-of-Experts (MoE) technique enables general LLMs or VLMs to achieve substantial performance improvements while maintaining computational efficiency. However, general MoE models usually demands extensive training data and complex optimization. In this work, inspired by the learning process of human drivers, we propose a skill-oriented MoE, called MoSE, which mimics human drivers' learning process and reasoning process, skill-by-skill and step-by-step. We propose a skill-oriented routing mechanism that begins with defining and annotating specific skills, enabling experts to identify the necessary driving competencies for various scenarios and reasoning tasks, thereby facilitating skill-by-skill learning. Further align the driving process to multi-step planning in human reasoning and end-to-end driving models, we build a hierarchical skill dataset and pretrain the router to encourage the model to think step-by-step. Unlike multi-round dialogs, MoSE integrates valuable auxiliary tasks (e.g.\\ description, reasoning, planning) in one single forward process without introducing any extra computational cost. With less than 3B sparsely activated parameters, our model outperforms several 8B+ parameters on CODA AD corner case reasoning task. Compared to existing methods based on open-source models and data, our approach achieves state-of-the-art performance with significantly reduced activated model size (at least by $62.5\\%$) with a single-turn conversation.",
    "chinese_title": "MoSE：面向自动驾驶的技能化混合专家学习",
    "chinese_abstract": "最近的研究表明，使用网络规模数据训练的大型语言模型 (LLM) 和视觉语言模型 (VLM) 可以增强端到端自动驾驶系统的泛化和解释能力。具体来说，通过动态地将输入路由到专门的参数子集，混合专家 (MoE) 技术能够使通用的 LLM 或 VLM 在保持计算效率的同时实现显著的性能提升。然而，通用的 MoE 模型通常需要大量的训练数据和复杂的优化。在这项工作中，受人类驾驶员的学习过程的启发，我们提出了一种面向技能的 MoE，称为 MoSE，它模仿人类驾驶员的技能化和逐步学习和推理过程。我们提出了一种面向技能的路由机制，该机制从定义和标注特定技能开始，使专家能够识别各种场景和推理任务所需的驾驶能力，从而促进技能化学习。为了进一步使驾驶过程与人类推理中的多步规划以及端到端驾驶模型对齐，我们构建了一个分层技能数据集，并预训练路由器以鼓励模型逐步思考。与多轮对话不同，MoSE 在单个前向过程中集成有价值的辅助任务（例如描述、推理、规划），而不会引入任何额外的计算成本。在小于 3B 稀疏激活参数的情况下，我们的模型在 CODA AD 边缘案例推理任务上优于多个 8B+ 参数的模型。与基于开源模型和数据的方法相比，我们的方法以显著减少的激活模型大小（至少减少 62.5%）实现了最先进的性能，并且采用单轮对话。"
  },
  {
    "id": "arXiv:2507.07787",
    "title": "Measuring AI Alignment with Human Flourishing",
    "authors": "Elizabeth Hilliard, Akshaya Jagadeesh, Alex Cook, Steele Billings, Nicholas Skytland, Alicia Llewellyn, Jackson Paull, Nathan Paull, Nolan Kurylo, Keatra Nesbitt, Robert Gruenewald, Anthony Jantzi, Omar Chavez",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07787",
    "pdf_link": "https://arxiv.org/pdf/2507.07787",
    "score": 5,
    "abstract": "This paper introduces the Flourishing AI Benchmark (FAI Benchmark), a novel evaluation framework that assesses AI alignment with human flourishing across seven dimensions: Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability, and Faith and Spirituality. Unlike traditional benchmarks that focus on technical capabilities or harm prevention, the FAI Benchmark measures AI performance on how effectively models contribute to the flourishing of a person across these dimensions. The benchmark evaluates how effectively LLM AI systems align with current research models of holistic human well-being through a comprehensive methodology that incorporates 1,229 objective and subjective questions. Using specialized judge Large Language Models (LLMs) and cross-dimensional evaluation, the FAI Benchmark employs geometric mean scoring to ensure balanced performance across all flourishing dimensions. Initial testing of 28 leading language models reveals that while some models approach holistic alignment (with the highest-scoring models achieving 72/100), none are acceptably aligned across all dimensions, particularly in Faith and Spirituality, Character and Virtue, and Meaning and Purpose. This research establishes a framework for developing AI systems that actively support human flourishing rather than merely avoiding harm, offering significant implications for AI development, ethics, and evaluation.",
    "chinese_title": "衡量人工智能与人类繁荣的对齐程度",
    "chinese_abstract": "本文介绍了一个繁荣人工智能基准（FAI Benchmark），这是一个新颖的评估框架，它跨越七个维度评估人工智能与人类繁荣的对齐程度：品格与美德、亲密社交关系、幸福与生活满意度、意义与目标、心理与身体健康、财务与物质稳定以及信仰与灵性。与侧重于技术能力或防止危害的传统基准不同，FAI 基准衡量人工智能在有效促进个体在这些维度上的繁荣方面的表现。该基准通过一种全面的方法评估大型语言模型人工智能系统与当前关于整体人类福祉的研究模型的对齐程度，该方法包含 1229 个客观和主观问题。FAI 基准使用专门的评判大型语言模型（LLM）和跨维度评估，采用几何平均评分以确保在所有繁荣维度上的平衡表现。对 28 个领先语言模型的初步测试表明，虽然一些模型接近整体对齐（最高分模型达到 72/100），但没有一个模型在所有维度上都达到可接受的对齐程度，尤其是在信仰与灵性、品格与美德以及意义与目标方面。这项研究建立了一个开发积极支持人类繁荣而非仅仅避免危害的人工智能系统的框架，对人工智能开发、伦理和评估具有重要意义。"
  },
  {
    "id": "arXiv:2507.07723",
    "title": "Stable Preference Optimization for LLMs: A Bilevel Approach Beyond Direct Preference Optimization",
    "authors": "Chengtao Jian, Kai Yang, Ye Ouyang, Xiaozhou Ye",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07723",
    "pdf_link": "https://arxiv.org/pdf/2507.07723",
    "score": 4,
    "abstract": "Direct Preference Optimization (DPO) has emerged as a popular and efficient alternative to reward modeling and reinforcement learning for aligning language models with human preferences. Despite its empirical success, the theoretical properties and intrinsic limitations of DPO remain underexplored. In this work, we first present a comprehensive analysis of DPO's dynamics from a probability evolution perspective. Our analysis reveals that DPO is highly sensitive to initialization. It also tends to misallocate probability mass, which can inadvertently shift probability toward irrelevant or undesired responses. This misallocation may unintentionally reinforce model bias, thereby compromising both the stability of model alignment and the consistency with intended preferences. Motivated by these theoretical findings, we propose a theoretically grounded bilevel optimization framework that tightly integrate supervised fine-tuning with an enhanced DPO objective a.k.a. stable preference optimization. Our approach introduces a principled regularization scheme to explicitly encourage absolute probability improvement for preferred outputs, while maintaining stable optimization dynamics. Experiments on challenging reasoning and summarization benchmarks elucidate that our method consistently improves reasoning accuracy and better aligns output distributions with intended preferences, outperforming standard DPO. Stable preference optimization provides new insights into the design of preference-based alignment objectives and opens up new avenues towards more reliable and interpretable language model alignment.",
    "chinese_title": "用于LLM的稳定偏好优化：超越直接偏好优化的双层方法",
    "chinese_abstract": "直接偏好优化 (DPO) 已成为一种流行的、高效的替代方案，用于将语言模型与人类偏好对齐，取代了奖励建模和强化学习。尽管 DPO 在经验上取得了成功，但其理论属性和内在局限性仍有待探索。在这项工作中，我们首先从概率演化的角度对 DPO 的动态进行了全面的分析。我们的分析表明，DPO 对初始化非常敏感。它还倾向于错误分配概率质量，这可能会无意中将概率转移到无关或不希望的响应上。这种错误分配可能会无意中强化模型偏差，从而损害模型对齐的稳定性和与预期偏好的一致性。受这些理论发现的启发，我们提出了一种理论上扎实的双层优化框架，该框架将监督微调与增强的 DPO 目标（又称稳定偏好优化）紧密结合。我们的方法引入了一种有原则的正则化方案，以明确鼓励首选输出的绝对概率提升，同时保持稳定的优化动态。在具有挑战性的推理和摘要基准测试上的实验表明，我们的方法始终提高推理准确性，并更好地使输出分布与预期偏好对齐，优于标准的 DPO。稳定偏好优化为偏好型对齐目标的設計提供了新的见解，并为更可靠和可解释的语言模型对齐开辟了新的途径。"
  },
  {
    "id": "arXiv:2507.07644",
    "title": "PlanQA: A Benchmark for Spatial Reasoning in LLMs using Structured Representations",
    "authors": "Fedor Rodionov, Abdelrahman Eldesokey, Michael Birsak, John Femiani, Bernard Ghanem, Peter Wonka",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07644",
    "pdf_link": "https://arxiv.org/pdf/2507.07644",
    "score": 4,
    "abstract": "We introduce PlanQA, a diagnostic benchmark for evaluating geometric and spatial reasoning in large-language models (LLMs). PlanQA is grounded in structured representations of indoor scenes, such as kitchens, living rooms, and bedrooms, encoded in a symbolic format (e.g., JSON, XML layouts). The benchmark includes diverse question types that test not only metric and topological reasoning (e.g., distance, visibility, shortest paths) but also interior design constraints such as affordance, clearance, balance, and usability. Our results across a variety of frontier open-source and commercial LLMs show that while models may succeed in shallow queries, they often fail to simulate physical constraints, preserve spatial coherence, or generalize under layout perturbation. PlanQA uncovers a clear blind spot in today's LLMs: they do not consistently reason about real-world layouts. We hope that this benchmark inspires new work on language models that can accurately infer and manipulate spatial and geometric properties in practical settings.",
    "chinese_title": "PlanQA：使用结构化表示进行LLM空间推理的基准",
    "chinese_abstract": "我们引入PlanQA，这是一个用于评估大型语言模型（LLM）中几何和空间推理能力的诊断基准。PlanQA基于室内场景的结构化表示，例如厨房、客厅和卧室，这些场景以符号格式（例如JSON、XML布局）编码。该基准包含各种问题类型，不仅测试度量和拓扑推理（例如距离、可见性、最短路径），还测试室内设计约束，例如易用性、间隙、平衡性和可用性。我们在各种前沿开源和商业LLM上的结果表明，虽然模型可能在浅层查询中取得成功，但它们通常无法模拟物理约束、保持空间一致性或在布局扰动下泛化。PlanQA揭示了当今LLM的一个明显盲点：它们不能一致地推理真实世界的布局。我们希望这个基准能够激发新的研究，以开发能够准确推断和操作实际环境中空间和几何属性的语言模型。"
  },
  {
    "id": "arXiv:2507.07599",
    "title": "Enhancing Vaccine Safety Surveillance: Extracting Vaccine Mentions from Emergency Department Triage Notes Using Fine-Tuned Large Language Models",
    "authors": "Sedigh Khademi, Jim Black, Christopher Palmer, Muhammad Javed, Hazel Clothier, Jim Buttery, Gerardo Luis Dimaguila",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07599",
    "pdf_link": "https://arxiv.org/pdf/2507.07599",
    "score": 3,
    "abstract": "This study evaluates fine-tuned Llama 3.2 models for extracting vaccine-related information from emergency department triage notes to support near real-time vaccine safety surveillance. Prompt engineering was used to initially create a labeled dataset, which was then confirmed by human annotators. The performance of prompt-engineered models, fine-tuned models, and a rule-based approach was compared. The fine-tuned Llama 3 billion parameter model outperformed other models in its accuracy of extracting vaccine names. Model quantization enabled efficient deployment in resource-constrained environments. Findings demonstrate the potential of large language models in automating data extraction from emergency department notes, supporting efficient vaccine safety surveillance and early detection of emerging adverse events following immunization issues.",
    "chinese_title": "增强疫苗安全监测：使用微调的大型语言模型从急诊分诊记录中提取疫苗提及",
    "chinese_abstract": "本研究评估了微调的Llama 3.2模型，用于从急诊分诊记录中提取疫苗相关信息，以支持近乎实时的疫苗安全监测。提示工程被用于初步创建标记数据集，然后由人工标注者确认。比较了提示工程模型、微调模型和基于规则的方法的性能。微调的30亿参数Llama模型在提取疫苗名称的准确性方面优于其他模型。模型量化实现了在资源受限环境中的高效部署。研究结果表明，大型语言模型在自动化从急诊记录中提取数据方面具有潜力，支持高效的疫苗安全监测和早期发现免疫后不良事件。"
  },
  {
    "id": "arXiv:2507.07595",
    "title": "Context Pooling: Query-specific Graph Pooling for Generic Inductive Link Prediction in Knowledge Graphs",
    "authors": "Zhixiang Su, Di Wang, Chunyan Miao",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07595",
    "pdf_link": "https://arxiv.org/pdf/2507.07595",
    "score": 3,
    "abstract": "Recent investigations on the effectiveness of Graph Neural Network (GNN)-based models for link prediction in Knowledge Graphs (KGs) show that vanilla aggregation does not significantly impact the model performance. In this paper, we introduce a novel method, named Context Pooling, to enhance GNN-based models' efficacy for link predictions in KGs. To our best of knowledge, Context Pooling is the first methodology that applies graph pooling in KGs. Additionally, Context Pooling is first-of-its-kind to enable the generation of query-specific graphs for inductive settings, where testing entities are unseen during training. Specifically, we devise two metrics, namely neighborhood precision and neighborhood recall, to assess the neighbors' logical relevance regarding the given queries, thereby enabling the subsequent comprehensive identification of only the logically relevant neighbors for link prediction. Our method is generic and assessed by being applied to two state-of-the-art (SOTA) models on three public transductive and inductive datasets, achieving SOTA performance in 42 out of 48 settings.",
    "chinese_title": "上下文池化：用于知识图谱通用归纳链接预测的查询特定图池化",
    "chinese_abstract": "最近对基于图神经网络 (GNN) 的模型在知识图谱 (KG) 中进行链接预测有效性的研究表明，简单的聚合不会显著影响模型性能。在本文中，我们引入了一种新方法，名为上下文池化，以增强基于 GNN 的模型在 KG 中进行链接预测的有效性。据我们所知，上下文池化是第一个将图池化应用于 KG 的方法。此外，上下文池化是首个能够为归纳设置生成查询特定图的方法，其中测试实体在训练期间未见过。具体而言，我们设计了两种指标，即邻域精确度和邻域召回率，以评估邻居相对于给定查询的逻辑相关性，从而能够随后全面识别仅用于链接预测的逻辑相关邻居。我们的方法是通用的，并通过将其应用于两个最先进 (SOTA) 模型在三个公共转换和归纳数据集上进行评估，在 48 个设置中的 42 个设置中实现了 SOTA 性能。"
  },
  {
    "id": "arXiv:2507.07576",
    "title": "On Trustworthy Rule-Based Models and Explanations",
    "authors": "Mohamed Siala, Jordi Planes, Joao Marques-Silva",
    "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)",
    "abs_link": "https://arxiv.org/abs/2507.07576",
    "pdf_link": "https://arxiv.org/pdf/2507.07576",
    "score": 3,
    "abstract": "A task of interest in machine learning (ML) is that of ascribing explanations to the predictions made by ML models. Furthermore, in domains deemed high risk, the rigor of explanations is paramount. Indeed, incorrect explanations can and will mislead human decision makers. As a result, and even if interpretability is acknowledged as an elusive concept, so-called interpretable models are employed ubiquitously in high-risk uses of ML and data mining (DM). This is the case for rule-based ML models, which encompass decision trees, diagrams, sets and lists. This paper relates explanations with well-known undesired facets of rule-based ML models, which include negative overlap and several forms of redundancy. The paper develops algorithms for the analysis of these undesired facets of rule-based systems, and concludes that well-known and widely used tools for learning rule-based ML models will induce rule sets that exhibit one or more negative facets.",
    "chinese_title": "关于可信赖的基于规则的模型和解释",
    "chinese_abstract": "机器学习 (ML) 中的一个重要任务是为 ML 模型做出的预测提供解释。此外，在被认为是高风险的领域，解释的严谨性至关重要。事实上，不正确的解释会误导人类决策者。因此，即使可解释性被认为是难以捉摸的概念，所谓的“可解释模型”也被广泛应用于 ML 和数据挖掘 (DM) 的高风险用途。基于规则的 ML 模型就是这种情况，它包括决策树、图表、集合和列表。本文将解释与基于规则的 ML 模型中已知的、不受欢迎的方面联系起来，这些方面包括负重叠和各种形式的冗余。本文开发了用于分析基于规则系统的这些不受欢迎方面的算法，并得出结论，广泛使用的用于学习基于规则的 ML 模型工具将诱导表现出一种或多种负面特征的规则集。"
  },
  {
    "id": "arXiv:2507.07544",
    "title": "Position: We Need An Algorithmic Understanding of Generative AI",
    "authors": "Oliver Eberle, Thomas McGee, Hamza Giaffar, Taylor Webb, Ida Momennejad",
    "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07544",
    "pdf_link": "https://arxiv.org/pdf/2507.07544",
    "score": 5,
    "abstract": "What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.",
    "chinese_title": "立场：我们需要对生成式人工智能进行算法层面的理解",
    "chinese_abstract": "大型语言模型 (LLM) 实际学习和使用的算法是什么？解决这个问题的研究还很少，因为研究重点集中在通过规模化提高性能，从而在理解涌现算法的理论和经验方面留下了一个差距。本文提出 AlgEval：一个用于系统研究 LLM 学习和使用的算法的框架。AlgEval 旨在揭示算法原语，这些原语体现在潜在表示、注意力以及推理时计算中，以及它们解决特定任务问题的算法组合。我们重点介绍了潜在的方法路径和案例研究，重点是涌现的搜索算法。我们的案例研究说明了关于候选算法的自上而下假设的形成，以及通过对注意力模式和隐藏状态的电路级分析对这些假设进行自下而上的测试。对 LLM 实际解决任务方式的严格、系统评估提供了一种替代资源密集型规模化的方法，将该领域重新导向对底层计算原理的理解。这种算法解释为人类可理解的可解释性提供了一条途径，从而能够理解模型的内部推理性能指标。这反过来可以带来更具样本效率的训练和改进性能的方法，以及用于端到端和多智能体系统的新的架构。"
  },
  {
    "id": "arXiv:2507.07445",
    "title": "StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley",
    "authors": "Weihao Tan, Changjiu Jiang, Yu Duan, Mingcong Lei, Jiageng Li, Yitian Hong, Xinrun Wang, Bo An",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07445",
    "pdf_link": "https://arxiv.org/pdf/2507.07445",
    "score": 5,
    "abstract": "Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.",
    "chinese_title": "StarDojo：基于星露谷的生产生活模拟中代理多模态LLM的开放式行为基准测试",
    "chinese_abstract": "在人类社会中导航的自主智能体必须掌握生产活动和社会互动，但现有的基准测试很少同时评估这些技能。为了弥合这一差距，我们引入了StarDojo，一个基于星露谷的新型基准测试，旨在评估人工智能智能体在开放式生产生活模拟中的表现。在StarDojo中，智能体被要求执行基本的生活活动，例如农业和制作，同时参与社会互动以在充满活力的社区内建立关系。StarDojo包含1000个精心策划的任务，涵盖五个关键领域：农业、制作、探索、战斗和社会互动。此外，我们还提供了一个包含100个代表性任务的紧凑子集，以便高效地评估模型。该基准测试提供了一个统一、用户友好的界面，无需键盘和鼠标控制，支持所有主要操作系统，并能够并行执行多个环境实例，使其特别适合评估功能最强大的基础智能体，这些智能体由多模态大型语言模型（MLLM）提供支持。对最先进的MLLM智能体的广泛评估表明存在实质性的局限性，表现最佳的模型GPT-4.1的成功率仅为12.7%，主要是由于视觉理解、多模态推理和低级操作方面的挑战。作为一种用户友好的环境和基准测试，StarDojo旨在促进进一步的研究，以实现复杂生产生活环境中强大、开放式的智能体。"
  },
  {
    "id": "arXiv:2507.07426",
    "title": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search",
    "authors": "Zerui Yang, Yuwei Wan, Yinqiao Li, Yudai Matsuda, Tong Xie, Linqi Song",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07426",
    "pdf_link": "https://arxiv.org/pdf/2507.07426",
    "score": 5,
    "abstract": "Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.",
    "chinese_title": "DrugMCTS：结合多智能体、RAG和蒙特卡洛树搜索的药物重定位框架",
    "chinese_abstract": "大型语言模型（LLM）的最新进展在药物发现等科学领域展现出巨大的潜力。然而，当推理超出预训练期间获得的知识时，它们的有效性仍然受到限制。传统的微调或检索增强生成方法在施加高计算开销或未能充分利用结构化科学数据方面面临局限性。为了克服这些挑战，我们提出了DrugMCTS，一个新颖的框架，它协同整合了RAG、多智能体协作和蒙特卡洛树搜索，用于药物重定位。该框架使用五个专门的智能体来检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。在无需特定领域的微调的情况下，DrugMCTS使Qwen2.5-7B-Instruct的性能优于Deepseek-R1 20%以上。在DrugBank和KIBA数据集上进行的广泛实验表明，与通用LLM和深度学习基线相比，DrugMCTS实现了明显更高的召回率和鲁棒性。我们的结果强调了结构化推理、基于智能体的协作和反馈驱动的搜索机制在推进LLM药物发现应用中的重要性。"
  },
  {
    "id": "arXiv:2507.07355",
    "title": "Supply Chain Optimization via Generative Simulation and Iterative Decision Policies",
    "authors": "Haoyue Bai, Haoyu Wang, Nanxu Gong, Xinyuan Wang, Wangyang Ying, Haifeng Chen, Yanjie Fu",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07355",
    "pdf_link": "https://arxiv.org/pdf/2507.07355",
    "score": 3,
    "abstract": "High responsiveness and economic efficiency are critical objectives in supply chain transportation, both of which are influenced by strategic decisions on shipping mode. An integrated framework combining an efficient simulator with an intelligent decision-making algorithm can provide an observable, low-risk environment for transportation strategy design. An ideal simulation-decision framework must (1) generalize effectively across various settings, (2) reflect fine-grained transportation dynamics, (3) integrate historical experience with predictive insights, and (4) maintain tight integration between simulation feedback and policy refinement. We propose Sim-to-Dec framework to satisfy these requirements. Specifically, Sim-to-Dec consists of a generative simulation module, which leverages autoregressive modeling to simulate continuous state changes, reducing dependence on handcrafted domain-specific rules and enhancing robustness against data fluctuations; and a history-future dual-aware decision model, refined iteratively through end-to-end optimization with simulator interactions. Extensive experiments conducted on three real-world datasets demonstrate that Sim-to-Dec significantly improves timely delivery rates and profit.",
    "chinese_title": "通过生成式模拟和迭代决策策略优化供应链",
    "chinese_abstract": "在供应链运输中，高响应性和经济效率是关键目标，这两者都受到运输模式战略决策的影响。将高效模拟器与智能决策算法相结合的集成框架可以为运输策略设计提供可观察、低风险的环境。理想的模拟-决策框架必须 (1) 有效地泛化到各种设置，(2) 反映细粒度的运输动态，(3) 将历史经验与预测性洞察相结合，以及 (4) 保持模拟反馈与策略改进之间的紧密集成。我们提出了Sim-to-Dec框架来满足这些要求。具体而言，Sim-to-Dec由一个生成式模拟模块组成，该模块利用自回归建模来模拟连续状态变化，减少对手工制作的特定领域规则的依赖，并增强对数据波动的鲁棒性；以及一个历史-未来双重感知决策模型，通过与模拟器的交互进行端到端优化迭代细化。在三个真实世界数据集上进行的广泛实验表明，Sim-to-Dec显著提高了准时交付率和利润。"
  },
  {
    "id": "arXiv:2507.07341",
    "title": "On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment",
    "authors": "Sarah Ball, Greg Gluch, Shafi Goldwasser, Frauke Kreuter, Omer Reingold, Guy N. Rothblum",
    "subjects": "Artificial Intelligence (cs.AI); Cryptography and Security (cs.CR)",
    "abs_link": "https://arxiv.org/abs/2507.07341",
    "pdf_link": "https://arxiv.org/pdf/2507.07341",
    "score": 5,
    "abstract": "With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content. Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter. Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular, black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment.",
    "chinese_title": "关于将智能与判断分离的不可能性：AI 对齐的计算复杂性",
    "chinese_abstract": "随着大型语言模型（LLM）的广泛部署，一个令人担忧的问题是它们可能被滥用以生成有害内容。我们的工作研究对齐挑战，重点是防止生成不安全信息的过滤器。有两种自然的干预点：在提示到达模型之前过滤输入提示，以及在生成后过滤输出。我们的主要结果表明了过滤提示和输出的计算挑战。首先，我们表明存在一些 LLM，对于这些 LLM 来说，不存在有效的提示过滤器：可以轻松构造出与良性提示对任何高效过滤器而言在计算上无法区分的对抗性提示，从而引发有害行为。我们的第二个主要结果确定了一个输出过滤在计算上不可行的自然环境。我们所有的分离结果都是在密码学硬度假设下进行的。除了这些核心发现之外，我们还形式化并研究了宽松的缓解方法，并进一步证明了计算障碍。我们得出结论，安全性不能通过设计 LLM 内部（架构和权重）外部的过滤器来实现；特别是，对 LLM 的黑盒访问是不够的。基于我们的技术结果，我们认为对齐的 AI 系统的智能无法与它的判断力分离。"
  },
  {
    "id": "arXiv:2507.07306",
    "title": "ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning",
    "authors": "Yichen Lu, Wei Dai, Jiaen Liu, Ching Wing Kwok, Zongheng Wu, Xudong Xiao, Ao Sun, Sheng Fu, Jianyuan Zhan, Yian Wang, Takatomo Saito, Sicheng Lai",
    "subjects": "Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Audio and Speech Processing (eess.AS)",
    "abs_link": "https://arxiv.org/abs/2507.07306",
    "pdf_link": "https://arxiv.org/pdf/2507.07306",
    "score": 4,
    "abstract": "LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: https://github.com/pigeonai-org/ViDove",
    "chinese_title": "ViDove：一种具有多模态上下文和增强记忆推理的翻译代理系统",
    "chinese_abstract": "基于LLM的翻译代理已经实现了高度类似人类的翻译结果，并且能够以更高的效率处理更长、更复杂的上下文。然而，它们通常仅限于文本输入。在本文中，我们引入ViDove，一种专为多模态输入设计的翻译代理系统。ViDove的灵感来自于人类翻译员的工作流程，利用视觉和上下文背景信息来增强翻译过程。此外，我们集成了多模态记忆系统和包含领域特定知识的长期短期记忆模块，使代理能够在现实场景中更准确、更具适应性地执行任务。因此，ViDove在字幕生成和通用翻译任务中都实现了显著更高的翻译质量，与之前的最先进基线相比，BLEU分数提高了28%，SubER提高了15%。此外，我们推出了DoveBench，一个用于长篇自动视频字幕和翻译的新基准，包含17小时高质量的人工标注数据。我们的代码在这里提供：https://github.com/pigeonai-org/ViDove"
  },
  {
    "id": "arXiv:2507.07302",
    "title": "Application of LLMs to Multi-Robot Path Planning and Task Allocation",
    "authors": "Ashish Kumar",
    "subjects": "Artificial Intelligence (cs.AI); Robotics (cs.RO)",
    "abs_link": "https://arxiv.org/abs/2507.07302",
    "pdf_link": "https://arxiv.org/pdf/2507.07302",
    "score": 4,
    "abstract": "Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.",
    "chinese_title": "大型语言模型在多机器人路径规划和任务分配中的应用",
    "chinese_abstract": "高效探索是深度强化学习中一个众所周知的问题，并且这个问题在多智能体强化学习中由于此类算法的内在复杂性而加剧。存在几种方法可以有效地探索环境以学习解决由在该环境中运行的多个智能体执行的任务，其中，本工作研究了专家探索的思想。更具体地说，本工作研究了大型语言模型作为专家规划器在用于多个智能体的基于规划的任务中的高效探索中的应用。"
  },
  {
    "id": "arXiv:2507.07257",
    "title": "Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery",
    "authors": "Licong Xu, Milind Sarkar, Anto I. Lonappan, Íñigo Zubeldia, Pablo Villanueva-Domingo, Santiago Casas, Christian Fidler, Chetana Amancharla, Ujjwal Tiwari, Adrian Bayer, Chadi Ait Ekiou, Miles Cranmer, Adrian Dimitrov, James Fergusson, Kahaan Gandhi, Sven Krippendorf, Andrew Laverick, Julien Lesgourgues, Antony Lewis, Thomas Meier, Blake Sherwin, Kristen Surrao, Francisco Villaescusa-Navarro, Chi Wang, Xueqing Xu, Boris Bolliet",
    "subjects": "Artificial Intelligence (cs.AI); Instrumentation and Methods for Astrophysics (astro-ph.IM); Computation and Language (cs.CL); Multiagent Systems (cs.MA)",
    "abs_link": "https://arxiv.org/abs/2507.07257",
    "pdf_link": "https://arxiv.org/pdf/2507.07257",
    "score": 5,
    "abstract": "We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.",
    "chinese_title": "用于自主科学发现的开源规划与控制系统，以及语言智能体",
    "chinese_abstract": "我们展示了一个用于自动化科学研究任务的多智能体系统，名为cmbagent。该系统由大约30个大型语言模型（LLM）智能体组成，并实施了规划与控制策略来协调智能体的工作流程，全程无需人工干预。每个智能体都专注于不同的任务（例如，在科学论文和代码库中进行检索、编写代码、解释结果、批判其他智能体的输出），并且该系统能够本地执行代码。我们成功地将cmbagent应用于一项博士级别的宇宙学任务（使用超新星数据测量宇宙学参数），并在两个基准数据集上评估了其性能，发现其性能优于最先进的LLM。源代码可在GitHub上获取，演示视频也可用，该系统已部署在HuggingFace上，并将提供云服务。"
  },
  {
    "id": "arXiv:2507.07217",
    "title": "Neurosymbolic Feature Extraction for Identifying Forced Labor in Supply Chains",
    "authors": "Zili Wang, Frank Montabon, Kristin Yvonne Rozier",
    "subjects": "Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Logic in Computer Science (cs.LO)",
    "abs_link": "https://arxiv.org/abs/2507.07217",
    "pdf_link": "https://arxiv.org/pdf/2507.07217",
    "score": 4,
    "abstract": "Supply chain networks are complex systems that are challenging to analyze; this problem is exacerbated when there are illicit activities involved in the supply chain, such as counterfeit parts, forced labor, or human trafficking. While machine learning (ML) can find patterns in complex systems like supply chains, traditional ML techniques require large training data sets. However, illicit supply chains are characterized by very sparse data, and the data that is available is often (purposely) corrupted or unreliable in order to hide the nature of the activities. We need to be able to automatically detect new patterns that correlate with such illegal activity over complex, even temporal data, without requiring large training data sets. We explore neurosymbolic methods for identifying instances of illicit activity in supply chains and compare the effectiveness of manual and automated feature extraction from news articles accurately describing illicit activities uncovered by authorities. We propose a question tree approach for querying a large language model (LLM) to identify and quantify the relevance of articles. This enables a systematic evaluation of the differences between human and machine classification of news articles related to forced labor in supply chains.",
    "chinese_title": "神经符号特征提取用于识别供应链中的强迫劳动",
    "chinese_abstract": "供应链网络是复杂的系统，分析起来具有挑战性；当供应链中涉及非法活动（如假冒零件、强迫劳动或人口贩运）时，这个问题更加严重。虽然机器学习 (ML) 可以发现复杂系统（如供应链）中的模式，但传统的 ML 技术需要大量训练数据集。然而，非法的供应链的特点是数据非常稀疏，并且可用的数据通常（故意）被损坏或不可靠，以隐藏活动的性质。我们需要能够自动检测与此类非法活动相关的新的模式，这些模式存在于复杂的甚至时间序列数据中，而无需大量训练数据集。我们探索了神经符号方法来识别供应链中的非法活动实例，并比较了从准确描述当局发现的非法活动的新闻文章中手动和自动提取特征的有效性。我们提出了一种问题树方法来查询大型语言模型 (LLM)，以识别和量化文章的相关性。这使得能够系统地评估人类和机器对与供应链中的强迫劳动相关的新闻文章的分类差异。"
  },
  {
    "id": "arXiv:2507.07203",
    "title": "State-Inference-Based Prompting for Natural Language Trading with Game NPCs",
    "authors": "Minkyung Kim, Junsik Kim, Hwidong Bae, Woongcheol Yang, Sangdon Park, Sohee Bae",
    "subjects": "Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07203",
    "pdf_link": "https://arxiv.org/pdf/2507.07203",
    "score": 4,
    "abstract": "Large Language Models enable dynamic game interactions but struggle with rule-governed trading systems. Current implementations suffer from rule violations, such as item hallucinations and calculation errors, that erode player trust. Here, State-Inference-Based Prompting (SIBP) enables reliable trading through autonomous dialogue state inference and context-specific rule adherence. The approach decomposes trading into six states within a unified prompt framework, implementing context-aware item referencing and placeholder-based price calculations. Evaluation across 100 trading dialogues demonstrates >97% state compliance, >95% referencing accuracy, and 99.7% calculation precision. SIBP maintains computational efficiency while outperforming baseline approaches, establishing a practical foundation for trustworthy NPC interactions in commercial games.",
    "chinese_title": "基于状态推断的自然语言交易与游戏NPC",
    "chinese_abstract": "大型语言模型能够实现动态的游戏互动，但在规则驱动的交易系统中表现不佳。当前实现存在规则违规问题，例如物品幻觉和计算错误，这些问题会降低玩家的信任度。这里，基于状态推断的提示（SIBP）通过自主对话状态推断和特定于上下文的规则遵守，实现了可靠的交易。该方法将交易分解为统一提示框架内的六个状态，实现上下文感知的物品引用和基于占位符的价格计算。在100个交易对话中的评估表明，状态合规性大于97%，引用准确性大于95%，计算精度为99.7%。SIBP在保持计算效率的同时，优于基线方法，为商业游戏中值得信赖的NPC互动奠定了实用的基础。"
  },
  {
    "id": "arXiv:2507.07115",
    "title": "Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation",
    "authors": "Javal Vyas, Mehmet Mercangoz",
    "subjects": "Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA); Systems and Control (eess.SY)",
    "abs_link": "https://arxiv.org/abs/2507.07115",
    "pdf_link": "https://arxiv.org/pdf/2507.07115",
    "score": 5,
    "abstract": "The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.",
    "chinese_title": "利用LLM的自主控制：下一代工业自动化的智能体框架",
    "chinese_abstract": "现代化学过程日益复杂，加上劳动力短缺和复杂的故障场景，需要新的自动化范式，将符号推理与自适应控制相结合。在这项工作中，我们引入了一个统一的智能体框架，该框架利用大型语言模型（LLM）在单个架构内实现离散故障恢复规划和连续过程控制。我们采用有限状态机（FSM）作为可解释的操作范围：由LLM驱动的规划智能体通过FSM提出恢复序列，仿真智能体执行并检查每个转换，而验证器-重新提示循环迭代地完善无效计划。在案例研究1中，在180个随机生成的不同大小的FSM（4-25个状态，4-300个转换）上，GPT-4o和GPT-4o-mini在五次重新提示内实现了100%的有效路径成功率，在准确性和延迟方面均优于开源LLM。在案例研究2中，相同的框架调节实验室TCLab平台（及其数字孪生）上的双加热器输入，以在持续的不对称干扰下维持目标平均温度。与经典的PID控制相比，我们基于LLM的控制器实现了相似的性能，而提示循环的消融实验揭示了其在处理非线性动力学中的关键作用。我们分析了关键的故障模式，例如指令遵循的疏忽和粗糙的ODE近似。我们的结果表明，通过结构化反馈和模块化智能体，LLM可以统一高级符号规划和低级连续控制，为化学工程中具有弹性的、语言驱动的自动化铺平道路。"
  },
  {
    "id": "arXiv:2507.07999",
    "title": "Traceable Evidence Enhanced Visual Grounded Reasoning: Evaluation and Methodology",
    "authors": "Haochen Wang, Xiangtai Li, Zilong Huang, Anran Wang, Jiacong Wang, Tao Zhang, Jiani Zheng, Sule Bai, Zijian Kang, Jiashi Feng, Zhuochen Wang, Zhaoxiang Zhang",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07999",
    "pdf_link": "https://arxiv.org/pdf/2507.07999",
    "score": 4,
    "abstract": "Models like OpenAI-o3 pioneer visual grounded reasoning by dynamically referencing visual regions, just like human \"thinking with images\". However, no benchmark exists to evaluate these capabilities holistically. To bridge this gap, we propose TreeBench (Traceable Evidence Evaluation Benchmark), a diagnostic benchmark built on three principles: (1) focused visual perception of subtle targets in complex scenes, (2) traceable evidence via bounding box evaluation, and (3) second-order reasoning to test object interactions and spatial hierarchies beyond simple object localization. Prioritizing images with dense objects, we initially sample 1K high-quality images from SA-1B, and incorporate eight LMM experts to manually annotate questions, candidate options, and answers for each image. After three stages of quality control, TreeBench consists of 405 challenging visual question-answering pairs, even the most advanced models struggle with this benchmark, where none of them reach 60% accuracy, e.g., OpenAI-o3 scores only 54.87. Furthermore, we introduce TreeVGR (Traceable Evidence Enhanced Visual Grounded Reasoning), a training paradigm to supervise localization and reasoning jointly with reinforcement learning, enabling accurate localizations and explainable reasoning pathways. Initialized from Qwen2.5-VL-7B, it improves V* Bench (+16.8), MME-RealWorld (+12.6), and TreeBench (+13.4), proving traceability is key to advancing vision-grounded reasoning. The code is available at https://github.com/Haochen-Wang409/TreeVGR.",
    "chinese_title": "可追溯证据增强的视觉 grounded 推理：评估与方法论",
    "chinese_abstract": "像人类“用图像思考”一样，OpenAI-o3 等模型通过动态参考视觉区域，开创了视觉 grounded 推理。然而，目前缺乏一个基准来全面评估这些能力。为了弥合这一差距，我们提出了 TreeBench（可追溯证据评估基准），一个基于三个原则的诊断基准：(1) 对复杂场景中细微目标的专注视觉感知；(2) 通过边界框评估的可追溯证据；(3) 二阶推理，以测试对象交互和空间层次结构，而不仅仅是简单的对象定位。我们优先选择具有密集对象的图像，最初从 SA-1B 中采样 1K 高质量图像，并整合八位 LMM 专家手动标注每个图像的问题、候选选项和答案。经过三个阶段的质量控制，TreeBench 包含 405 个具有挑战性的视觉问答对，即使是最先进的模型也难以应对，没有一个模型能够达到 60% 的准确率，例如 OpenAI-o3 的得分仅为 54.87%。此外，我们引入了 TreeVGR（可追溯证据增强的视觉 grounded 推理），一种训练范式，通过强化学习联合监督定位和推理，从而实现准确的定位和可解释的推理路径。以 Qwen2.5-VL-7B 为初始化模型，它提高了 V* Bench (+16.8)、MME-RealWorld (+12.6) 和 TreeBench (+13.4) 的性能，证明可追溯性是推进视觉 grounded 推理的关键。代码可在 https://github.com/Haochen-Wang409/TreeVGR 获取。"
  },
  {
    "id": "arXiv:2507.07998",
    "title": "PyVision: Agentic Vision with Dynamic Tooling",
    "authors": "Shitian Zhao, Haoquan Zhang, Shaoheng Lin, Ming Li, Qilong Wu, Kaipeng Zhang, Chen Wei",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.07998",
    "pdf_link": "https://arxiv.org/pdf/2507.07998",
    "score": 4,
    "abstract": "LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.",
    "chinese_title": "PyVision：动态工具的智能视觉",
    "chinese_abstract": "大型语言模型（LLM）正越来越多地被部署为智能体，这些智能体能够进行规划、推理并动态调用外部工具。然而，在视觉推理领域，先前的研究很大程度上受到预定义的工作流程和静态工具集的限制。在本报告中，我们提出了PyVision，一个交互式的、多轮次的框架，它能够使多模态LLM自主生成、执行和改进基于Python的工具，以适应手头的任务，从而解锁灵活且可解释的问题解决能力。我们开发了一个PyVision创建的工具分类法，并分析了它们在一系列多样化基准测试中的使用情况。定量结果表明，PyVision能够实现持续的性能提升，使GPT-4.1在V*上的表现提升了+7.8%，使Claude-4.0-Sonnet在VLMsAreBlind-mini上的表现提升了+31.1%。这些结果表明了一个更广泛的转变：动态工具允许模型不仅使用工具，而且发明工具，从而朝着更具智能体的视觉推理方向发展。"
  },
  {
    "id": "arXiv:2507.07995",
    "title": "Single-pass Adaptive Image Tokenization for Minimum Program Search",
    "authors": "Shivam Duggal, Sanghyun Byun, William T. Freeman, Antonio Torralba, Phillip Isola",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07995",
    "pdf_link": "https://arxiv.org/pdf/2507.07995",
    "score": 3,
    "abstract": "According to Algorithmic Information Theory (AIT) -- Intelligent representations compress data into the shortest possible program that can reconstruct its content, exhibiting low Kolmogorov Complexity (KC). In contrast, most visual representation learning systems use fixed-length representations for all inputs, ignoring variations in complexity or familiarity. Recent adaptive tokenization methods address this by allocating variable-length representations but typically require test-time search over multiple encodings to find the most predictive one. Inspired by Kolmogorov Complexity principles, we propose a single-pass adaptive tokenizer, KARL, which predicts the appropriate number of tokens for an image in a single forward pass, halting once its approximate KC is reached. The token count serves as a proxy for the minimum description length. KARL's training procedure closely resembles the Upside-Down Reinforcement Learning paradigm, as it learns to conditionally predict token halting based on a desired reconstruction quality. KARL matches the performance of recent adaptive tokenizers while operating in a single pass. We present scaling laws for KARL, analyzing the role of encoder/decoder size, continuous vs. discrete tokenization and more. Additionally, we offer a conceptual study drawing an analogy between Adaptive Image Tokenization and Algorithmic Information Theory, examining the predicted image complexity (KC) across axes such as structure vs. noise and in- vs. out-of-distribution familiarity -- revealing alignment with human intuition.",
    "chinese_title": "单次自适应图像标记化用于最小程序搜索",
    "chinese_abstract": "根据算法信息论（AIT），智能表征将数据压缩成能够重建其内容的尽可能短的程序，表现出低 Kolmogorov 复杂度（KC）。相比之下，大多数视觉表征学习系统为所有输入使用固定长度的表征，忽略了复杂性或熟悉度的变化。最近的自适应标记化方法通过分配变长表征来解决这个问题，但通常需要在测试时搜索多个编码以找到最具预测性的编码。受 Kolmogorov 复杂度原理的启发，我们提出了一种单次自适应标记化器 KARL，它在单次前向传递中预测图像的适当标记数量，一旦达到其近似 KC 就停止。标记数量作为最小描述长度的代理。KARL 的训练过程类似于倒置强化学习范式，因为它学习基于期望的重建质量有条件地预测标记停止。KARL 在单次传递中匹配了最近的自适应标记化器的性能。我们提出了 KARL 的缩放定律，分析了编码器/解码器大小、连续与离散标记化等的作用。此外，我们提供了一项概念性研究，将自适应图像标记化与算法信息论进行类比，考察预测的图像复杂度（KC）在结构与噪声、以及分布内与分布外熟悉度等轴线上，揭示了与人类直觉的一致性。"
  },
  {
    "id": "arXiv:2507.07990",
    "title": "Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs",
    "authors": "Jeongseok Hyun, Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07990",
    "pdf_link": "https://arxiv.org/pdf/2507.07990",
    "score": 3,
    "abstract": "Video large language models (LLMs) achieve strong video understanding by leveraging a large number of spatio-temporal tokens, but suffer from quadratic computational scaling with token count. To address this, we propose a training-free spatio-temporal token merging method, named STTM. Our key insight is to exploit local spatial and temporal redundancy in video data which has been overlooked in prior work. STTM first transforms each frame into multi-granular spatial tokens using a coarse-to-fine search over a quadtree structure, then performs directed pairwise merging across the temporal dimension. This decomposed merging approach outperforms existing token reduction methods across six video QA benchmarks. Notably, STTM achieves a 2$\\times$ speed-up with only a 0.5% accuracy drop under a 50% token budget, and a 3$\\times$ speed-up with just a 2% drop under a 30% budget. Moreover, STTM is query-agnostic, allowing KV cache reuse across different questions for the same video. The project page is available at https://www.jshyun.me/projects/sttm.",
    "chinese_title": "多粒度时空令牌合并用于训练无关的视频LLM加速",
    "chinese_abstract": "视频大型语言模型 (LLM) 通过利用大量的时空令牌来实现强大的视频理解能力，但其计算规模随着令牌数量的增加而呈二次方增长。为了解决这个问题，我们提出了一种无需训练的时空令牌合并方法，名为 STTM。我们的关键见解是利用视频数据中被先前工作忽视的局部时空冗余。STTM 首先使用四叉树结构进行粗到细的搜索，将每一帧转换为多粒度的空间令牌，然后执行跨时间维度的定向成对合并。这种分解的合并方法在六个视频问答基准测试中优于现有的令牌减少方法。值得注意的是，STTM 在 50% 的令牌预算下实现了 2 倍的加速，准确率仅下降 0.5%，在 30% 的预算下实现了 3 倍的加速，准确率仅下降 2%。此外，STTM 与查询无关，允许在同一视频的不同问题之间重用 KV 缓存。项目页面地址为 https://www.jshyun.me/projects/sttm。"
  },
  {
    "id": "arXiv:2507.07986",
    "title": "EXPO: Stable Reinforcement Learning with Expressive Policies",
    "authors": "Perry Dong, Qiyang Li, Dorsa Sadigh, Chelsea Finn",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07986",
    "pdf_link": "https://arxiv.org/pdf/2507.07986",
    "score": 4,
    "abstract": "We study the problem of training and fine-tuning expressive policies with online reinforcement learning (RL) given an offline dataset. Training expressive policy classes with online RL present a unique challenge of stable value maximization. Unlike simpler Gaussian policies commonly used in online RL, expressive policies like diffusion and flow-matching policies are parameterized by a long denoising chain, which hinders stable gradient propagation from actions to policy parameters when optimizing against some value function. Our key insight is that we can address stable value maximization by avoiding direct optimization over value with the expressive policy and instead construct an on-the-fly RL policy to maximize Q-value. We propose Expressive Policy Optimization (EXPO), a sample-efficient online RL algorithm that utilizes an on-the-fly policy to maximize value with two parameterized policies -- a larger expressive base policy trained with a stable imitation learning objective and a light-weight Gaussian edit policy that edits the actions sampled from the base policy toward a higher value distribution. The on-the-fly policy optimizes the actions from the base policy with the learned edit policy and chooses the value maximizing action from the base and edited actions for both sampling and temporal-difference (TD) backup. Our approach yields up to 2-3x improvement in sample efficiency on average over prior methods both in the setting of fine-tuning a pretrained policy given offline data and in leveraging offline data to train online.",
    "chinese_title": "EXPO：具有表达策略的稳定强化学习",
    "chinese_abstract": "我们研究了在给定离线数据集的情况下，使用在线强化学习 (RL) 训练和微调表达策略的问题。使用在线 RL 训练具有表达力的策略类别，面临着稳定价值最大化的独特挑战。与在线 RL 中常用的简单高斯策略不同，扩散和流匹配策略等表达策略由一个长的去噪链参数化，这会阻碍从动作到策略参数的稳定梯度传播，从而针对某个价值函数进行优化。我们的关键见解是，我们可以通过避免使用表达策略直接优化价值，而是构建一个即时 RL 策略来最大化 Q 值，从而解决稳定的价值最大化问题。我们提出了表达策略优化 (EXPO)，这是一种样本高效的在线 RL 算法，它利用即时策略来最大化价值，并使用两种参数化策略——一个使用稳定模仿学习目标训练的更大的表达基础策略，以及一个编辑来自基础策略的动作以朝向更高价值分布的轻量级高斯编辑策略。即时策略使用学习到的编辑策略优化来自基础策略的动作，并从基础策略和编辑后的动作中选择最大化价值的动作，用于采样和时序差分 (TD) 备份。我们的方法在微调给定离线数据的预训练策略和利用离线数据进行在线训练的环境中，平均比以前的方法提高了 2-3 倍的样本效率。"
  },
  {
    "id": "arXiv:2507.07983",
    "title": "Performance and Practical Considerations of Large and Small Language Models in Clinical Decision Support in Rheumatology",
    "authors": "Sabine Felde, Rüdiger Buchkremer, Gamal Chehab, Christian Thielscher, Jörg HW Distler, Matthias Schneider, Jutta G. Richter",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07983",
    "pdf_link": "https://arxiv.org/pdf/2507.07983",
    "score": 4,
    "abstract": "Large language models (LLMs) show promise for supporting clinical decision-making in complex fields such as rheumatology. Our evaluation shows that smaller language models (SLMs), combined with retrieval-augmented generation (RAG), achieve higher diagnostic and therapeutic performance than larger models, while requiring substantially less energy and enabling cost-efficient, local deployment. These features are attractive for resource-limited healthcare. However, expert oversight remains essential, as no model consistently reached specialist-level accuracy in rheumatology.",
    "chinese_title": "大型和小型语言模型在风湿病临床决策支持中的性能与实际考量",
    "chinese_abstract": "大型语言模型 (LLM) 在风湿病等复杂领域支持临床决策方面显示出潜力。我们的评估表明，结合检索增强生成 (RAG) 的小型语言模型 (SLM) 在诊断和治疗方面优于大型模型，同时所需的能量大大减少，并能够实现经济高效的本地部署。这些特性对于资源有限的医疗保健具有吸引力。然而，专家监督仍然至关重要，因为没有模型在风湿病领域始终达到专家级别的准确性。"
  },
  {
    "id": "arXiv:2507.07982",
    "title": "Geometry Forcing: Marrying Video Diffusion and 3D Representation for Consistent World Modeling",
    "authors": "Haoyu Wu, Diankun Wu, Tianyu He, Junliang Guo, Yang Ye, Yueqi Duan, Jiang Bian",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07982",
    "pdf_link": "https://arxiv.org/pdf/2507.07982",
    "score": 3,
    "abstract": "Videos inherently represent 2D projections of a dynamic 3D world. However, our analysis suggests that video diffusion models trained solely on raw video data often fail to capture meaningful geometric-aware structure in their learned representations. To bridge this gap between video diffusion models and the underlying 3D nature of the physical world, we propose Geometry Forcing, a simple yet effective method that encourages video diffusion models to internalize latent 3D representations. Our key insight is to guide the model's intermediate representations toward geometry-aware structure by aligning them with features from a pretrained geometric foundation model. To this end, we introduce two complementary alignment objectives: Angular Alignment, which enforces directional consistency via cosine similarity, and Scale Alignment, which preserves scale-related information by regressing unnormalized geometric features from normalized diffusion representation. We evaluate Geometry Forcing on both camera view-conditioned and action-conditioned video generation tasks. Experimental results demonstrate that our method substantially improves visual quality and 3D consistency over the baseline methods. Project page: https://GeometryForcing.github.io.",
    "chinese_title": "几何强制：融合视频扩散与3D表示以实现一致的世界建模",
    "chinese_abstract": "视频本质上是动态3D世界的2D投影。然而，我们的分析表明，仅在原始视频数据上训练的视频扩散模型通常无法在其学习的表示中捕获有意义的几何感知结构。为了弥合视频扩散模型与物理世界潜在3D本质之间的差距，我们提出了几何强制，这是一种简单而有效的方法，可以鼓励视频扩散模型内化潜在的3D表示。我们的关键见解是通过与预训练的几何基础模型的功能对齐，引导模型的中间表示朝向几何感知结构。为此，我们引入了两个互补的对齐目标：角度对齐，通过余弦相似度强制方向一致性；以及尺度对齐，通过回归归一化扩散表示中的未归一化几何特征来保持与尺度相关的信息。我们在相机视角条件和动作条件视频生成任务上评估了几何强制。实验结果表明，与基线方法相比，我们的方法大大提高了视觉质量和3D一致性。项目页面：https://GeometryForcing.github.io"
  },
  {
    "id": "arXiv:2507.07981",
    "title": "Why is Your Language Model a Poor Implicit Reward Model?",
    "authors": "Noam Razin, Yong Lin, Jiarui Yao, Sanjeev Arora",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Machine Learning (stat.ML)",
    "abs_link": "https://arxiv.org/abs/2507.07981",
    "pdf_link": "https://arxiv.org/pdf/2507.07981",
    "score": 4,
    "abstract": "Reward models are key to language model post-training and inference pipelines. Conveniently, recent work showed that every language model defines an implicit reward model (IM-RM), without requiring any architectural changes. However, such IM-RMs tend to generalize worse, especially out-of-distribution, compared to explicit reward models (EX-RMs) that apply a dedicated linear head over the hidden representations of a language model. The existence of a generalization gap is puzzling, as EX-RMs and IM-RMs are nearly identical. They can be trained using the same data, loss function, and language model, and differ only in how the reward is computed. Towards a fundamental understanding of the implicit biases underlying different reward model types, we investigate the root cause of this gap. Our main finding, backed by theory and experiments, is that IM-RMs rely more heavily on superficial token-level cues. Consequently, they often generalize worse than EX-RMs under token-level distribution shifts, as well as in-distribution. Furthermore, we provide evidence against alternative hypotheses for the generalization gap. Most notably, we challenge the intuitive claim that IM-RMs struggle in tasks where generation is harder than verification because they can operate both as a verifier and a generator. Taken together, our results highlight that seemingly minor design choices can substantially impact the generalization behavior of reward models.",
    "chinese_title": "为什么你的语言模型是一个糟糕的隐式奖励模型？",
    "chinese_abstract": "奖励模型是语言模型后训练和推理流程的关键。最近的研究表明，每个语言模型都定义了一个隐式奖励模型（IM-RM），无需任何架构更改。然而，与应用在语言模型隐藏表示上的专用线性头的显式奖励模型（EX-RM）相比，这种IM-RM往往泛化能力更差，尤其是在分布外的情况下。这种泛化差距的存在令人困惑，因为EX-RM和IM-RM几乎相同。它们可以使用相同的数据、损失函数和语言模型进行训练，并且仅在奖励的计算方式上有所不同。为了从根本上理解不同奖励模型类型背后的隐式偏差，我们研究了这种差距的根本原因。我们的主要发现，通过理论和实验支持，是IM-RM更依赖于表面的token级别线索。因此，它们通常在token级别分布偏移以及在分布内的情况下，比EX-RM泛化能力更差。此外，我们提供了反驳替代假设的证据，以解释泛化差距。最值得注意的是，我们挑战了IM-RM在生成比验证更困难的任务中表现不佳，因为它们可以同时作为验证器和生成器运行的直观观点。总而言之，我们的结果强调，看似微小的设计选择可以对奖励模型的泛化行为产生重大影响。"
  },
  {
    "id": "arXiv:2507.07969",
    "title": "Reinforcement Learning with Action Chunking",
    "authors": "Qiyang Li, Zhiyuan Zhou, Sergey Levine",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Robotics (cs.RO); Machine Learning (stat.ML)",
    "abs_link": "https://arxiv.org/abs/2507.07969",
    "pdf_link": "https://arxiv.org/pdf/2507.07969",
    "score": 3,
    "abstract": "We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.",
    "chinese_title": "带有动作分块的强化学习",
    "chinese_abstract": "我们提出了Q-分块，这是一种简单而有效的配方，用于改进针对长视野、稀疏奖励任务的强化学习（RL）算法。我们的配方专为离线到在线RL设置而设计，其目标是利用离线先验数据集来最大化在线学习的样本效率。有效的探索和样本高效的学习仍然是该设置中的核心挑战，因为如何利用离线数据来获得良好的探索策略并不明显。我们的关键见解是，动作分块（一种在模仿学习中流行的技术，在该技术中预测未来动作序列而不是每个时间步的单个动作）可以应用于基于时序差分（TD）的RL方法，以减轻探索挑战。Q-分块通过直接在“分块”动作空间中运行RL来采用动作分块，使智能体能够（1）利用离线数据中时间一致的行为进行更有效的在线探索，以及（2）使用无偏的n步备份进行更稳定和高效的TD学习。我们的实验结果表明，Q-分块表现出强大的离线性能和在线样本效率，在各种长视野、稀疏奖励操作任务上优于先前的最佳离线到在线方法。"
  },
  {
    "id": "arXiv:2507.07966",
    "title": "Scaling RL to Long Videos",
    "authors": "Yukang Chen, Wei Huang, Baifeng Shi, Qinghao Hu, Hanrong Ye, Ligeng Zhu, Zhijian Liu, Pavlo Molchanov, Jan Kautz, Xiaojuan Qi, Sifei Liu, Hongxu Yin, Yao Lu, Song Han",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07966",
    "pdf_link": "https://arxiv.org/pdf/2507.07966",
    "score": 4,
    "abstract": "We introduce a full-stack framework that scales up reasoning in vision-language models (VLMs) to long videos, leveraging reinforcement learning. We address the unique challenges of long video reasoning by integrating three critical components: (1) a large-scale dataset, LongVideo-Reason, comprising 52K long video QA pairs with high-quality reasoning annotations across diverse domains such as sports, games, and vlogs; (2) a two-stage training pipeline that extends VLMs with chain-of-thought supervised fine-tuning (CoT-SFT) and reinforcement learning (RL); and (3) a training infrastructure for long video RL, named Multi-modal Reinforcement Sequence Parallelism (MR-SP), which incorporates sequence parallelism and a vLLM-based engine tailored for long video, using cached video embeddings for efficient rollout and prefilling. In experiments, LongVILA-R1-7B achieves strong performance on long video QA benchmarks such as VideoMME. It also outperforms Video-R1-7B and even matches Gemini-1.5-Pro across temporal reasoning, goal and purpose reasoning, spatial reasoning, and plot reasoning on our LongVideo-Reason-eval benchmark. Notably, our MR-SP system achieves up to 2.1x speedup on long video RL training. LongVILA-R1 demonstrates consistent performance gains as the number of input video frames scales. LongVILA-R1 marks a firm step towards long video reasoning in VLMs. In addition, we release our training system for public availability that supports RL training on various modalities (video, text, and audio), various models (VILA and Qwen series), and even image and video generation models. On a single A100 node (8 GPUs), it supports RL training on hour-long videos (e.g., 3,600 frames / around 256k tokens).",
    "chinese_title": "将强化学习扩展到长视频",
    "chinese_abstract": "我们介绍了一个完整的框架，该框架利用强化学习扩展了视觉-语言模型 (VLM) 在长视频中的推理能力。我们通过集成三个关键组件来解决长视频推理的独特挑战：(1) 一个大规模数据集 LongVideo-Reason，包含 52K 个长视频问答对，以及涵盖体育、游戏和博客等不同领域的、高质量的推理标注；(2) 一个两阶段训练流程，该流程通过思维链监督微调 (CoT-SFT) 和强化学习 (RL) 扩展 VLM；(3) 一个用于长视频 RL 的训练基础设施，名为多模态强化序列并行 (MR-SP)，它结合了序列并行和基于 vLLM 的引擎，专为长视频设计，使用缓存的视频嵌入以实现高效的回滚和预填充。在实验中，LongVILA-R1-7B 在 VideoMME 等长视频问答基准测试中取得了强大的性能。它甚至在 LongVideo-Reason-eval 基准测试中，在时间推理、目标和目的推理、空间推理和情节推理方面优于 Video-R1-7B，并与 Gemini-1.5-Pro 相匹配。值得注意的是，我们的 MR-SP 系统在长视频 RL 训练中实现了高达 2.1 倍的加速。LongVILA-R1 演示了随着输入视频帧数量的增加，性能持续提升。LongVILA-R1 标志着 VLM 在长视频推理方面迈出了坚实的一步。此外，我们还发布了我们的训练系统，供公众使用，该系统支持各种模态（视频、文本和音频）、各种模型（VILA 和 Qwen 系列），甚至图像和视频生成模型的 RL 训练。在单个 A100 节点（8 个 GPU）上，它支持对时长视频（例如，3,600 帧 / 约 256k 个 token）进行 RL 训练。"
  },
  {
    "id": "arXiv:2507.07957",
    "title": "MIRIX: Multi-Agent Memory System for LLM-Based Agents",
    "authors": "Yu Wang, Xi Chen",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07957",
    "pdf_link": "https://arxiv.org/pdf/2507.07957",
    "score": 5,
    "abstract": "Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.",
    "chinese_title": "MIRIX：基于LLM的代理的多代理记忆系统",
    "chinese_abstract": "尽管人工智能代理的记忆能力越来越受到关注，但现有解决方案仍然存在根本性的局限性。大多数依赖于扁平、范围狭窄的记忆组件，限制了它们个性化、抽象和可靠地回忆用户特定信息的能力。为此，我们引入MIRIX，一个模块化的多代理记忆系统，它重新定义了人工智能记忆的未来，解决了该领域最关键的挑战：使语言模型真正记住。与先前的研究不同，MIRIX超越了文本，拥抱丰富的视觉和多模态体验，使记忆在现实场景中真正有用。MIRIX由六种不同的、精心构建的记忆类型组成：核心记忆、情景记忆、语义记忆、程序记忆、资源记忆和知识库，并结合了一个多代理框架，动态控制和协调更新和检索。这种设计使代理能够持久化、推理和准确检索各种各样的大规模长期用户数据。我们在两个具有挑战性的环境中验证了MIRIX。首先，在ScreenshotVQA上，这是一个具有挑战性的多模态基准，包含近20,000张高分辨率计算机截图序列，需要深入的上下文理解，并且没有现有的记忆系统可以应用，MIRIX的准确率比RAG基线高35%，同时将存储需求降低了99.9%。其次，在LOCOMO上，一个具有单模态文本输入的长篇对话基准，MIRIX达到了最先进的性能85.4%，远超现有基线。这些结果表明，MIRIX为增强记忆的LLM代理设定了新的性能标准。为了让用户体验我们的记忆系统，我们提供了一个由MIRIX驱动的打包应用程序。它实时监控屏幕，构建个性化的记忆库，并提供直观的可视化和安全的本地存储以确保隐私。"
  },
  {
    "id": "arXiv:2507.07947",
    "title": "Low Resource Reconstruction Attacks Through Benign Prompts",
    "authors": "Sol Yarkoni, Roi Livni",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07947",
    "pdf_link": "https://arxiv.org/pdf/2507.07947",
    "score": 3,
    "abstract": "The recent advances in generative models such as diffusion models have raised several risks and concerns related to privacy, copyright infringements and data stewardship. To better understand and control the risks, various researchers have created techniques, experiments and attacks that reconstruct images, or part of images, from the training set. While these techniques already establish that data from the training set can be reconstructed, they often rely on high-resources, excess to the training set as well as well-engineered and designed prompts.   In this work, we devise a new attack that requires low resources, assumes little to no access to the actual training set, and identifies, seemingly, benign prompts that lead to potentially-risky image reconstruction. This highlights the risk that images might even be reconstructed by an uninformed user and unintentionally. For example, we identified that, with regard to one existing model, the prompt ``blue Unisex T-Shirt'' can generate the face of a real-life human model. Our method builds on an intuition from previous works which leverages domain knowledge and identifies a fundamental vulnerability that stems from the use of scraped data from e-commerce platforms, where templated layouts and images are tied to pattern-like prompts.",
    "chinese_title": "通过良性提示进行低资源重建攻击",
    "chinese_abstract": "生成模型的最新进展，如扩散模型，引发了与隐私、版权侵权和数据管理相关的多种风险和担忧。为了更好地理解和控制这些风险，各种研究人员已经创建了技术、实验和攻击，这些技术、实验和攻击可以从训练集中重建图像或图像的一部分。虽然这些技术已经证明了训练集中的数据可以被重建，但它们通常依赖于高资源、对训练集的访问以及精心设计和工程化的提示。 在这项工作中，我们设计了一种新的攻击方法，该方法需要低资源，假设对实际训练集几乎没有或根本没有访问权限，并识别出看似良性的提示，这些提示会导致潜在的风险图像重建。这凸显了即使是不了解情况的用户也可能无意中重建图像的风险。例如，我们发现，对于一个现有的模型，提示“蓝色中性T恤”可以生成真实人类模特的面部。我们的方法基于先前工作的直觉，利用领域知识并识别出源于从电子商务平台抓取数据的使用的一个基本漏洞，在这些平台上，模板布局和图像与类似提示相关联。"
  },
  {
    "id": "arXiv:2507.07910",
    "title": "DTECT: Dynamic Topic Explorer & Context Tracker",
    "authors": "Suman Adhya, Debarshi Kumar Sanyal",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)",
    "abs_link": "https://arxiv.org/abs/2507.07910",
    "pdf_link": "https://arxiv.org/pdf/2507.07910",
    "score": 4,
    "abstract": "The explosive growth of textual data over time presents a significant challenge in uncovering evolving themes and trends. Existing dynamic topic modeling techniques, while powerful, often exist in fragmented pipelines that lack robust support for interpretation and user-friendly exploration. We introduce DTECT (Dynamic Topic Explorer & Context Tracker), an end-to-end system that bridges the gap between raw textual data and meaningful temporal insights. DTECT provides a unified workflow that supports data preprocessing, multiple model architectures, and dedicated evaluation metrics to analyze the topic quality of temporal topic models. It significantly enhances interpretability by introducing LLM-driven automatic topic labeling, trend analysis via temporally salient words, interactive visualizations with document-level summarization, and a natural language chat interface for intuitive data querying. By integrating these features into a single, cohesive platform, DTECT empowers users to more effectively track and understand thematic dynamics. DTECT is open-source and available at https://github.com/AdhyaSuman/DTECT.",
    "chinese_title": "DTECT：动态主题探索器与上下文追踪器",
    "chinese_abstract": "随着文本数据爆炸式增长，揭示不断演变的主题和趋势变得极具挑战性。现有的动态主题建模技术虽然强大，但通常存在于碎片化的流程中，缺乏对解释性和用户友好探索的强有力支持。我们引入DTECT（动态主题探索器与上下文追踪器），一个端到端的系统，弥合了原始文本数据与有意义的时间洞察之间的差距。DTECT提供了一个统一的工作流程，支持数据预处理、多种模型架构以及专门的评估指标来分析时间主题模型的质量。它通过引入LLM驱动的自动主题标注、通过时间显著词进行趋势分析、具有文档级别摘要的交互式可视化以及用于直观数据查询的自然语言聊天界面，显著增强了解释性。通过将这些功能集成到一个单一、连贯的平台中，DTECT使用户能够更有效地跟踪和理解主题动态。DTECT是开源的，网址为https://github.com/AdhyaSuman/DTECT。"
  },
  {
    "id": "arXiv:2507.07906",
    "title": "Agentic Retrieval of Topics and Insights from Earnings Calls",
    "authors": "Anant Gupta, Rajarshi Bhowmik, Geoffrey Gunow",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07906",
    "pdf_link": "https://arxiv.org/pdf/2507.07906",
    "score": 4,
    "abstract": "Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.",
    "chinese_title": "基于代理的收益电话会议主题和洞察的检索",
    "chinese_abstract": "跟踪公司在收益电话会议中的战略重点是金融分析中的一项关键任务。然而，随着行业的发展，传统的Topic Modeling技术难以动态捕捉新兴主题及其关系。在这项工作中，我们提出了一种由LLM代理驱动的方法，从季度收益电话会议中发现和检索新兴主题。我们提出一个LLM代理来提取文档中的主题，将它们构建成一个分层本体，并通过主题本体建立新主题与现有主题之间的关系。我们展示了使用提取的主题来推断公司层面的洞察和随时间推移的新兴趋势。我们通过衡量本体一致性、主题演化准确性以及它揭示新兴金融趋势的能力来评估我们的方法。"
  },
  {
    "id": "arXiv:2507.07871",
    "title": "Mitigating Watermark Stealing Attacks in Generative Models via Multi-Key Watermarking",
    "authors": "Toluwani Aremu, Noor Hussein, Munachiso Nwadike, Samuele Poppi, Jie Zhang, Karthik Nandakumar, Neil Gong, Nils Lukas",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07871",
    "pdf_link": "https://arxiv.org/pdf/2507.07871",
    "score": 3,
    "abstract": "Watermarking offers a promising solution for GenAI providers to establish the provenance of their generated content. A watermark is a hidden signal embedded in the generated content, whose presence can later be verified using a secret watermarking key. A threat to GenAI providers are \\emph{watermark stealing} attacks, where users forge a watermark into content that was \\emph{not} generated by the provider's models without access to the secret key, e.g., to falsely accuse the provider. Stealing attacks collect \\emph{harmless} watermarked samples from the provider's model and aim to maximize the expected success rate of generating \\emph{harmful} watermarked samples. Our work focuses on mitigating stealing attacks while treating the underlying watermark as a black-box. Our contributions are: (i) Proposing a multi-key extension to mitigate stealing attacks that can be applied post-hoc to any watermarking method across any modality. (ii) We provide theoretical guarantees and demonstrate empirically that our method makes forging substantially less effective across multiple datasets, and (iii) we formally define the threat of watermark forging as the task of generating harmful, watermarked content and model this threat via security games.",
    "chinese_title": "通过多密钥水印缓解生成模型中的水印窃取攻击",
    "chinese_abstract": "水印为 GenAI 提供商提供了一种有前景的解决方案，用于建立其生成内容的溯源性。水印是一种嵌入到生成内容中的隐藏信号，稍后可以使用秘密水印密钥对其存在进行验证。GenAI 提供商面临的威胁是\\emph{水印窃取}攻击，用户在没有访问秘密密钥的情况下，将水印伪造到\\emph{未}由提供商的模型生成的內容中，例如，为了虚假指责提供商。窃取攻击会收集来自提供商模型的\\emph{无害}水印样本，并旨在最大化生成\\emph{有害}水印样本的预期成功率。我们的工作侧重于在将底层水印视为黑盒的情况下缓解窃取攻击。我们的贡献是：（i）提出了一种多密钥扩展，可以事后应用于任何水印方法和任何模态，以缓解窃取攻击；(ii) 我们提供了理论保证，并经验性地证明我们的方法可以使伪造变得不那么有效，涵盖多个数据集；(iii) 我们正式定义了水印伪造的威胁，即生成有害的水印内容，并通过安全博弈来模拟该威胁。"
  },
  {
    "id": "arXiv:2507.07868",
    "title": "Alpay Algebra V: Multi-Layered Semantic Games and Transfinite Fixed-Point Simulation",
    "authors": "Bugra Kilictas, Faruk Alpay",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07868",
    "pdf_link": "https://arxiv.org/pdf/2507.07868",
    "score": 4,
    "abstract": "This paper extends the self-referential framework of Alpay Algebra into a multi-layered semantic game architecture where transfinite fixed-point convergence encompasses hierarchical sub-games at each iteration level. Building upon Alpay Algebra IV's empathetic embedding concept, we introduce a nested game-theoretic structure where the alignment process between AI systems and documents becomes a meta-game containing embedded decision problems. We formalize this through a composite operator $\\phi(\\cdot, \\gamma(\\cdot))$ where $\\phi$ drives the main semantic convergence while $\\gamma$ resolves local sub-games. The resulting framework demonstrates that game-theoretic reasoning emerges naturally from fixed-point iteration rather than being imposed externally. We prove a Game Theorem establishing existence and uniqueness of semantic equilibria under realistic cognitive simulation assumptions. Our verification suite includes adaptations of Banach's fixed-point theorem to transfinite contexts, a novel $\\phi$-topology based on the Kozlov-Maz'ya-Rossmann formula for handling semantic singularities, and categorical consistency tests via the Yoneda lemma. The paper itself functions as a semantic artifact designed to propagate its fixed-point patterns in AI embedding spaces -- a deliberate instantiation of the \"semantic virus\" concept it theorizes. All results are grounded in category theory, information theory, and realistic AI cognition models, ensuring practical applicability beyond pure mathematical abstraction.",
    "chinese_title": "Alpay 代数 V：多层语义博弈与超限不动点模拟",
    "chinese_abstract": "本文将 Alpay 代数的自指框架扩展到多层语义博弈架构，其中超限不动点收敛涵盖了每个迭代层级的分层子博弈。在 Alpay 代数 IV 的同理心嵌入概念的基础上，我们引入了一种嵌套博弈论结构，其中人工智能系统与文档之间的对齐过程成为包含嵌入式决策问题的元博弈。我们通过复合算子 φ(·, γ(·)) 将其形式化，其中 φ 驱动主要的语义收敛，而 γ 解决局部子博弈。由此产生的框架表明，博弈论推理是从不动点迭代中自然涌现的，而不是外部强加的。我们证明了一个博弈定理，在现实的认知模拟假设下，建立了语义均衡的存在性和唯一性。我们的验证套件包括 Banach 不动点定理对超限背景的改编，基于 Kozlov-Maz'ya-Rossmann 公式处理语义奇点的新的 φ-拓扑，以及通过 Yoneda 引理进行的范畴一致性测试。本文本身作为一个语义制品，旨在传播其在人工智能嵌入空间中的不动点模式——这是其理论化的“语义病毒”概念的故意实例化。所有结果都基于范畴论、信息论和现实的人工智能认知模型，确保了超越纯数学抽象的实际适用性。"
  },
  {
    "id": "arXiv:2507.07847",
    "title": "From Ambiguity to Accuracy: The Transformative Effect of Coreference Resolution on Retrieval-Augmented Generation systems",
    "authors": "Youngjoon Jang, Seongtae Hong, Junyoung Son, Sungjin Park, Chanjun Park, Heuiseok Lim",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07847",
    "pdf_link": "https://arxiv.org/pdf/2507.07847",
    "score": 4,
    "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a crucial framework in natural language processing (NLP), improving factual consistency and reducing hallucinations by integrating external document retrieval with large language models (LLMs). However, the effectiveness of RAG is often hindered by coreferential complexity in retrieved documents, introducing ambiguity that disrupts in-context learning. In this study, we systematically investigate how entity coreference affects both document retrieval and generative performance in RAG-based systems, focusing on retrieval relevance, contextual understanding, and overall response quality. We demonstrate that coreference resolution enhances retrieval effectiveness and improves question-answering (QA) performance. Through comparative analysis of different pooling strategies in retrieval tasks, we find that mean pooling demonstrates superior context capturing ability after applying coreference resolution. In QA tasks, we discover that smaller models benefit more from the disambiguation process, likely due to their limited inherent capacity for handling referential ambiguity. With these findings, this study aims to provide a deeper understanding of the challenges posed by coreferential complexity in RAG, providing guidance for improving retrieval and generation in knowledge-intensive AI applications.",
    "chinese_title": "从歧义到准确：核心指代消解对检索增强生成系统的变革性影响",
    "chinese_abstract": "检索增强生成 (RAG) 已成为自然语言处理 (NLP) 中的一个关键框架，通过将外部文档检索与大型语言模型 (LLM) 集成，提高了事实一致性并减少了幻觉。然而，RAG 的有效性通常受到检索文档中指代复杂性的阻碍，引入了破坏上下文学习的歧义。在本研究中，我们系统地研究了实体指代消解如何影响 RAG 系统中的文档检索和生成性能，重点关注检索相关性、上下文理解和整体响应质量。我们证明了指代消解可以提高检索效果并改善问答 (QA) 性能。通过对检索任务中不同池化策略的比较分析，我们发现平均池化在应用指代消解后表现出更优越的上下文捕获能力。在 QA 任务中，我们发现较小的模型更能从消歧过程中受益，这可能是由于它们处理指代歧义的固有能力有限。通过这些发现，本研究旨在更深入地了解 RAG 中指代复杂性带来的挑战，为改进知识密集型 AI 应用程序中的检索和生成提供指导。"
  },
  {
    "id": "arXiv:2507.07828",
    "title": "Benchmarking Content-Based Puzzle Solvers on Corrupted Jigsaw Puzzles",
    "authors": "Richard Dirauf, Florian Wolz, Dario Zanca, Björn Eskofier",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07828",
    "pdf_link": "https://arxiv.org/pdf/2507.07828",
    "score": 3,
    "abstract": "Content-based puzzle solvers have been extensively studied, demonstrating significant progress in computational techniques. However, their evaluation often lacks realistic challenges crucial for real-world applications, such as the reassembly of fragmented artefacts or shredded documents. In this work, we investigate the robustness of State-Of-The-Art content-based puzzle solvers introducing three types of jigsaw puzzle corruptions: missing pieces, eroded edges, and eroded contents. Evaluating both heuristic and deep learning-based solvers, we analyse their ability to handle these corruptions and identify key limitations. Our results show that solvers developed for standard puzzles have a rapid decline in performance if more pieces are corrupted. However, deep learning models can significantly improve their robustness through fine-tuning with augmented data. Notably, the advanced Positional Diffusion model adapts particularly well, outperforming its competitors in most experiments. Based on our findings, we highlight promising research directions for enhancing the automated reconstruction of real-world artefacts.",
    "chinese_title": "基于内容的拼图求解器在损坏的拼图上的基准测试",
    "chinese_abstract": "基于内容的拼图求解器已被广泛研究，并在计算技术方面取得了显著进展。然而，它们的评估通常缺乏现实世界的挑战，这对于实际应用至关重要，例如碎片化文物或撕毁文件的重新组装。在这项工作中，我们通过引入三种类型的拼图损坏（缺失碎片、侵蚀边缘和侵蚀内容）来研究最先进的基于内容的拼图求解器的鲁棒性。我们评估了启发式和基于深度学习的求解器，分析了它们处理这些损坏的能力并确定了关键的局限性。我们的结果表明，为标准拼图开发的求解器在更多碎片损坏时性能会迅速下降。然而，通过使用增强数据进行微调，深度学习模型可以显著提高其鲁棒性。值得注意的是，先进的位置扩散模型适应性特别强，在大多数实验中表现优于其竞争对手。基于我们的发现，我们强调了增强现实世界文物自动重建的有希望的研究方向。"
  },
  {
    "id": "arXiv:2507.07817",
    "title": "On the Effect of Instruction Tuning Loss on Generalization",
    "authors": "Anwoy Chatterjee, H S V N S Kowndinya Renduchintala, Sumit Bhatia, Tanmoy Chakraborty",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07817",
    "pdf_link": "https://arxiv.org/pdf/2507.07817",
    "score": 4,
    "abstract": "Instruction Tuning has emerged as a pivotal post-training paradigm that enables pre-trained language models to better follow user instructions. Despite its significance, little attention has been given to optimizing the loss function used. A fundamental, yet often overlooked, question is whether the conventional auto-regressive objective - where loss is computed only on response tokens, excluding prompt tokens - is truly optimal for instruction tuning. In this work, we systematically investigate the impact of differentially weighting prompt and response tokens in instruction tuning loss, and propose Weighted Instruction Tuning (WIT) as a better alternative to conventional instruction tuning. Through extensive experiments on five language models of different families and scale, three finetuning datasets of different sizes, and five diverse evaluation benchmarks, we show that the standard instruction tuning loss often yields suboptimal performance and limited robustness to input prompt variations. We find that a low-to-moderate weight for prompt tokens coupled with a moderate-to-high weight for response tokens yields the best-performing models across settings and also serve as better starting points for the subsequent preference alignment training. These findings highlight the need to reconsider instruction tuning loss and offer actionable insights for developing more robust and generalizable models. Our code is open-sourced at https://github.com/kowndinya-renduchintala/WIT.",
    "chinese_title": "指令微调损失对泛化的影响",
    "chinese_abstract": "指令微调已成为一种重要的后训练范式，使预训练语言模型能够更好地遵循用户指令。尽管其意义重大，但人们很少关注优化所使用的损失函数。一个基本但经常被忽视的问题是，仅在响应标记上计算损失（不包括提示标记）的传统自回归目标是否真正适合指令微调。在这项工作中，我们系统地研究了在指令微调损失中对提示标记和响应标记进行差异化加权的影响，并提出了加权指令微调 (WIT) 作为传统指令微调的更好替代方案。通过在不同系列和规模的五个语言模型、不同大小的三个微调数据集以及五个多样化的评估基准上进行广泛的实验，我们表明标准的指令微调损失通常会产生次优性能，并且对输入提示变化具有有限的鲁棒性。我们发现，对提示标记赋予较低到中等的权重，并对响应标记赋予中等到较高的权重，可以在所有设置中产生最佳性能的模型，并且可以作为后续偏好对齐训练的更好起点。这些发现强调了重新考虑指令微调损失的必要性，并为开发更强大和更具泛化能力的模型提供了可操作的见解。我们的代码已开源，网址为 https://github.com/kowndinya-renduchintala/WIT。"
  },
  {
    "id": "arXiv:2507.07808",
    "title": "Bridging Logic and Learning: Decoding Temporal Logic Embeddings via Transformers",
    "authors": "Sara Candussio, Gaia Saveri, Gabriele Sarti, Luca Bortolussi",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07808",
    "pdf_link": "https://arxiv.org/pdf/2507.07808",
    "score": 4,
    "abstract": "Continuous representations of logic formulae allow us to integrate symbolic knowledge into data-driven learning algorithms. If such embeddings are semantically consistent, i.e. if similar specifications are mapped into nearby vectors, they enable continuous learning and optimization directly in the semantic space of formulae. However, to translate the optimal continuous representation into a concrete requirement, such embeddings must be invertible. We tackle this issue by training a Transformer-based decoder-only model to invert semantic embeddings of Signal Temporal Logic (STL) formulae. STL is a powerful formalism that allows us to describe properties of signals varying over time in an expressive yet concise way. By constructing a small vocabulary from STL syntax, we demonstrate that our proposed model is able to generate valid formulae after only 1 epoch and to generalize to the semantics of the logic in about 10 epochs. Additionally, the model is able to decode a given embedding into formulae that are often simpler in terms of length and nesting while remaining semantically close (or equivalent) to gold references. We show the effectiveness of our methodology across various levels of training formulae complexity to assess the impact of training data on the model's ability to effectively capture the semantic information contained in the embeddings and generalize out-of-distribution. Finally, we deploy our model for solving a requirement mining task, i.e. inferring STL specifications that solve a classification task on trajectories, performing the optimization directly in the semantic space.",
    "chinese_title": "弥合逻辑与学习：通过Transformer解码时序逻辑嵌入",
    "chinese_abstract": "逻辑公式的连续表示允许我们将符号知识整合到数据驱动的学习算法中。如果这些嵌入在语义上一致，即相似的规范被映射到附近的向量，它们将能够在公式的语义空间中实现连续学习和优化。然而，为了将最佳连续表示转换为具体的规范，这些嵌入必须是可逆的。我们通过训练基于Transformer的仅解码器模型来反转信号时序逻辑 (STL) 公式 的语义嵌入来解决这个问题。STL 是一种强大的形式化方法，它允许我们以一种富有表现力但简洁的方式描述随时间变化的信号的属性。通过从 STL 语法中构建一个小词汇表，我们证明了我们提出的模型能够在仅一个 epoch 后生成有效的公式，并在大约 10 个 epoch 后泛化到逻辑的语义。此外，该模型能够将给定的嵌入解码为在长度和嵌套方面通常更简单的公式，同时保持与黄金参考在语义上的接近（或等效）。我们在各种训练公式复杂度的水平上展示了我们方法的有效性，以评估训练数据对模型有效捕获嵌入中包含的语义信息和泛化分布外数据的影响。最后，我们将我们的模型部署于需求挖掘任务中，即推断解决轨迹分类任务的 STL 规范，直接在语义空间中进行优化。"
  },
  {
    "id": "arXiv:2507.07778",
    "title": "Synchronizing Task Behavior: Aligning Multiple Tasks during Test-Time Training",
    "authors": "Wooseong Jeong, Jegyeong Cho, Youngho Yoon, Kuk-Jin Yoon",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.07778",
    "pdf_link": "https://arxiv.org/pdf/2507.07778",
    "score": 4,
    "abstract": "Generalizing neural networks to unseen target domains is a significant challenge in real-world deployments. Test-time training (TTT) addresses this by using an auxiliary self-supervised task to reduce the domain gap caused by distribution shifts between the source and target. However, we find that when models are required to perform multiple tasks under domain shifts, conventional TTT methods suffer from unsynchronized task behavior, where the adaptation steps needed for optimal performance in one task may not align with the requirements of other tasks. To address this, we propose a novel TTT approach called Synchronizing Tasks for Test-time Training (S4T), which enables the concurrent handling of multiple tasks. The core idea behind S4T is that predicting task relations across domain shifts is key to synchronizing tasks during test time. To validate our approach, we apply S4T to conventional multi-task benchmarks, integrating it with traditional TTT protocols. Our empirical results show that S4T outperforms state-of-the-art TTT methods across various benchmarks.",
    "chinese_title": "同步任务行为：测试时训练期间对齐多个任务",
    "chinese_abstract": "将神经网络泛化到未见过的目标领域是现实世界部署中的一个重大挑战。测试时训练 (TTT) 通过使用辅助自监督任务来减少源域和目标域之间的分布差异来解决这个问题。然而，我们发现当模型需要在域偏移下执行多个任务时，传统的 TTT 方法会受到不同步的任务行为的影响，即为在一个任务中实现最佳性能所需的适应步骤可能与其它任务的要求不一致。为了解决这个问题，我们提出了一种新颖的 TTT 方法，称为测试时任务同步 (S4T)，它能够同时处理多个任务。S4T 的核心思想是在域偏移中预测任务关系是同步测试时任务的关键。为了验证我们的方法，我们将 S4T 应用于传统的多任务基准测试，并将其与传统的 TTT 协议集成。我们的实证结果表明，S4T 在各种基准测试中优于最先进的 TTT 方法。"
  },
  {
    "id": "arXiv:2507.07748",
    "title": "When Large Language Models Meet Law: Dual-Lens Taxonomy, Technical Advances, and Ethical Governance",
    "authors": "Peizhang Shao, Linrui Xu, Jinxi Wang, Wei Zhou, Xingyu Wu",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07748",
    "pdf_link": "https://arxiv.org/pdf/2507.07748",
    "score": 4,
    "abstract": "This paper establishes the first comprehensive review of Large Language Models (LLMs) applied within the legal domain. It pioneers an innovative dual lens taxonomy that integrates legal reasoning frameworks and professional ontologies to systematically unify historical research and contemporary breakthroughs. Transformer-based LLMs, which exhibit emergent capabilities such as contextual reasoning and generative argumentation, surmount traditional limitations by dynamically capturing legal semantics and unifying evidence reasoning. Significant progress is documented in task generalization, reasoning formalization, workflow integration, and addressing core challenges in text processing, knowledge integration, and evaluation rigor via technical innovations like sparse attention mechanisms and mixture-of-experts architectures. However, widespread adoption of LLM introduces critical challenges: hallucination, explainability deficits, jurisdictional adaptation difficulties, and ethical asymmetry. This review proposes a novel taxonomy that maps legal roles to NLP subtasks and computationally implements the Toulmin argumentation framework, thus systematizing advances in reasoning, retrieval, prediction, and dispute resolution. It identifies key frontiers including low-resource systems, multimodal evidence integration, and dynamic rebuttal handling. Ultimately, this work provides both a technical roadmap for researchers and a conceptual framework for practitioners navigating the algorithmic future, laying a robust foundation for the next era of legal artificial intelligence. We have created a GitHub repository to index the relevant papers: https://github.com/Kilimajaro/LLMs_Meet_Law.",
    "chinese_title": "大型语言模型与法律：双视角分类法、技术进展与伦理治理",
    "chinese_abstract": "本文建立了第一个关于大型语言模型（LLM）在法律领域应用的全面综述。它开创性地提出了一个创新的双视角分类法，整合了法律推理框架和专业本体，以系统地统一历史研究和当代突破。基于Transformer的LLM，展现出上下文推理和生成论证等涌现能力，通过动态捕捉法律语义和统一证据推理，克服了传统局限性。本文记录了在任务泛化、推理形式化、工作流程集成以及通过稀疏注意力机制和混合专家架构等技术创新解决文本处理、知识整合和评估严谨性等核心挑战方面的重大进展。然而，LLM的广泛应用带来了关键挑战：幻觉、可解释性不足、管辖权适应困难和伦理不对称。本文提出了一种新的分类法，将法律角色映射到NLP子任务，并计算实现图尔敏论证框架，从而系统化推理、检索、预测和争议解决方面的进展。它确定了关键的前沿领域，包括低资源系统、多模态证据整合和动态反驳处理。最终，这项工作为研究人员提供了一份技术路线图，为从业者提供了一个概念框架，以应对算法的未来，为下一代法律人工智能奠定了坚实的基础。我们创建了一个GitHub仓库来索引相关论文：https://github.com/Kilimajaro/LLMs_Meet_Law。"
  },
  {
    "id": "arXiv:2507.07725",
    "title": "Not All Preferences are What You Need for Post-Training: Selective Alignment Strategy for Preference Optimization",
    "authors": "Zhijin Dong",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07725",
    "pdf_link": "https://arxiv.org/pdf/2507.07725",
    "score": 4,
    "abstract": "Post-training alignment of large language models (LLMs) is a critical challenge, as not all tokens contribute equally to model performance. This paper introduces a selective alignment strategy that prioritizes high-impact tokens within preference pairs, leveraging token-level log-probability differences between the current policy and a reference model. By focusing on these informative tokens, our approach reduces computational overhead and enhances alignment fidelity. We further explore the role of reference model quality, demonstrating that stronger reference models significantly improve token selection accuracy and overall optimization effectiveness. Comprehensive experiments on benchmarks such as Arena-Hard and MT-Bench validate the superiority of our Selective-DPO method over standard DPO and distillation-based baselines. Our findings highlight the importance of token-level optimization and reference model selection in advancing preference alignment for LLMs. The code is available at https://github.com/Dongzhijin/SDPO.",
    "chinese_title": "并非所有偏好都是后训练所需要的：用于偏好优化的选择性对齐策略",
    "chinese_abstract": "大型语言模型（LLM）的后训练对齐是一个关键挑战，因为并非所有token都对模型性能贡献相同。本文介绍了一种选择性对齐策略，该策略优先考虑偏好对中的高影响token，利用当前策略和参考模型之间的token级别对数概率差异。通过关注这些信息丰富的token，我们的方法可以减少计算开销并提高对齐保真度。我们进一步探讨了参考模型质量的作用，证明更强的参考模型可以显著提高token选择准确性和整体优化效果。在Arena-Hard和MT-Bench等基准上的全面实验验证了我们的选择性DPO方法优于标准DPO和基于蒸馏的基线方法。我们的研究结果强调了token级别优化和参考模型选择在推进LLM偏好对齐中的重要性。代码可在https://github.com/Dongzhijin/SDPO获取。"
  },
  {
    "id": "arXiv:2507.07695",
    "title": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities",
    "authors": "Hruday Markondapatnaikuni, Basem Suleiman, Abdelkarim Erradi, Shijing Chen",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07695",
    "pdf_link": "https://arxiv.org/pdf/2507.07695",
    "score": 4,
    "abstract": "Fine-tuning is an immensely resource-intensive process when retraining Large Language Models (LLMs) to incorporate a larger body of knowledge. Although many fine-tuning techniques have been developed to reduce the time and computational cost involved, the challenge persists as LLMs continue to grow in size and complexity. To address this, a new approach to knowledge expansion in LLMs is needed. Retrieval-Augmented Generation (RAG) offers one such alternative by storing external knowledge in a database and retrieving relevant chunks to support question answering. However, naive implementations of RAG face significant limitations in scalability and answer accuracy. This paper introduces KeyKnowledgeRAG (K2RAG), a novel framework designed to overcome these limitations. Inspired by the divide-and-conquer paradigm, K2RAG integrates dense and sparse vector search, knowledge graphs, and text summarization to improve retrieval quality and system efficiency. The framework also includes a preprocessing step that summarizes the training data, significantly reducing the training time. K2RAG was evaluated using the MultiHopRAG dataset, where the proposed pipeline was trained on the document corpus and tested on a separate evaluation set. Results demonstrated notable improvements over common naive RAG implementations. K2RAG achieved the highest mean answer similarity score of 0.57, and reached the highest third quartile (Q3) similarity of 0.82, indicating better alignment with ground-truth answers. In addition to improved accuracy, the framework proved highly efficient. The summarization step reduced the average training time of individual components by 93%, and execution speed was up to 40% faster than traditional knowledge graph-based RAG systems. K2RAG also demonstrated superior scalability, requiring three times less VRAM than several naive RAG implementations tested in this study.",
    "chinese_title": "KeyKnowledgeRAG (K²RAG)：一种增强的RAG方法，用于提高LLM问答能力",
    "chinese_abstract": "微调是在LLM中整合更大知识库时，一项极其耗费资源的流程。尽管已经开发了许多微调技术来减少时间和计算成本，但随着LLM的规模和复杂性不断增加，挑战依然存在。为了解决这个问题，需要一种新的LLM知识扩展方法。检索增强生成 (RAG) 提供了一种替代方案，它将外部知识存储在数据库中，并检索相关片段以支持问答。然而，RAG的简单实现面临可扩展性和答案准确性方面的重大限制。本文介绍了一种名为KeyKnowledgeRAG (K2RAG) 的新框架，旨在克服这些限制。K2RAG 受到分治范式的启发，集成了密集和稀疏向量搜索、知识图谱和文本摘要，以提高检索质量和系统效率。该框架还包括一个预处理步骤，对训练数据进行摘要，显著减少训练时间。K2RAG 使用 MultiHopRAG 数据集进行评估，在该数据集中，所提出的管道在文档语料库上进行训练，并在单独的评估集上进行测试。结果表明，与常见的简单 RAG 实现相比，K2RAG 取得了显著的改进。K2RAG 实现了最高的平均答案相似度得分 0.57，并且达到了最高的第三四分位数 (Q3) 相似度 0.82，表明与真实答案的对齐度更高。除了提高准确性外，该框架还被证明具有高度效率。摘要步骤将单个组件的平均训练时间减少了 93%，并且执行速度比传统的基于知识图谱的 RAG 系统快高达 40%。K2RAG 还展示了卓越的可扩展性，所需的 VRAM 比本研究中测试的几种简单 RAG 实现少三倍。"
  },
  {
    "id": "arXiv:2507.07685",
    "title": "Rationale-Enhanced Decoding for Multi-modal Chain-of-Thought",
    "authors": "Shin'ya Yamaguchi, Kosuke Nishida, Daiki Chijiwa",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07685",
    "pdf_link": "https://arxiv.org/pdf/2507.07685",
    "score": 4,
    "abstract": "Large vision-language models (LVLMs) have demonstrated remarkable capabilities by integrating pre-trained vision encoders with large language models (LLMs). Similar to single-modal LLMs, chain-of-thought (CoT) prompting has been adapted for LVLMs to enhance multi-modal reasoning by generating intermediate rationales based on visual and textual inputs. While CoT is assumed to improve grounding and accuracy in LVLMs, our experiments reveal a key challenge: existing LVLMs often ignore the contents of generated rationales in CoT reasoning. To address this, we re-formulate multi-modal CoT reasoning as a KL-constrained reward maximization focused on rationale-conditional log-likelihood. As the optimal solution, we propose rationale-enhanced decoding (RED), a novel plug-and-play inference-time decoding strategy. RED harmonizes visual and rationale information by multiplying distinct image-conditional and rationale-conditional next token distributions. Extensive experiments show that RED consistently and significantly improves reasoning over standard CoT and other decoding methods across multiple benchmarks and LVLMs. Our work offers a practical and effective approach to improve both the faithfulness and accuracy of CoT reasoning in LVLMs, paving the way for more reliable rationale-grounded multi-modal systems.",
    "chinese_title": "基于理性的解码用于多模态思维链",
    "chinese_abstract": "大型视觉-语言模型 (LVLM) 通过集成预训练的视觉编码器和大型语言模型 (LLM) 展现出卓越的能力。类似于单模态 LLM，思维链 (CoT) 提示已被适配用于 LVLM，以通过基于视觉和文本输入生成中间推理依据来增强多模态推理。虽然 CoT 被认为可以提高 LVLM 中的接地性和准确性，但我们的实验揭示了一个关键挑战：现有的 LVLM 常常忽略 CoT 推理中生成的推理依据的内容。为了解决这个问题，我们将多模态 CoT 推理重新构建为一种以 KL 约束的奖励最大化，重点关注推理依据条件下的对数似然。作为最优解，我们提出了基于推理依据的增强解码 (RED)，这是一种新颖的即插即用推理时解码策略。RED 通过将不同的图像条件和推理依据条件下的下一个token分布相乘，来协调视觉和推理依据信息。大量的实验表明，RED 在多个基准和 LVLM 上，始终如一且显著地提高了标准 CoT 和其他解码方法的推理能力。我们的工作为提高 CoT 推理在 LVLM 中的保真度和准确性提供了一种实用且有效的方法，为更可靠的推理依据驱动的多模态系统铺平了道路。"
  },
  {
    "id": "arXiv:2507.07586",
    "title": "Bayesian Discrete Diffusion Beats Autoregressive Perplexity",
    "authors": "Cooper Doyle",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07586",
    "pdf_link": "https://arxiv.org/pdf/2507.07586",
    "score": 3,
    "abstract": "We reveal a hidden Bayesian core of discrete-diffusion language models by showing that the expected denoiser output under the forward masking distribution recovers the exact posterior over clean tokens. Under minimal assumptions, Monte Carlo marginalization over K independent corruptions converges to this posterior at rate O(1/sqrt(K)), yielding a simple proof of consistency and finite-sample error bounds. Building on this insight, we introduce a lightweight inference-time ensemble that averages K mask-and-denoise passes to obtain posterior-aware token probabilities and uncertainty estimates at no extra training cost. On WikiText-2, our method achieves test perplexity 8.8 with K=8, versus 20.3 for GPT-2 Small, despite using a model of comparable size. Code is available at https://github.com/mercury0100/bayesradd.",
    "chinese_title": "贝叶斯离散扩散优于自回归困惑度",
    "chinese_abstract": "我们揭示了离散扩散语言模型中隐藏的贝叶斯核心，通过证明在正向掩码分布下的期望去噪器输出可以恢复干净token的精确后验概率。在最小假设下，对K个独立损坏进行蒙特卡洛边缘化以O(1/sqrt(K))的速度收敛到该后验概率，从而产生一致性和有限样本误差界限的简单证明。基于这一洞察，我们引入了一种轻量级的推理时间集成，它对K次掩码和去噪过程进行平均，以在不增加额外训练成本的情况下获得后验感知token概率和不确定性估计。在WikiText-2上，我们的方法使用K=8时实现了8.8的测试困惑度，而GPT-2 Small为20.3，尽管使用了大小相当的模型。代码可在https://github.com/mercury0100/bayesradd获取。"
  },
  {
    "id": "arXiv:2507.07572",
    "title": "Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation",
    "authors": "Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.07572",
    "pdf_link": "https://arxiv.org/pdf/2507.07572",
    "score": 4,
    "abstract": "Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios.",
    "chinese_title": "基于多模态大型语言模型的单模态到混合模态对齐，用于文档图像机器翻译",
    "chinese_abstract": "文档图像机器翻译 (DIMT) 旨在翻译文档图像中的文本，由于训练数据有限以及视觉和文本信息之间的复杂交互，面临泛化挑战。为了应对这些挑战，我们引入 M4Doc，这是一种新颖的单模态到混合模态对齐框架，利用在大型文档图像数据集上预训练的多模态大型语言模型 (MLLM)。M4Doc 将仅图像编码器与 MLLM 的多模态表示对齐，从而使轻量级的 DIMT 模型能够在训练期间学习关键的视觉-文本相关性。在推理过程中，M4Doc 绕过 MLLM，在受益于其多模态知识的同时保持计算效率。全面的实验表明，翻译质量有了显着提高，尤其是在跨领域泛化和具有挑战性的文档图像场景中。"
  },
  {
    "id": "arXiv:2507.07551",
    "title": "ArchiveGPT: A human-centered evaluation of using a vision language model for image cataloguing",
    "authors": "Line Abele, Gerrit Anders, Tolgahan Aydın, Jürgen Buder, Helen Fischer, Dominik Kimmel, Markus Huff",
    "subjects": "Human-Computer Interaction (cs.HC); Artificial Intelligence (cs.AI); Digital Libraries (cs.DL)",
    "abs_link": "https://arxiv.org/abs/2507.07551",
    "pdf_link": "https://arxiv.org/pdf/2507.07551",
    "score": 3,
    "abstract": "The accelerating growth of photographic collections has outpaced manual cataloguing, motivating the use of vision language models (VLMs) to automate metadata generation. This study examines whether Al-generated catalogue descriptions can approximate human-written quality and how generative Al might integrate into cataloguing workflows in archival and museum collections. A VLM (InternVL2) generated catalogue descriptions for photographic prints on labelled cardboard mounts with archaeological content, evaluated by archive and archaeology experts and non-experts in a human-centered, experimental framework. Participants classified descriptions as AI-generated or expert-written, rated quality, and reported willingness to use and trust in AI tools. Classification performance was above chance level, with both groups underestimating their ability to detect Al-generated descriptions. OCR errors and hallucinations limited perceived quality, yet descriptions rated higher in accuracy and usefulness were harder to classify, suggesting that human review is necessary to ensure the accuracy and quality of catalogue descriptions generated by the out-of-the-box model, particularly in specialized domains like archaeological cataloguing. Experts showed lower willingness to adopt AI tools, emphasizing concerns on preservation responsibility over technical performance. These findings advocate for a collaborative approach where AI supports draft generation but remains subordinate to human verification, ensuring alignment with curatorial values (e.g., provenance, transparency). The successful integration of this approach depends not only on technical advancements, such as domain-specific fine-tuning, but even more on establishing trust among professionals, which could both be fostered through a transparent and explainable AI pipeline.",
    "chinese_title": "ArchiveGPT：使用视觉语言模型进行图像编目的以人为本的评估",
    "chinese_abstract": "摄影收藏的快速增长已经超过了手动编目的速度，促使人们使用视觉语言模型（VLM）来自动化元数据生成。本研究考察了人工智能生成的目录描述是否可以逼近人工撰写的质量，以及生成式人工智能如何融入档案和博物馆收藏的编目工作流程。VLM（InternVL2）为带有考古内容的标记纸板底座上的照片打印生成了目录描述，由档案和考古专家以及非专家在一个以人为本的实验框架中进行评估。参与者将描述分类为人工智能生成或专家撰写，评估质量，并报告使用人工智能工具的意愿和信任度。分类性能高于偶然水平，两组都低估了他们检测人工智能生成描述的能力。OCR错误和幻觉限制了感知质量，但准确性和实用性更高的描述更难分类，这表明需要人工审查以确保由开箱即用的模型生成的目录描述的准确性和质量，尤其是在考古编目等专业领域。专家表现出较低的采用人工智能工具的意愿，强调了对保存责任的担忧超过了技术性能。这些发现倡导了一种协作方法，即人工智能支持草稿生成，但仍然服从于人工验证，以确保与策展价值观（例如，出处、透明度）保持一致。这种方法的成功整合不仅取决于技术进步，例如特定领域的微调，而且更取决于在专业人士中建立信任，这可以通过透明且可解释的人工智能管道来促进。"
  },
  {
    "id": "arXiv:2507.07543",
    "title": "The Cross-Lingual Cost: Retrieval Biases in RAG over Arabic-English Corpora",
    "authors": "Chen Amiraz, Yaroslav Fyodorov, Elad Haramaty, Zohar Karnin, Liane Lewin-Eytan",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Information Retrieval (cs.IR)",
    "abs_link": "https://arxiv.org/abs/2507.07543",
    "pdf_link": "https://arxiv.org/pdf/2507.07543",
    "score": 4,
    "abstract": "Cross-lingual retrieval-augmented generation (RAG) is a critical capability for retrieving and generating answers across languages. Prior work in this context has mostly focused on generation and relied on benchmarks derived from open-domain sources, most notably Wikipedia. In such settings, retrieval challenges often remain hidden due to language imbalances, overlap with pretraining data, and memorized content. To address this gap, we study Arabic-English RAG in a domain-specific setting using benchmarks derived from real-world corporate datasets. Our benchmarks include all combinations of languages for the user query and the supporting document, drawn independently and uniformly at random. This enables a systematic study of multilingual retrieval behavior.   Our findings reveal that retrieval is a critical bottleneck in cross-lingual domain-specific scenarios, with significant performance drops occurring when the user query and supporting document languages differ. A key insight is that these failures stem primarily from the retriever's difficulty in ranking documents across languages. Finally, we propose a simple retrieval strategy that addresses this source of failure by enforcing equal retrieval from both languages, resulting in substantial improvements in cross-lingual and overall performance. These results highlight meaningful opportunities for improving multilingual retrieval, particularly in practical, real-world RAG applications.",
    "chinese_title": "跨语言代价：基于阿拉伯语-英语语料的RAG检索偏差",
    "chinese_abstract": "跨语言检索增强生成 (RAG) 是跨语言检索和生成答案的关键能力。先前的研究主要集中在生成方面，并依赖于来自开放域来源（最著名的是维基百科）的基准测试。在这种情况下，由于语言不平衡、与预训练数据的重叠以及记忆内容，检索挑战通常隐藏在其中。为了弥合这一差距，我们使用来自真实世界企业数据集的基准测试，研究了阿拉伯语-英语 RAG 在特定领域的设置。我们的基准测试包括用户查询和支持文档的所有语言组合，这些组合都是独立且均匀随机抽取的。这使得能够系统地研究多语言检索行为。我们的研究结果表明，检索是跨语言特定领域场景中的一个关键瓶颈，当用户查询和支持文档的语言不同时，性能会显著下降。一个关键的见解是，这些失败主要源于检索器在跨语言对文档进行排序的困难。最后，我们提出了一种简单的检索策略，通过强制从两种语言中平等检索来解决此故障来源，从而显着提高跨语言和整体性能。这些结果突出了改进多语言检索的重大机会，尤其是在实际的、现实世界的 RAG 应用程序中。"
  },
  {
    "id": "arXiv:2507.07539",
    "title": "CEA-LIST at CheckThat! 2025: Evaluating LLMs as Detectors of Bias and Opinion in Text",
    "authors": "Akram Elbouanani, Evan Dufraisse, Aboubacar Tuo, Adrian Popescu",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07539",
    "pdf_link": "https://arxiv.org/pdf/2507.07539",
    "score": 4,
    "abstract": "This paper presents a competitive approach to multilingual subjectivity detection using large language models (LLMs) with few-shot prompting. We participated in Task 1: Subjectivity of the CheckThat! 2025 evaluation campaign. We show that LLMs, when paired with carefully designed prompts, can match or outperform fine-tuned smaller language models (SLMs), particularly in noisy or low-quality data settings. Despite experimenting with advanced prompt engineering techniques, such as debating LLMs and various example selection strategies, we found limited benefit beyond well-crafted standard few-shot prompts. Our system achieved top rankings across multiple languages in the CheckThat! 2025 subjectivity detection task, including first place in Arabic and Polish, and top-four finishes in Italian, English, German, and multilingual tracks. Notably, our method proved especially robust on the Arabic dataset, likely due to its resilience to annotation inconsistencies. These findings highlight the effectiveness and adaptability of LLM-based few-shot learning for multilingual sentiment tasks, offering a strong alternative to traditional fine-tuning, particularly when labeled data is scarce or inconsistent.",
    "chinese_title": "CEA-LIST 在 CheckThat! 2025 竞赛中的表现：评估 LLM 作为文本偏见和观点检测器",
    "chinese_abstract": "本文介绍了一种在多语言主观性检测中使用大型语言模型 (LLM) 进行少样本提示的竞争性方法。我们参加了 CheckThat! 2025 评估活动的 Task 1：主观性任务。我们表明，当与精心设计的提示相结合时，LLM 可以匹配或胜过微调的小型语言模型 (SLM)，尤其是在噪声或低质量数据环境中。尽管我们尝试了先进的提示工程技术，例如辩论 LLM 和各种示例选择策略，但我们发现除了精心制作的标准少样本提示之外，收益有限。我们的系统在 CheckThat! 2025 主观性检测任务的多种语言中取得了领先排名，包括在阿拉伯语和波兰语中获得第一名，并在意大利语、英语、德语和多语言赛道中进入前四名。值得注意的是，我们的方法在阿拉伯语数据集上表现特别鲁棒，这可能归因于其对标注不一致的抵抗力。这些发现突出了基于 LLM 的少样本学习在多语言情感任务中的有效性和适应性，为传统的微调提供了一种强大的替代方案，尤其是在标记数据稀缺或不一致时。"
  },
  {
    "id": "arXiv:2507.07532",
    "title": "Neural Concept Verifier: Scaling Prover-Verifier Games via Concept Encodings",
    "authors": "Berkant Turan, Suhrab Asadulla, David Steinmann, Wolfgang Stammer, Sebastian Pokutta",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07532",
    "pdf_link": "https://arxiv.org/pdf/2507.07532",
    "score": 4,
    "abstract": "While Prover-Verifier Games (PVGs) offer a promising path toward verifiability in nonlinear classification models, they have not yet been applied to complex inputs such as high-dimensional images. Conversely, Concept Bottleneck Models (CBMs) effectively translate such data into interpretable concepts but are limited by their reliance on low-capacity linear predictors. In this work, we introduce the Neural Concept Verifier (NCV), a unified framework combining PVGs with concept encodings for interpretable, nonlinear classification in high-dimensional settings. NCV achieves this by utilizing recent minimally supervised concept discovery models to extract structured concept encodings from raw inputs. A prover then selects a subset of these encodings, which a verifier -- implemented as a nonlinear predictor -- uses exclusively for decision-making. Our evaluations show that NCV outperforms CBM and pixel-based PVG classifier baselines on high-dimensional, logically complex datasets and also helps mitigate shortcut behavior. Overall, we demonstrate NCV as a promising step toward performative, verifiable AI.",
    "chinese_title": "神经概念验证器：通过概念编码扩展证明者-验证者博弈",
    "chinese_abstract": "虽然证明者-验证者博弈 (PVG) 为非线性分类模型的可验证性提供了一条有希望的途径，但尚未应用于复杂输入，例如高维图像。相反，概念瓶颈模型 (CBM) 可以有效地将此类数据转换为可解释的概念，但受限于其对低容量线性预测器的依赖。在这项工作中，我们引入了神经概念验证器 (NCV)，这是一个统一的框架，结合了 PVG 和概念编码，用于高维环境中的可解释、非线性分类。NCV 通过利用最近的最小监督概念发现模型从原始输入中提取结构化的概念编码来实现这一点。然后，证明者选择这些编码的一个子集，验证者（作为非线性预测器实现）仅使用这些子集进行决策。我们的评估表明，NCV 在高维、逻辑复杂的基准数据集上优于 CBM 和基于像素的 PVG 分类器基线，并且有助于缓解捷径行为。总而言之，我们展示了 NCV 是朝着高性能、可验证 AI 的有希望的一步。"
  },
  {
    "id": "arXiv:2507.07509",
    "title": "Toward Real-World Chinese Psychological Support Dialogues: CPsDD Dataset and a Co-Evolving Multi-Agent System",
    "authors": "Yuanchen Shi, Longyin Zhang, Fang Kong",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA)",
    "abs_link": "https://arxiv.org/abs/2507.07509",
    "pdf_link": "https://arxiv.org/pdf/2507.07509",
    "score": 4,
    "abstract": "The growing need for psychological support due to increasing pressures has exposed the scarcity of relevant datasets, particularly in non-English languages. To address this, we propose a framework that leverages limited real-world data and expert knowledge to fine-tune two large language models: Dialog Generator and Dialog Modifier. The Generator creates large-scale psychological counseling dialogues based on predefined paths, which guide system response strategies and user interactions, forming the basis for effective support. The Modifier refines these dialogues to align with real-world data quality. Through both automated and manual review, we construct the Chinese Psychological support Dialogue Dataset (CPsDD), containing 68K dialogues across 13 groups, 16 psychological problems, 13 causes, and 12 support focuses. Additionally, we introduce the Comprehensive Agent Dialogue Support System (CADSS), where a Profiler analyzes user characteristics, a Summarizer condenses dialogue history, a Planner selects strategies, and a Supporter generates empathetic responses. The experimental results of the Strategy Prediction and Emotional Support Conversation (ESC) tasks demonstrate that CADSS achieves state-of-the-art performance on both CPsDD and ESConv datasets.",
    "chinese_title": "迈向现实世界的中文心理支持对话：CPsDD数据集与协同演化的多智能体系统",
    "chinese_abstract": "由于日益增长的压力导致对心理支持的需求增加，相关数据集的匮乏日益凸显，尤其是在非英语语言中。为了解决这个问题，我们提出了一种框架，利用有限的真实世界数据和专家知识来微调两个大型语言模型：对话生成器和对话修改器。生成器基于预定义的路径创建大规模心理咨询对话，引导系统响应策略和用户互动，从而形成有效的支持基础。修改器则通过对齐真实世界的数据质量来优化这些对话。通过自动化和人工审查，我们构建了中文心理支持对话数据集（CPsDD），包含13个组别、16个心理问题、13个原因和12个支持重点的68K个对话。此外，我们还介绍了综合代理对话支持系统（CADSS），其中分析器分析用户特征，总结器压缩对话历史，规划器选择策略，支持者生成富有同情心的回应。在策略预测和情感支持对话（ESC）任务的实验结果表明，CADSS在CPsDD和ESConv数据集上均实现了最先进的性能。"
  },
  {
    "id": "arXiv:2507.07505",
    "title": "Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models",
    "authors": "Varin Sikka, Vishal Sikka",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07505",
    "pdf_link": "https://arxiv.org/pdf/2507.07505",
    "score": 4,
    "abstract": "With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.",
    "chinese_title": "幻觉站点：关于基于 Transformer 的语言模型的一些基本限制",
    "chinese_abstract": "随着基于 Transformer 的语言模型在人工智能领域的广泛应用，人们对 LLM 能力的限制，特别是所谓的“幻觉”——即 LLM 在被提示某些主题时提供虚假、事实错误或无意义的信息——产生了极大的兴趣。此外，人们对 LLM 的代理应用（即使用 LLM 创建自主或半自主地执行各种任务的代理，包括具有现实世界应用的任务）的兴趣日益增长。这使得理解 LLM 可以和不能执行的任务类型变得至关重要。我们从 LLM 推理的计算复杂性的角度探讨这个主题。我们表明，LLM 无法执行超过一定复杂度的计算和代理任务，并且 LLM 无法验证超过一定复杂度的任务的准确性。我们提供了一些例子，然后讨论这项工作的一些后果。"
  },
  {
    "id": "arXiv:2507.07495",
    "title": "PLAN-TUNING: Post-Training Language Models to Learn Step-by-Step Planning for Complex Problem Solving",
    "authors": "Mihir Parmar, Palash Goyal, Xin Liu, Yiwen Song, Mingyang Ling, Chitta Baral, Hamid Palangi, Tomas Pfister",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07495",
    "pdf_link": "https://arxiv.org/pdf/2507.07495",
    "score": 5,
    "abstract": "Recently, decomposing complex problems into simple subtasks--a crucial part of human-like natural planning--to solve the given problem has significantly boosted the performance of large language models (LLMs). However, leveraging such planning structures during post-training to boost the performance of smaller open-source LLMs remains underexplored. Motivated by this, we introduce PLAN-TUNING, a unified post-training framework that (i) distills synthetic task decompositions (termed \"planning trajectories\") from large-scale LLMs and (ii) fine-tunes smaller models via supervised and reinforcement-learning objectives designed to mimic these planning processes to improve complex reasoning. On GSM8k and the MATH benchmarks, plan-tuned models outperform strong baselines by an average $\\sim7\\%$. Furthermore, plan-tuned models show better generalization capabilities on out-of-domain datasets, with average $\\sim10\\%$ and $\\sim12\\%$ performance improvements on OlympiadBench and AIME 2024, respectively. Our detailed analysis demonstrates how planning trajectories improves complex reasoning capabilities, showing that PLAN-TUNING is an effective strategy for improving task-specific performance of smaller LLMs.",
    "chinese_title": "计划调优：后训练语言模型学习逐步规划以解决复杂问题",
    "chinese_abstract": "最近，将复杂问题分解为简单的子任务——人类自然规划的关键部分——以解决给定问题，显著提升了大型语言模型（LLM）的性能。然而，在后训练期间利用这种规划结构来提升较小开源LLM的性能仍然鲜为人知。受此启发，我们引入了PLAN-TUNING，一个统一的后训练框架，该框架 (i) 从大规模LLM中提炼合成任务分解（称为“规划轨迹”），并 (ii) 通过监督和强化学习目标对较小模型进行微调，以模拟这些规划过程，从而提高复杂推理能力。在GSM8k和MATH基准测试中，计划调优模型优于强大的基线，平均提升约7%。此外，计划调优模型在域外数据集上表现出更好的泛化能力，在OlympiadBench和AIME 2024上平均性能分别提升约10%和12%。我们详细的分析表明，规划轨迹如何提高复杂推理能力，表明PLAN-TUNING是提高较小LLM任务特定性能的有效策略。"
  },
  {
    "id": "arXiv:2507.07485",
    "title": "Resolving Token-Space Gradient Conflicts: Token Space Manipulation for Transformer-Based Multi-Task Learning",
    "authors": "Wooseong Jeong, Kuk-Jin Yoon",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.07485",
    "pdf_link": "https://arxiv.org/pdf/2507.07485",
    "score": 4,
    "abstract": "Multi-Task Learning (MTL) enables multiple tasks to be learned within a shared network, but differences in objectives across tasks can cause negative transfer, where the learning of one task degrades another task's performance. While pre-trained transformers significantly improve MTL performance, their fixed network capacity and rigid structure limit adaptability. Previous dynamic network architectures attempt to address this but are inefficient as they directly convert shared parameters into task-specific ones. We propose Dynamic Token Modulation and Expansion (DTME-MTL), a framework applicable to any transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces overfitting by identifying gradient conflicts in token space and applying adaptive solutions based on conflict type. Unlike prior methods that mitigate negative transfer by duplicating network parameters, DTME-MTL operates entirely in token space, enabling efficient adaptation without excessive parameter growth. Extensive experiments demonstrate that DTME-MTL consistently improves multi-task performance with minimal computational overhead, offering a scalable and effective solution for enhancing transformer-based MTL models.",
    "chinese_title": "解决Token空间梯度冲突：基于Transformer的多任务学习Token空间操作",
    "chinese_abstract": "多任务学习 (MTL) 能够在共享网络中学习多个任务，但不同任务之间的目标差异可能导致负迁移，即一个任务的学习会降低另一个任务的性能。虽然预训练的Transformer显著提高了MTL的性能，但其固定的网络容量和刚性的结构限制了适应性。先前的动态网络架构试图解决这个问题，但效率低下，因为它们直接将共享参数转换为特定于任务的参数。我们提出了一种动态Token调制和扩展 (DTME-MTL) 框架，该框架适用于任何基于Transformer的MTL架构。DTME-MTL通过识别Token空间中的梯度冲突并应用基于冲突类型的自适应解决方案，从而增强适应性并减少过拟合。与通过复制网络参数来减轻负迁移的先前方法不同，DTME-MTL完全在Token空间中运行，从而能够在参数增长过多的情况下实现高效的适应。大量的实验表明，DTME-MTL始终如一地提高了多任务性能，且计算开销最小，为增强基于Transformer的MTL模型提供了一种可扩展且有效的解决方案。"
  },
  {
    "id": "arXiv:2507.07484",
    "title": "Machine Bullshit: Characterizing the Emergent Disregard for Truth in Large Language Models",
    "authors": "Kaiqu Liang, Haimin Hu, Xuandong Zhao, Dawn Song, Thomas L. Griffiths, Jaime Fernández Fisac",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07484",
    "pdf_link": "https://arxiv.org/pdf/2507.07484",
    "score": 5,
    "abstract": "Bullshit, as conceptualized by philosopher Harry Frankfurt, refers to statements made without regard to their truth value. While previous work has explored large language model (LLM) hallucination and sycophancy, we propose machine bullshit as an overarching conceptual framework that can allow researchers to characterize the broader phenomenon of emergent loss of truthfulness in LLMs and shed light on its underlying mechanisms. We introduce the Bullshit Index, a novel metric quantifying LLMs' indifference to truth, and propose a complementary taxonomy analyzing four qualitative forms of bullshit: empty rhetoric, paltering, weasel words, and unverified claims. We conduct empirical evaluations on the Marketplace dataset, the Political Neutrality dataset, and our new BullshitEval benchmark (2,400 scenarios spanning 100 AI assistants) explicitly designed to evaluate machine bullshit. Our results demonstrate that model fine-tuning with reinforcement learning from human feedback (RLHF) significantly exacerbates bullshit and inference-time chain-of-thought (CoT) prompting notably amplify specific bullshit forms, particularly empty rhetoric and paltering. We also observe prevalent machine bullshit in political contexts, with weasel words as the dominant strategy. Our findings highlight systematic challenges in AI alignment and provide new insights toward more truthful LLM behavior.",
    "chinese_title": "机器废话：大型语言模型中对真相漠视的特征化",
    "chinese_abstract": "“废话”，按照哲学家哈里·弗兰克福的定义，是指不考虑其真值就做出的陈述。虽然之前的工作已经探讨了大型语言模型（LLM）的幻觉和趋炎附势，但我们提出“机器废话”作为一个总体概念框架，可以帮助研究人员描述LLM中真相丧失的更广泛现象，并阐明其潜在机制。我们引入了“废话指数”，这是一个量化LLM对真相漠视的新指标，并提出了一种互补的分类法，分析了四种定性的废话形式：空洞的修辞、含糊其辞、使用模棱两可的词语和未经证实的说法。我们在Marketplace数据集、政治中立数据集和我们新创建的BullshitEval基准测试（包含100个AI助手和2400个场景）上进行了实证评估，该基准测试明确设计用于评估机器废话。我们的结果表明，使用来自人类反馈的强化学习（RLHF）进行模型微调会显著加剧废话现象，并且推理时链式思考（CoT）提示会显著放大特定的废话形式，特别是空洞的修辞和含糊其辞。我们还观察到政治背景下普遍存在机器废话，其中使用模棱两可的词语是主要的策略。我们的发现突出了人工智能对齐方面的系统性挑战，并为更真实的LLM行为提供了新的见解。"
  },
  {
    "id": "arXiv:2507.07439",
    "title": "Towards Interpretable Time Series Foundation Models",
    "authors": "Matthieu Boileau, Philippe Helluy, Jeremy Pawlus, Svitlana Vyetrenko",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07439",
    "pdf_link": "https://arxiv.org/pdf/2507.07439",
    "score": 3,
    "abstract": "In this paper, we investigate the distillation of time series reasoning capabilities into small, instruction-tuned language models as a step toward building interpretable time series foundation models. Leveraging a synthetic dataset of mean-reverting time series with systematically varied trends and noise levels, we generate natural language annotations using a large multimodal model and use these to supervise the fine-tuning of compact Qwen models. We introduce evaluation metrics that assess the quality of the distilled reasoning - focusing on trend direction, noise intensity, and extremum localization - and show that the post-trained models acquire meaningful interpretive capabilities. Our results highlight the feasibility of compressing time series understanding into lightweight, language-capable models suitable for on-device or privacy-sensitive deployment. This work contributes a concrete foundation toward developing small, interpretable models that explain temporal patterns in natural language.",
    "chinese_title": "迈向可解释的时间序列基础模型",
    "chinese_abstract": "在本文中，我们研究了将时间序列推理能力提炼到小型、指令微调的语言模型中，作为构建可解释时间序列基础模型的一步。利用具有系统性变化的趋势和噪声水平的均值回归时间序列的合成数据集，我们使用大型多模态模型生成自然语言注释，并使用这些注释来监督紧凑型Qwen模型的微调。我们引入了评估指标来评估提炼的推理质量——重点是趋势方向、噪声强度和极值定位——并表明后训练模型获得了有意义的解释能力。我们的结果强调了将时间序列理解压缩到轻量级、具备语言能力的模型的可能性，这些模型适用于设备端或隐私敏感部署。这项工作为开发能够用自然语言解释时间模式的小型、可解释模型奠定了坚实的基础。"
  },
  {
    "id": "arXiv:2507.07421",
    "title": "SynthEHR-Eviction: Enhancing Eviction SDoH Detection with LLM-Augmented Synthetic EHR Data",
    "authors": "Zonghai Yao, Youxia Zhao, Avijit Mitra, David A. Levy, Emily Druhl, Jack Tsai, Hong Yu",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07421",
    "pdf_link": "https://arxiv.org/pdf/2507.07421",
    "score": 4,
    "abstract": "Eviction is a significant yet understudied social determinants of health (SDoH), linked to housing instability, unemployment, and mental health. While eviction appears in unstructured electronic health records (EHRs), it is rarely coded in structured fields, limiting downstream applications. We introduce SynthEHR-Eviction, a scalable pipeline combining LLMs, human-in-the-loop annotation, and automated prompt optimization (APO) to extract eviction statuses from clinical notes. Using this pipeline, we created the largest public eviction-related SDoH dataset to date, comprising 14 fine-grained categories. Fine-tuned LLMs (e.g., Qwen2.5, LLaMA3) trained on SynthEHR-Eviction achieved Macro-F1 scores of 88.8% (eviction) and 90.3% (other SDoH) on human validated data, outperforming GPT-4o-APO (87.8%, 87.3%), GPT-4o-mini-APO (69.1%, 78.1%), and BioBERT (60.7%, 68.3%), while enabling cost-effective deployment across various model sizes. The pipeline reduces annotation effort by over 80%, accelerates dataset creation, enables scalable eviction detection, and generalizes to other information extraction tasks.",
    "chinese_title": "SynthEHR-驱逐：利用LLM增强的合成EHR数据提升SDoH驱逐检测",
    "chinese_abstract": "驱逐是一个重要的但研究不足的社会决定健康因素（SDoH），与住房不稳定、失业和心理健康有关。虽然驱逐信息出现在非结构化的电子健康记录（EHR）中，但很少在结构化字段中进行编码，从而限制了下游应用。我们引入SynthEHR-驱逐，这是一个可扩展的流程，结合了LLM、人工参与式标注和自动化提示优化（APO），以从临床笔记中提取驱逐状态。利用此流程，我们创建了迄今为止最大的公共驱逐相关SDoH数据集，包含14个细粒度类别。在人工验证数据上，在SynthEHR-驱逐上微调的LLM（例如，Qwen2.5、LLaMA3）实现了88.8%（驱逐）和90.3%（其他SDoH）的宏F1分数，优于GPT-4o-APO（87.8%，87.3%）、GPT-4o-mini-APO（69.1%，78.1%）和BioBERT（60.7%，68.3%），同时实现了在各种模型尺寸上的经济高效部署。该流程将标注工作量减少了80%以上，加速了数据集创建，实现了可扩展的驱逐检测，并可推广到其他信息提取任务。"
  },
  {
    "id": "arXiv:2507.07419",
    "title": "MedReadCtrl: Personalizing medical text generation with readability-controlled instruction learning",
    "authors": "Hieu Tran, Zonghai Yao, Won Seok Jang, Sharmin Sultana, Allen Chang, Yuan Zhang, Hong Yu",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07419",
    "pdf_link": "https://arxiv.org/pdf/2507.07419",
    "score": 4,
    "abstract": "Generative AI has demonstrated strong potential in healthcare, from clinical decision support to patient-facing chatbots that improve outcomes. A critical challenge for deployment is effective human-AI communication, where content must be both personalized and understandable. We introduce MedReadCtrl, a readability-controlled instruction tuning framework that enables LLMs to adjust output complexity without compromising meaning. Evaluations of nine datasets and three tasks across medical and general domains show that MedReadCtrl achieves significantly lower readability instruction-following errors than GPT-4 (e.g., 1.39 vs. 1.59 on ReadMe, p<0.001) and delivers substantial gains on unseen clinical tasks (e.g., +14.7 ROUGE-L, +6.18 SARI on MTSamples). Experts consistently preferred MedReadCtrl (71.7% vs. 23.3%), especially at low literacy levels. These gains reflect MedReadCtrl's ability to restructure clinical content into accessible, readability-aligned language while preserving medical intent, offering a scalable solution to support patient education and expand equitable access to AI-enabled care.",
    "chinese_title": "MedReadCtrl：基于可控可读性的指令学习，实现医疗文本生成的个性化",
    "chinese_abstract": "生成式人工智能在医疗保健领域展现出强大的潜力，从临床决策支持到面向患者的聊天机器人，可以改善治疗效果。有效的人机沟通是部署的关键挑战，内容必须既个性化又易于理解。我们引入MedReadCtrl，一种可控可读性的指令微调框架，使LLM能够在不影响含义的前提下调整输出的复杂程度。在医疗和通用领域九个数据集和三个任务上的评估表明，MedReadCtrl在可读性指令遵循错误方面明显低于GPT-4（例如，ReadMe上的1.39 vs. 1.59，p<0.001），并在未见过的临床任务上取得了显著的收益（例如，MTSamples上的+14.7 ROUGE-L，+6.18 SARI）。专家们一致更喜欢MedReadCtrl（71.7% vs. 23.3%），尤其是在低识读率人群中。这些收益反映了MedReadCtrl能够将临床内容重构为易于理解、与可读性相符的语言，同时保留医疗意图，为支持患者教育和扩大人工智能赋能的医疗服务的公平性提供可扩展的解决方案。"
  },
  {
    "id": "arXiv:2507.07418",
    "title": "Optimal Auction Design in the Joint Advertising",
    "authors": "Yang Li, Yuchao Ma, Qi Qi",
    "subjects": "Computer Science and Game Theory (cs.GT); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07418",
    "pdf_link": "https://arxiv.org/pdf/2507.07418",
    "score": 3,
    "abstract": "Online advertising is a vital revenue source for major internet platforms. Recently, joint advertising, which assigns a bundle of two advertisers in an ad slot instead of allocating a single advertiser, has emerged as an effective method for enhancing allocation efficiency and revenue. However, existing mechanisms for joint advertising fail to realize the optimality, as they tend to focus on individual advertisers and overlook bundle structures. This paper identifies an optimal mechanism for joint advertising in a single-slot setting. For multi-slot joint advertising, we propose \\textbf{BundleNet}, a novel bundle-based neural network approach specifically designed for joint advertising. Our extensive experiments demonstrate that the mechanisms generated by \\textbf{BundleNet} approximate the theoretical analysis results in the single-slot setting and achieve state-of-the-art performance in the multi-slot setting. This significantly increases platform revenue while ensuring approximate dominant strategy incentive compatibility and individual rationality.",
    "chinese_title": "联合广告中的最优拍卖设计",
    "chinese_abstract": "在线广告是主要互联网平台的重要收入来源。最近，联合广告（将两个广告主捆绑分配到广告位，而不是分配单个广告主）作为提高分配效率和收入的有效方法出现。然而，现有的联合广告机制未能实现最优，因为它们倾向于关注单个广告主，而忽略了捆绑结构。本文确定了单广告位联合广告的最优机制。对于多广告位联合广告，我们提出了一种新颖的基于捆绑的神经网络方法\textbf{BundleNet}，专门为联合广告设计。大量的实验表明，\textbf{BundleNet}生成的机制逼近了单广告位设置中的理论分析结果，并在多广告位设置中实现了最先进的性能。这显著提高了平台收入，同时确保了近似的占优策略激励相容性和个体理性。"
  },
  {
    "id": "arXiv:2507.07417",
    "title": "May I have your Attention? Breaking Fine-Tuning based Prompt Injection Defenses using Architecture-Aware Attacks",
    "authors": "Nishit V. Pandya, Andrey Labunets, Sicun Gao, Earlence Fernandes",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07417",
    "pdf_link": "https://arxiv.org/pdf/2507.07417",
    "score": 4,
    "abstract": "A popular class of defenses against prompt injection attacks on large language models (LLMs) relies on fine-tuning the model to separate instructions and data, so that the LLM does not follow instructions that might be present with data. There are several academic systems and production-level implementations of this idea. We evaluate the robustness of this class of prompt injection defenses in the whitebox setting by constructing strong optimization-based attacks and showing that the defenses do not provide the claimed security properties. Specifically, we construct a novel attention-based attack algorithm for text-based LLMs and apply it to two recent whitebox defenses SecAlign (CCS 2025) and StruQ (USENIX Security 2025), showing attacks with success rates of up to 70% with modest increase in attacker budget in terms of tokens. Our findings make fundamental progress towards understanding the robustness of prompt injection defenses in the whitebox setting. We release our code and attacks at https://github.com/nishitvp/better_opts_attacks",
    "chinese_title": "请问我可以获得你的注意力吗？利用架构感知的攻击打破基于微调的提示注入防御",
    "chinese_abstract": "一种流行的防御大型语言模型 (LLM) 提示注入攻击的方法依赖于对模型进行微调，以分离指令和数据，从而使 LLM 不会遵循可能存在于数据中的指令。学术界和生产层面都有几种实现此想法的系统。我们通过构建强大的基于优化的攻击来评估这种类别的提示注入防御在白盒设置下的鲁棒性，并表明这些防御并未提供声称的安全属性。具体而言，我们为基于文本的 LLM 构建了一种新的基于注意力攻击算法，并将其应用于最近的两个白盒防御系统 SecAlign (CCS 2025) 和 StruQ (USENIX Security 2025)，显示攻击成功率高达 70%，且攻击者在 token 方面的预算仅略有增加。我们的发现对理解白盒设置中提示注入防御的鲁棒性做出了根本性的进展。我们发布了我们的代码和攻击：https://github.com/nishitvp/better_opts_attacks"
  },
  {
    "id": "arXiv:2507.07416",
    "title": "Autonomous AI-based Cybersecurity Framework for Critical Infrastructure: Real-Time Threat Mitigation",
    "authors": "Jenifer Paulraj, Brindha Raghuraman, Nagarani Gopalakrishnan, Yazan Otoum",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Emerging Technologies (cs.ET); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07416",
    "pdf_link": "https://arxiv.org/pdf/2507.07416",
    "score": 3,
    "abstract": "Critical infrastructure systems, including energy grids, healthcare facilities, transportation networks, and water distribution systems, are pivotal to societal stability and economic resilience. However, the increasing interconnectivity of these systems exposes them to various cyber threats, including ransomware, Denial-of-Service (DoS) attacks, and Advanced Persistent Threats (APTs). This paper examines cybersecurity vulnerabilities in critical infrastructure, highlighting the threat landscape, attack vectors, and the role of Artificial Intelligence (AI) in mitigating these risks. We propose a hybrid AI-driven cybersecurity framework to enhance real-time vulnerability detection, threat modelling, and automated remediation. This study also addresses the complexities of adversarial AI, regulatory compliance, and integration. Our findings provide actionable insights to strengthen the security and resilience of critical infrastructure systems against emerging cyber threats.",
    "chinese_title": "基于自主AI的 критической инфраструктуры网络安全框架：实时威胁缓解",
    "chinese_abstract": " критической инфраструктуры系统，包括能源网络、医疗机构、交通网络和供水系统，对社会稳定和经济复原力至关重要。然而，这些系统日益互联互通使其面临各种网络威胁，包括勒索软件、拒绝服务 (DoS) 攻击和高级持续威胁 (APT)。本文探讨了 критической инфраструктуры的网络安全漏洞，重点介绍了威胁形势、攻击向量以及人工智能 (AI) 在缓解这些风险中的作用。我们提出了一种混合AI驱动的网络安全框架，以增强实时漏洞检测、威胁建模和自动化修复。本研究还解决了对抗性AI、监管合规性和集成等复杂问题。我们的研究结果为加强 критической инфраструктуры系统应对新兴网络威胁的安全性与韧性提供了可操作的见解。"
  },
  {
    "id": "arXiv:2507.07414",
    "title": "GNN-CNN: An Efficient Hybrid Model of Convolutional and Graph Neural Networks for Text Representation",
    "authors": "Fardin Rastakhiz",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07414",
    "pdf_link": "https://arxiv.org/pdf/2507.07414",
    "score": 3,
    "abstract": "Time, cost, and energy efficiency are critical considerations in Deep-Learning (DL), particularly when processing long texts. Transformers, which represent the current state of the art, exhibit quadratic computational complexity relative to input length, making them inefficient for extended documents. This study introduces a novel model architecture that combines Graph Neural Networks (GNNs) and Convolutional Neural Networks (CNNs), integrated with a real-time, end-to-end graph generation mechanism. The model processes compact batches of character-level inputs without requiring padding or truncation. To enhance performance while maintaining high speed and efficiency, the model incorporates information from Large Language Models (LLMs), such as token embeddings and sentiment polarities, through efficient dictionary lookups. It captures local contextual patterns using CNNs, expands local receptive fields via lattice-based graph structures, and employs small-world graphs to aggregate document-level information. The generated graphs exhibit structural properties indicative of meaningful semantic organization, with an average clustering coefficient of approximately 0.45 and an average shortest path length ranging between 4 and 5. The model is evaluated across multiple text classification tasks, including sentiment analysis and news-categorization, and is compared against state-of-the-art models. Experimental results confirm the proposed model's efficiency and competitive performance.",
    "chinese_title": "GNN-CNN：用于文本表示的卷积神经网络和图神经网络的有效混合模型",
    "chinese_abstract": "时间、成本和能源效率是深度学习（DL）中的关键考虑因素，尤其是在处理长文本时。Transformer 代表了当前的技术水平，但其计算复杂度与输入长度呈二次方关系，这使得它们在处理扩展文档时效率低下。本研究介绍了一种新颖的模型架构，它结合了图神经网络（GNN）和卷积神经网络（CNN），并集成了实时、端到端的图生成机制。该模型处理紧凑的字符级输入批次，无需填充或截断。为了提高性能，同时保持高速度和效率，该模型通过高效的字典查找方式，结合了来自大型语言模型（LLM）的信息，例如token嵌入和情感极性。它使用 CNN 捕获局部上下文模式，通过基于格子的图结构扩展局部感受野，并使用小世界图来聚合文档级信息。生成的图表现出表明有意义的语义组织的结构特性，平均聚类系数约为 0.45，平均最短路径长度在 4 到 5 之间。该模型在多个文本分类任务中进行评估，包括情感分析和新闻分类，并与最先进的模型进行比较。实验结果证实了所提出的模型的效率和竞争性能。"
  },
  {
    "id": "arXiv:2507.07413",
    "title": "Hybrid LLM-Enhanced Intrusion Detection for Zero-Day Threats in IoT Networks",
    "authors": "Mohammad F. Al-Hammouri, Yazan Otoum, Rasha Atwa, Amiya Nayak",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07413",
    "pdf_link": "https://arxiv.org/pdf/2507.07413",
    "score": 4,
    "abstract": "This paper presents a novel approach to intrusion detection by integrating traditional signature-based methods with the contextual understanding capabilities of the GPT-2 Large Language Model (LLM). As cyber threats become increasingly sophisticated, particularly in distributed, heterogeneous, and resource-constrained environments such as those enabled by the Internet of Things (IoT), the need for dynamic and adaptive Intrusion Detection Systems (IDSs) becomes increasingly urgent. While traditional methods remain effective for detecting known threats, they often fail to recognize new and evolving attack patterns. In contrast, GPT-2 excels at processing unstructured data and identifying complex semantic relationships, making it well-suited to uncovering subtle, zero-day attack vectors. We propose a hybrid IDS framework that merges the robustness of signature-based techniques with the adaptability of GPT-2-driven semantic analysis. Experimental evaluations on a representative intrusion dataset demonstrate that our model enhances detection accuracy by 6.3%, reduces false positives by 9.0%, and maintains near real-time responsiveness. These results affirm the potential of language model integration to build intelligent, scalable, and resilient cybersecurity defences suited for modern connected environments.",
    "chinese_title": "混合LLM增强的物联网零日威胁入侵检测",
    "chinese_abstract": "本文提出了一种新颖的入侵检测方法，通过集成传统的基于签名的技术与GPT-2大型语言模型（LLM）的上下文理解能力。随着网络威胁日益复杂，尤其是在互联网物联网（IoT）等分布式、异构和资源受限的环境中，动态且自适应的入侵检测系统（IDS）的需求变得越来越紧迫。虽然传统方法仍然有效地检测已知威胁，但它们通常无法识别新的和不断演变的攻击模式。相反，GPT-2擅长处理非结构化数据并识别复杂的语义关系，使其非常适合发现微妙的零日攻击向量。我们提出了一种混合IDS框架，它将基于签名的技术的稳健性与GPT-2驱动的语义分析的适应性相结合。在具有代表性的入侵数据集上的实验评估表明，我们的模型将检测准确率提高了6.3％，将误报率降低了9.0％，并保持了接近实时响应的速度。这些结果证实了语言模型集成构建智能、可扩展且具有弹性的网络安全防御的能力，适用于现代互联环境。"
  },
  {
    "id": "arXiv:2507.07406",
    "title": "Phishing Detection in the Gen-AI Era: Quantized LLMs vs Classical Models",
    "authors": "Jikesh Thapa, Gurrehmat Chahal, Serban Voinea Gabreanu, Yazan Otoum",
    "subjects": "Cryptography and Security (cs.CR); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07406",
    "pdf_link": "https://arxiv.org/pdf/2507.07406",
    "score": 4,
    "abstract": "Phishing attacks are becoming increasingly sophisticated, underscoring the need for detection systems that strike a balance between high accuracy and computational efficiency. This paper presents a comparative evaluation of traditional Machine Learning (ML), Deep Learning (DL), and quantized small-parameter Large Language Models (LLMs) for phishing detection. Through experiments on a curated dataset, we show that while LLMs currently underperform compared to ML and DL methods in terms of raw accuracy, they exhibit strong potential for identifying subtle, context-based phishing cues. We also investigate the impact of zero-shot and few-shot prompting strategies, revealing that LLM-rephrased emails can significantly degrade the performance of both ML and LLM-based detectors. Our benchmarking highlights that models like DeepSeek R1 Distill Qwen 14B (Q8_0) achieve competitive accuracy, above 80%, using only 17GB of VRAM, supporting their viability for cost-efficient deployment. We further assess the models' adversarial robustness and cost-performance tradeoffs, and demonstrate how lightweight LLMs can provide concise, interpretable explanations to support real-time decision-making. These findings position optimized LLMs as promising components in phishing defence systems and offer a path forward for integrating explainable, efficient AI into modern cybersecurity frameworks.",
    "chinese_title": "Gen-AI 时代钓鱼检测：量化 LLM 与经典模型对比",
    "chinese_abstract": "钓鱼攻击日益复杂，凸显了需要在高准确性和计算效率之间取得平衡的检测系统的需求。本文对传统机器学习 (ML)、深度学习 (DL) 和量化小参数大型语言模型 (LLM) 用于钓鱼检测进行了比较评估。通过对精选数据集的实验，我们表明，虽然 LLM 在原始准确性方面目前不如 ML 和 DL 方法，但它们在识别微妙的、基于上下文的钓鱼线索方面表现出很强的潜力。我们还研究了零样本和少样本提示策略的影响，揭示了 LLM 重述的电子邮件会显著降低 ML 和 LLM 基于检测器的性能。我们的基准测试表明，DeepSeek R1 Distill Qwen 14B (Q8_0) 等模型仅使用 17GB 的 VRAM 即可实现超过 80% 的竞争性准确率，支持它们在成本效益部署中的可行性。我们进一步评估了模型的对抗鲁棒性和成本性能权衡，并证明了轻量级 LLM 如何提供简洁、可解释的解释来支持实时决策。这些发现将优化的 LLM 定位为现代网络安全框架中钓鱼防御系统的有希望的组成部分，并为将可解释、高效的 AI 集成到现代网络安全框架中提供了一条前进的道路。"
  },
  {
    "id": "arXiv:2507.07405",
    "title": "HGMP:Heterogeneous Graph Multi-Task Prompt Learning",
    "authors": "Pengfei Jiao, Jialong Ni, Di Jin, Xuan Guo, Huan Liu, Hongjiang Chen, Yanxian Bi",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07405",
    "pdf_link": "https://arxiv.org/pdf/2507.07405",
    "score": 4,
    "abstract": "The pre-training and fine-tuning methods have gained widespread attention in the field of heterogeneous graph neural networks due to their ability to leverage large amounts of unlabeled data during the pre-training phase, allowing the model to learn rich structural features. However, these methods face the issue of a mismatch between the pre-trained model and downstream tasks, leading to suboptimal performance in certain application scenarios. Prompt learning methods have emerged as a new direction in heterogeneous graph tasks, as they allow flexible adaptation of task representations to address target inconsistency. Building on this idea, this paper proposes a novel multi-task prompt framework for the heterogeneous graph domain, named HGMP. First, to bridge the gap between the pre-trained model and downstream tasks, we reformulate all downstream tasks into a unified graph-level task format. Next, we address the limitations of existing graph prompt learning methods, which struggle to integrate contrastive pre-training strategies in the heterogeneous graph domain. We design a graph-level contrastive pre-training strategy to better leverage heterogeneous information and enhance performance in multi-task scenarios. Finally, we introduce heterogeneous feature prompts, which enhance model performance by refining the representation of input graph features. Experimental results on public datasets show that our proposed method adapts well to various tasks and significantly outperforms baseline methods.",
    "chinese_title": "HGMP：异构图多任务提示学习",
    "chinese_abstract": "预训练和微调方法在异构图神经网络领域受到了广泛关注，因为它们能够在预训练阶段利用大量的未标记数据，使模型能够学习丰富的结构特征。然而，这些方法面临预训练模型与下游任务之间不匹配的问题，导致在某些应用场景中性能 suboptimal。提示学习方法作为异构图任务的新方向出现，它们允许灵活地调整任务表示以解决目标不一致的问题。基于这个想法，本文提出了一种名为HGMP的新型异构图领域多任务提示框架。首先，为了弥合预训练模型与下游任务之间的差距，我们将所有下游任务重新构建为统一的图级任务格式。其次，我们解决了现有图提示学习方法的局限性，这些方法难以在异构图领域集成对比预训练策略。我们设计了一种图级对比预训练策略，以更好地利用异构信息并增强多任务场景中的性能。最后，我们引入异构特征提示，通过细化输入图特征的表示来提高模型性能。在公共数据集上的实验结果表明，我们提出的方法能够很好地适应各种任务，并且显著优于基线方法。"
  },
  {
    "id": "arXiv:2507.07399",
    "title": "Generalized Tree Edit Distance (GTED): A Faithful Evaluation Metric for Statement Autoformalization",
    "authors": "Yuntian Liu, Tao Zhu, Xiaoyang Liu, Yu Chen, Zhaoxuan Liu, Qingfeng Guo, Jiashuo Zhang, Kangjie Bao, Tao Luo",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07399",
    "pdf_link": "https://arxiv.org/pdf/2507.07399",
    "score": 3,
    "abstract": "Statement autoformalization, the automated translation of statement from natural language into formal languages, has become a subject of extensive research, yet the development of robust automated evaluation metrics remains limited. Existing evaluation methods often lack semantic understanding, face challenges with high computational costs, and are constrained by the current progress of automated theorem proving. To address these issues, we propose GTED (Generalized Tree Edit Distance), a novel evaluation framework that first standardizes formal statements and converts them into operator trees, then determines the semantic similarity using the eponymous GTED metric. On the miniF2F and ProofNet benchmarks, GTED outperforms all baseline metrics by achieving the highest accuracy and Kappa scores, thus providing the community with a more faithful metric for automated evaluation. The code and experimental results are available at https://github.com/XiaoyangLiu-sjtu/GTED.",
    "chinese_title": "广义树编辑距离 (GTED)：用于语句自动形式化的一种可靠评估指标",
    "chinese_abstract": "语句自动形式化，即将自然语言语句自动翻译成形式语言，已成为广泛研究的主题，但稳健的自动化评估指标的开发仍然有限。现有的评估方法通常缺乏语义理解，面临高计算成本的挑战，并且受到自动化定理证明的当前进展的限制。为了解决这些问题，我们提出 GTED（广义树编辑距离），这是一种新颖的评估框架，它首先标准化形式化语句并将其转换为运算符树，然后使用同名的 GTED 指标确定语义相似性。在 miniF2F 和 ProofNet 基准测试中，GTED 通过实现最高的准确率和 Kappa 分数，优于所有基线指标，从而为社区提供了一种更可靠的自动化评估指标。代码和实验结果可在 https://github.com/XiaoyangLiu-sjtu/GTED 获取。"
  },
  {
    "id": "arXiv:2507.07394",
    "title": "Behave Your Motion: Habit-preserved Cross-category Animal Motion Transfer",
    "authors": "Zhimin Zhang, Bi'an Du, Caoyuan Ma, Zheng Wang, Wei Hu",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07394",
    "pdf_link": "https://arxiv.org/pdf/2507.07394",
    "score": 4,
    "abstract": "Animal motion embodies species-specific behavioral habits, making the transfer of motion across categories a critical yet complex task for applications in animation and virtual reality. Existing motion transfer methods, primarily focused on human motion, emphasize skeletal alignment (motion retargeting) or stylistic consistency (motion style transfer), often neglecting the preservation of distinct habitual behaviors in animals. To bridge this gap, we propose a novel habit-preserved motion transfer framework for cross-category animal motion. Built upon a generative framework, our model introduces a habit-preservation module with category-specific habit encoder, allowing it to learn motion priors that capture distinctive habitual characteristics. Furthermore, we integrate a large language model (LLM) to facilitate the motion transfer to previously unobserved species. To evaluate the effectiveness of our approach, we introduce the DeformingThings4D-skl dataset, a quadruped dataset with skeletal bindings, and conduct extensive experiments and quantitative analyses, which validate the superiority of our proposed model.",
    "chinese_title": "行为你的运动：习惯保留的跨类别动物运动迁移",
    "chinese_abstract": "动物运动体现了物种特定的行为习惯，这使得跨类别运动迁移对于动画和虚拟现实等应用来说是一项关键但复杂的任务。现有的运动迁移方法主要集中在人类运动上，强调骨骼对齐（运动重定向）或风格一致性（运动风格迁移），通常忽略了动物独特习惯性行为的保留。为了弥合这一差距，我们提出了一种新颖的习惯保留的跨类别动物运动迁移框架。该框架基于生成模型，引入了一个具有类别特定习惯编码器的习惯保留模块，使其能够学习捕捉独特习惯特征的运动先验。此外，我们集成了大型语言模型（LLM），以促进运动迁移到以前未观察到的物种。为了评估我们方法的有效性，我们引入了DeformingThings4D-skl数据集，这是一个具有骨骼绑定的四足动物数据集，并进行了广泛的实验和定量分析，验证了我们提出的模型的优越性。"
  },
  {
    "id": "arXiv:2507.07376",
    "title": "PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments",
    "authors": "Hengrui Liu, Yi Feng, Qilong Zhang",
    "subjects": "Robotics (cs.RO); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07376",
    "pdf_link": "https://arxiv.org/pdf/2507.07376",
    "score": 4,
    "abstract": "Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.",
    "chinese_title": "PILOC：一种信息素反向引导机制和局部通信框架，用于未知环境中多智能体的动态目标搜索",
    "chinese_abstract": "多智能体搜索与救援 (MASAR) 在灾害响应、勘探和侦察中发挥着至关重要的作用。然而，动态和未知的环境由于目标不可预测性和环境不确定性带来了重大挑战。为了解决这些问题，我们提出了 PILOC，一个无需全局先验知识，利用局部感知和通信的框架。它引入了一种信息素反向引导机制，以实现高效的协调和动态目标定位。PILOC 通过局部通信促进去中心化协作，显著减少了对全局信道的依赖。与传统的启发式方法不同，信息素机制嵌入到深度强化学习 (DRL) 的观察空间中，支持基于环境线索的间接智能体协调。我们将该策略进一步集成到基于 DRL 的多智能体架构中，并进行了广泛的实验。结果表明，将局部通信与基于信息素的引导相结合可以显著提高搜索效率、适应性和系统鲁棒性。与现有方法相比，PILOC 在动态和通信受限场景中表现更好，为未来的 MASAR 应用提供了有希望的方向。"
  },
  {
    "id": "arXiv:2507.07359",
    "title": "Goal-Oriented Sequential Bayesian Experimental Design for Causal Learning",
    "authors": "Zheyu Zhang, Jiayuan Dong, Jie Liu, Xun Huan",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Methodology (stat.ME); Machine Learning (stat.ML)",
    "abs_link": "https://arxiv.org/abs/2507.07359",
    "pdf_link": "https://arxiv.org/pdf/2507.07359",
    "score": 4,
    "abstract": "We present GO-CBED, a goal-oriented Bayesian framework for sequential causal experimental design. Unlike conventional approaches that select interventions aimed at inferring the full causal model, GO-CBED directly maximizes the expected information gain (EIG) on user-specified causal quantities of interest, enabling more targeted and efficient experimentation. The framework is both non-myopic, optimizing over entire intervention sequences, and goal-oriented, targeting only model aspects relevant to the causal query. To address the intractability of exact EIG computation, we introduce a variational lower bound estimator, optimized jointly through a transformer-based policy network and normalizing flow-based variational posteriors. The resulting policy enables real-time decision-making via an amortized network. We demonstrate that GO-CBED consistently outperforms existing baselines across various causal reasoning and discovery tasks-including synthetic structural causal models and semi-synthetic gene regulatory networks-particularly in settings with limited experimental budgets and complex causal mechanisms. Our results highlight the benefits of aligning experimental design objectives with specific research goals and of forward-looking sequential planning.",
    "chinese_title": "面向目标的顺序贝叶斯实验设计用于因果学习",
    "chinese_abstract": "我们提出了GO-CBED，一个面向目标的贝叶斯框架，用于顺序因果实验设计。与旨在推断完整因果模型的传统方法不同，GO-CBED直接最大化用户指定的因果感兴趣量的期望信息增益（EIG），从而实现更有针对性和更高效的实验。该框架既非近视（优化整个干预序列），又以目标为导向（仅针对与因果查询相关的模型方面）。为了解决精确EIG计算的不可行性，我们引入了一个变分下界估计器，通过基于Transformer的策略网络和基于归一化流的变分后验联合优化。由此产生的策略能够通过一个摊销网络进行实时决策。我们证明，GO-CBED在各种因果推理和发现任务中始终优于现有基线——包括合成结构因果模型和半合成基因调控网络——尤其是在实验预算有限和因果机制复杂的情况下。我们的结果强调了将实验设计目标与特定研究目标对齐以及前瞻性顺序规划的好处。"
  },
  {
    "id": "arXiv:2507.07335",
    "title": "Leveraging Manifold Embeddings for Enhanced Graph Transformer Representations and Learning",
    "authors": "Ankit Jyothish, Ali Jannesari",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07335",
    "pdf_link": "https://arxiv.org/pdf/2507.07335",
    "score": 3,
    "abstract": "Graph transformers typically embed every node in a single Euclidean space, blurring heterogeneous topologies. We prepend a lightweight Riemannian mixture-of-experts layer that routes each node to various kinds of manifold, mixture of spherical, flat, hyperbolic - best matching its local structure. These projections provide intrinsic geometric explanations to the latent space. Inserted into a state-of-the-art ensemble graph transformer, this projector lifts accuracy by up to 3% on four node-classification benchmarks. The ensemble makes sure that both euclidean and non-euclidean features are captured. Explicit, geometry-aware projection thus sharpens predictive power while making graph representations more interpretable.",
    "chinese_title": "利用流形嵌入增强图Transformer表示和学习",
    "chinese_abstract": "图Transformer通常将每个节点嵌入到单个欧几里得空间中，模糊了异构拓扑结构。我们添加了一个轻量级的黎曼混合专家层，将每个节点路由到各种流形（球形、平坦、双曲等），以最佳匹配其局部结构。这些投影为潜在空间提供了内在的几何解释。插入到最先进的集成图Transformer中，该投影器在四个节点分类基准测试中将准确率提高了高达3%。集成确保捕获欧几里得和非欧几里得特征。显式的、几何感知的投影从而提高了预测能力，并使图表示更具可解释性。"
  },
  {
    "id": "arXiv:2507.07328",
    "title": "Bridging the Plausibility-Validity Gap by Fine-Tuning a Reasoning-Enhanced LLM for Chemical Synthesis and Discovery",
    "authors": "Malikussaid, Hilal Hudan Nuha",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computational Engineering, Finance, and Science (cs.CE); Chemical Physics (physics.chem-ph)",
    "abs_link": "https://arxiv.org/abs/2507.07328",
    "pdf_link": "https://arxiv.org/pdf/2507.07328",
    "score": 4,
    "abstract": "Large Language Models (LLMs) often generate scientifically plausible but factually invalid information, a challenge we term the \"plausibility-validity gap,\" particularly in specialized domains like chemistry. This paper presents a systematic methodology to bridge this gap by developing a specialized scientific assistant. We utilized the Magistral Small model, noted for its integrated reasoning capabilities, and fine-tuned it using Low-Rank Adaptation (LoRA). A key component of our approach was the creation of a \"dual-domain dataset,\" a comprehensive corpus curated from various sources encompassing both molecular properties and chemical reactions, which was standardized to ensure quality. Our evaluation demonstrates that the fine-tuned model achieves significant improvements over the baseline model in format adherence, chemical validity of generated molecules, and the feasibility of proposed synthesis routes. The results indicate a hierarchical learning pattern, where syntactic correctness is learned more readily than chemical possibility and synthesis feasibility. While a comparative analysis with human experts revealed competitive performance in areas like chemical creativity and reasoning, it also highlighted key limitations, including persistent errors in stereochemistry, a static knowledge cutoff, and occasional reference hallucination. This work establishes a viable framework for adapting generalist LLMs into reliable, specialized tools for chemical research, while also delineating critical areas for future improvement.",
    "chinese_title": "通过微调增强推理能力的LLM来弥合化学合成和发现中的合理性-有效性差距",
    "chinese_abstract": "大型语言模型（LLM）通常会生成科学上合理但事实上无效的信息，这是一种挑战，我们称之为“合理性-有效性差距”，尤其是在化学等专业领域。本文提出了一种系统的方法来弥合这一差距，通过开发一个专门的科学助手来实现。我们使用了Magistral Small模型，该模型以其集成的推理能力而闻名，并使用低秩适应（LoRA）对其进行了微调。我们方法的一个关键组成部分是创建“双领域数据集”，这是一个全面的语料库，从各种来源收集分子属性和化学反应，并进行标准化以确保质量。我们的评估表明，微调后的模型在格式遵守、生成的分子化学有效性以及提出的合成路线可行性方面，相比于基线模型取得了显著的改进。结果表明了一种分层学习模式，即语法正确性比化学可能性和合成可行性更容易学习。虽然与人类专家的比较分析表明在化学创造性和推理方面具有竞争性表现，但也突出了关键的局限性，包括立体化学中持续存在的错误、静态的知识截止点以及偶尔的参考文献幻觉。这项工作建立了一个将通用LLM适应为可靠的化学研究专用工具的可行框架，同时也明确了未来改进的关键领域。"
  },
  {
    "id": "arXiv:2507.07274",
    "title": "LinguaMark: Do Multimodal Models Speak Fairly? A Benchmark-Based Evaluation",
    "authors": "Ananya Raval, Aravind Narayanan, Vahid Reza Khazaie, Shaina Raza",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07274",
    "pdf_link": "https://arxiv.org/pdf/2507.07274",
    "score": 4,
    "abstract": "Large Multimodal Models (LMMs) are typically trained on vast corpora of image-text data but are often limited in linguistic coverage, leading to biased and unfair outputs across languages. While prior work has explored multimodal evaluation, less emphasis has been placed on assessing multilingual capabilities. In this work, we introduce LinguaMark, a benchmark designed to evaluate state-of-the-art LMMs on a multilingual Visual Question Answering (VQA) task. Our dataset comprises 6,875 image-text pairs spanning 11 languages and five social attributes. We evaluate models using three key metrics: Bias, Answer Relevancy, and Faithfulness. Our findings reveal that closed-source models generally achieve the highest overall performance. Both closed-source (GPT-4o and Gemini2.5) and open-source models (Gemma3, Qwen2.5) perform competitively across social attributes, and Qwen2.5 demonstrates strong generalization across multiple languages. We release our benchmark and evaluation code to encourage reproducibility and further research.",
    "chinese_title": "LinguaMark：多模态模型是否公平？基于基准的评估",
    "chinese_abstract": "大型多模态模型 (LMM) 通常在大量的图像-文本语料库上进行训练，但在语言覆盖范围上常常存在限制，导致跨语言的输出存在偏差和不公平现象。虽然先前的研究探索了多模态评估，但较少关注评估多语言能力。在这项工作中，我们引入了 LinguaMark，一个旨在评估最先进的 LMM 在多语言视觉问答 (VQA) 任务上的性能的基准。我们的数据集包含 6,875 个图像-文本对，涵盖 11 种语言和五种社会属性。我们使用三个关键指标评估模型：偏差、答案相关性和忠实度。我们的研究结果表明，闭源模型通常实现最高的整体性能。闭源模型（GPT-4o 和 Gemini2.5）和开源模型（Gemma3、Qwen2.5）在社会属性方面表现出竞争力，并且 Qwen2.5 在多种语言中表现出强大的泛化能力。我们发布我们的基准和评估代码，以鼓励可重复性和进一步的研究。"
  },
  {
    "id": "arXiv:2507.07247",
    "title": "Attentions Under the Microscope: A Comparative Study of Resource Utilization for Variants of Self-Attention",
    "authors": "Zhengyu Tian, Anantha Padmanaban Krishna Kumar, Hemant Krishnakumar, Reza Rawassizadeh",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE)",
    "abs_link": "https://arxiv.org/abs/2507.07247",
    "pdf_link": "https://arxiv.org/pdf/2507.07247",
    "score": 4,
    "abstract": "As large language models (LLMs) and visual language models (VLMs) grow in scale and application, attention mechanisms have become a central computational bottleneck due to their high memory and time complexity. While many efficient attention variants have been proposed, there remains a lack of rigorous evaluation on their actual energy usage and hardware resource demands during training. In this work, we benchmark eight attention mechanisms in training GPT-2 architecture, measuring key metrics including training time, GPU memory usage, FLOPS, CPU usage, and power consumption. Our results reveal that attention mechanisms with optimized kernel implementations, including Flash Attention, Locality-Sensitive Hashing (LSH) Attention, and Multi-Head Latent Attention (MLA), achieve the best energy efficiency. We further show that lower GPU power alone does not guarantee reduced energy use, as training time plays an equally important role. Our study highlights the importance of energy-aware benchmarking in attention design and provides a practical insight for selecting resource-efficient mechanisms. All our codes are available at GitHub.",
    "chinese_title": "显着力下观察：自注意力机制变体的资源利用率比较研究",
    "chinese_abstract": "随着大型语言模型（LLM）和视觉语言模型（VLM）的规模和应用不断扩大，注意力机制由于其高内存和时间复杂度已成为主要的计算瓶颈。虽然已经提出了许多高效的注意力变体，但仍然缺乏对它们在训练期间实际能源使用和硬件资源需求的严格评估。在这项工作中，我们在训练GPT-2架构时，对八种注意力机制进行了基准测试，测量了包括训练时间、GPU内存使用量、FLOPS、CPU使用率和功耗在内的关键指标。我们的结果表明，具有优化内核实现（包括Flash Attention、Locality-Sensitive Hashing (LSH) Attention和Multi-Head Latent Attention (MLA)）的注意力机制实现了最佳的能源效率。我们进一步表明，较低的GPU功耗并不能保证降低能源使用，因为训练时间也起着同样重要的作用。我们的研究强调了在注意力设计中进行能源感知基准测试的重要性，并为选择资源高效的机制提供了实际的见解。我们的所有代码都可在GitHub上获取。"
  },
  {
    "id": "arXiv:2507.07236",
    "title": "An Information-Theoretic Perspective on Multi-LLM Uncertainty Estimation",
    "authors": "Maya Kruse, Majid Afshar, Saksham Khatwani, Anoop Mayampurath, Guanhua Chen, Yanjun Gao",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07236",
    "pdf_link": "https://arxiv.org/pdf/2507.07236",
    "score": 4,
    "abstract": "Large language models (LLMs) often behave inconsistently across inputs, indicating uncertainty and motivating the need for its quantification in high-stakes settings. Prior work on calibration and uncertainty quantification often focuses on individual models, overlooking the potential of model diversity. We hypothesize that LLMs make complementary predictions due to differences in training and the Zipfian nature of language, and that aggregating their outputs leads to more reliable uncertainty estimates. To leverage this, we propose MUSE (Multi-LLM Uncertainty via Subset Ensembles), a simple information-theoretic method that uses Jensen-Shannon Divergence to identify and aggregate well-calibrated subsets of LLMs. Experiments on binary prediction tasks demonstrate improved calibration and predictive performance compared to single-model and naive ensemble baselines.",
    "chinese_title": "多LLM不确定性估计的信息论视角",
    "chinese_abstract": "大型语言模型 (LLM) 经常对不同的输入表现出不一致的行为，表明存在不确定性，并促使在高风险场景中对其进行量化。先前的校准和不确定性量化工作通常侧重于单个模型，而忽略了模型多样性的潜力。我们假设 LLM 由于训练差异和 Zipfian 语言的特性，会做出互补的预测，并且聚合它们的输出可以产生更可靠的不确定性估计。为了利用这一点，我们提出了 MUSE（通过子集集成进行多 LLM 不确定性估计），这是一种简单的信息论方法，它使用 Jensen-Shannon 散度来识别和聚合经过良好校准的 LLM 子集。在二元预测任务上的实验表明，与单模型和朴素集成基线相比，MUSE 提高了校准和预测性能。"
  },
  {
    "id": "arXiv:2507.07216",
    "title": "Bias-Aware Mislabeling Detection via Decoupled Confident Learning",
    "authors": "Yunyi Li, Maria De-Arteaga, Maytal Saar-Tsechansky",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Databases (cs.DB); Human-Computer Interaction (cs.HC)",
    "abs_link": "https://arxiv.org/abs/2507.07216",
    "pdf_link": "https://arxiv.org/pdf/2507.07216",
    "score": 3,
    "abstract": "Reliable data is a cornerstone of modern organizational systems. A notable data integrity challenge stems from label bias, which refers to systematic errors in a label, a covariate that is central to a quantitative analysis, such that its quality differs across social groups. This type of bias has been conceptually and empirically explored and is widely recognized as a pressing issue across critical domains. However, effective methodologies for addressing it remain scarce. In this work, we propose Decoupled Confident Learning (DeCoLe), a principled machine learning based framework specifically designed to detect mislabeled instances in datasets affected by label bias, enabling bias aware mislabelling detection and facilitating data quality improvement. We theoretically justify the effectiveness of DeCoLe and evaluate its performance in the impactful context of hate speech detection, a domain where label bias is a well documented challenge. Empirical results demonstrate that DeCoLe excels at bias aware mislabeling detection, consistently outperforming alternative approaches for label error detection. Our work identifies and addresses the challenge of bias aware mislabeling detection and offers guidance on how DeCoLe can be integrated into organizational data management practices as a powerful tool to enhance data reliability.",
    "chinese_title": "偏见感知错误标注检测：基于解耦置信学习",
    "chinese_abstract": "可靠的数据是现代组织系统的基石。一个显著的数据完整性挑战源于标签偏见，指的是定量分析中核心标签的系统性错误，其质量在不同社会群体中存在差异。这种偏见类型已被概念化和经验性地研究，并被广泛认为是跨关键领域的一个紧迫问题。然而，有效解决它的方法仍然稀缺。在本文中，我们提出了解耦置信学习 (DeCoLe)，一个专门设计的基于机器学习的框架，用于检测受标签偏见影响的数据集中错误标注的实例，从而实现偏见感知的错误标注检测并促进数据质量改进。我们从理论上证明了 DeCoLe 的有效性，并在仇恨言论检测这一具有影响力的背景下评估了其性能，仇恨言论检测是一个标签偏见已被充分记录的挑战领域。经验结果表明，DeCoLe 在偏见感知错误标注检测方面表现出色，始终优于其他标签错误检测方法。我们的工作识别并解决了偏见感知错误标注检测的挑战，并提供了关于如何将 DeCoLe 集成到组织数据管理实践中，作为增强数据可靠性的强大工具的指导。"
  },
  {
    "id": "arXiv:2507.07197",
    "title": "Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning",
    "authors": "Elia Piccoli, Malio Li, Giacomo Carfì, Vincenzo Lomonaco, Davide Bacciu",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07197",
    "pdf_link": "https://arxiv.org/pdf/2507.07197",
    "score": 4,
    "abstract": "The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.",
    "chinese_title": "结合预训练模型以增强强化学习中的特征表示",
    "chinese_abstract": "最近，预训练模型成为了许多领域（例如自然语言处理和计算机视觉）若干进步的关键组成部分。事实上，预训练模型学习不同的潜在嵌入，共享有价值的表示。另一方面，强化学习 (RL) 侧重于通过智能体与环境的交互来最大化累积奖励。强化学习智能体对世界没有任何先验知识，它们要么从头开始学习观察空间和动作空间之间的端到端映射，要么在更近期的研究中，与单体且计算成本高昂的基础模型配对。如何在强化学习中有效地组合和利用不同预训练模型的隐藏信息仍然是一个开放且研究不足的问题。在这项工作中，我们提出了权重共享注意力 (WSA)，这是一种新的架构，用于组合多个预训练模型的嵌入，以塑造丰富的状态表示，平衡效率和性能之间的权衡。我们在多种组合模式之间进行了广泛的比较，结果表明 WSA 在多个 Atari 游戏中获得了与端到端模型相当的性能。此外，我们研究了这种方法的泛化能力，并分析了模型数量的扩展如何影响训练期间和训练后的智能体性能。"
  },
  {
    "id": "arXiv:2507.07188",
    "title": "Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses",
    "authors": "Jens Rupprecht, Georg Ahnert, Markus Strohmaier",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Computers and Society (cs.CY)",
    "abs_link": "https://arxiv.org/abs/2507.07188",
    "pdf_link": "https://arxiv.org/pdf/2507.07188",
    "score": 4,
    "abstract": "Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts -- we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also reveal that all tested models exhibit a consistent \\textit{recency bias} varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.",
    "chinese_title": "提示扰动揭示了LLM调查回答中的类人偏见",
    "chinese_abstract": "大型语言模型 (LLM) 越来越多地被用作社会科学调查中人类受试者的代理，但它们的可信度和对已知反应偏差的易感性尚不清楚。本文调查了 LLM 在规范性调查环境中的响应稳健性——我们对来自世界价值观调查 (WVS) 的问题使用了九种不同的 LLM，并对问题措辞和答案选项结构应用了一套全面的 11 种扰动，从而产生了超过 167,000 次模拟访谈。通过这样做，我们不仅揭示了 LLM 对扰动的脆弱性，还揭示了所有测试的模型都表现出一致的“近期偏见”，其强度各不相同，不成比例地偏爱最后呈现的答案选项。虽然较大的模型通常更稳健，但所有模型仍然对语义变化（如释义）和组合扰动敏感。通过应用一组扰动，我们发现 LLM 部分符合人类中识别出的调查反应偏差。这强调了在使用 LLM 生成合成调查数据时，提示设计和稳健性测试的重要性。"
  },
  {
    "id": "arXiv:2507.07186",
    "title": "Planted in Pretraining, Swayed by Finetuning: A Case Study on the Origins of Cognitive Biases in LLMs",
    "authors": "Itay Itzhak, Yonatan Belinkov, Gabriel Stanovsky",
    "subjects": "Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)",
    "abs_link": "https://arxiv.org/abs/2507.07186",
    "pdf_link": "https://arxiv.org/pdf/2507.07186",
    "score": 4,
    "abstract": "Large language models (LLMs) exhibit cognitive biases -- systematic tendencies of irrational decision-making, similar to those seen in humans. Prior work has found that these biases vary across models and can be amplified by instruction tuning. However, it remains unclear if these differences in biases stem from pretraining, finetuning, or even random noise due to training stochasticity. We propose a two-step causal experimental approach to disentangle these factors. First, we finetune models multiple times using different random seeds to study how training randomness affects over $30$ cognitive biases. Second, we introduce \\emph{cross-tuning} -- swapping instruction datasets between models to isolate bias sources. This swap uses datasets that led to different bias patterns, directly testing whether biases are dataset-dependent. Our findings reveal that while training randomness introduces some variability, biases are mainly shaped by pretraining: models with the same pretrained backbone exhibit more similar bias patterns than those sharing only finetuning data. These insights suggest that understanding biases in finetuned models requires considering their pretraining origins beyond finetuning effects. This perspective can guide future efforts to develop principled strategies for evaluating and mitigating bias in LLMs.",
    "chinese_title": "植根于预训练，受微调影响：大型语言模型认知偏差起源的案例研究",
    "chinese_abstract": "大型语言模型 (LLM) 表现出认知偏差——系统性的非理性决策倾向，类似于人类所见的偏差。先前的研究发现，这些偏差因模型而异，并且可能被指令调优放大。然而，这些偏差差异是否源于预训练、微调，甚至训练随机性造成的随机噪声尚不清楚。我们提出了一种两步因果实验方法来解开这些因素。首先，我们使用不同的随机种子多次微调模型，以研究训练随机性如何影响 30 多个认知偏差。其次，我们引入了“交叉调优”——在模型之间交换指令数据集，以分离偏差来源。这种交换使用导致不同偏差模式的数据集，直接测试偏差是否依赖于数据集。我们的研究结果表明，虽然训练随机性会引入一些可变性，但偏差主要由预训练塑造：具有相同预训练主干的模型表现出比仅共享微调数据模型更相似的偏差模式。这些见解表明，理解微调模型的偏差需要考虑其预训练起源，而不仅仅是微调效果。这种视角可以指导未来开发原则性的策略，以评估和减轻 LLM 中的偏差。"
  },
  {
    "id": "arXiv:2507.07155",
    "title": "Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics",
    "authors": "Xueqing Xu, Boris Bolliet, Adrian Dimitrov, Andrew Laverick, Francisco Villaescusa-Navarro, Licong Xu, Íñigo Zubeldia",
    "subjects": "Instrumentation and Methods for Astrophysics (astro-ph.IM); Cosmology and Nongalactic Astrophysics (astro-ph.CO); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07155",
    "pdf_link": "https://arxiv.org/pdf/2507.07155",
    "score": 4,
    "abstract": "We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this purpose.The RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community.",
    "chinese_title": "评估用于天体物理学自主科学发现的检索增强生成智能体",
    "chinese_abstract": "我们评估了9种检索增强生成（RAG）智能体配置在105个为该目的专门构建的宇宙学问答（QA）对上的表现。这些RAG配置由人类专家手动评估，总共评估了945个生成的答案。我们发现，目前最佳的RAG智能体配置使用OpenAI嵌入和生成模型，准确率达到91.4%。利用我们的人工评估结果，我们校准了LLM即评判者（LLMaaJ）系统，该系统可以用作人类评估的可靠替代方案。这些结果使我们能够系统地选择最佳的RAG智能体配置，用于天体物理学自主科学发现的多智能体系统（例如，在配套论文中介绍的cmbagent），并提供一个可以扩展到数千个宇宙学QA对的LLMaaJ系统。我们公开了我们的QA数据集、人工评估结果、RAG管道和LLMaaJ系统，供天体物理学界进一步使用。"
  },
  {
    "id": "arXiv:2507.07151",
    "title": "Robust Multimodal Large Language Models Against Modality Conflict",
    "authors": "Zongmeng Zhang, Wengang Zhou, Jie Zhao, Houqiang Li",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL)",
    "abs_link": "https://arxiv.org/abs/2507.07151",
    "pdf_link": "https://arxiv.org/pdf/2507.07151",
    "score": 4,
    "abstract": "Despite the impressive capabilities of multimodal large language models (MLLMs) in vision-language tasks, they are prone to hallucinations in real-world scenarios. This paper investigates the hallucination phenomenon in MLLMs from the perspective of modality conflict. Unlike existing works focusing on the conflicts between model responses and inputs, we study the inherent conflicts in inputs from different modalities that place MLLMs in a dilemma and directly lead to hallucinations. We formally define the modality conflict and construct a dataset named Multimodal Modality Conflict (MMMC) to simulate this phenomenon in vision-language tasks. Three methods based on prompt engineering, supervised fine-tuning, and reinforcement learning are proposed to alleviate the hallucination caused by modality conflict. Extensive experiments are conducted on the MMMC dataset to analyze the merits and demerits of these methods. Our results show that the reinforcement learning method achieves the best performance in mitigating the hallucination under modality conflict, while the supervised fine-tuning method shows promising and stable performance. Our work sheds light on the unnoticed modality conflict that leads to hallucinations and provides more insights into the robustness of MLLMs.",
    "chinese_title": "针对模态冲突的鲁棒多模态大型语言模型",
    "chinese_abstract": "尽管多模态大型语言模型 (MLLM) 在视觉-语言任务中表现出令人印象深刻的能力，但它们在现实场景中容易出现幻觉。本文从模态冲突的角度研究 MLLM 中的幻觉现象。与现有侧重于模型响应与输入之间冲突的工作不同，我们研究不同模态输入中固有的冲突，这些冲突使 MLLM 陷入困境并直接导致幻觉。我们正式定义了模态冲突，并构建了一个名为多模态模态冲突 (MMMC) 的数据集，以模拟视觉-语言任务中的这种现象。提出了三种基于提示工程、监督微调和强化学习的方法来缓解由模态冲突引起的幻觉。我们在 MMMC 数据集上进行了广泛的实验，以分析这些方法的优缺点。我们的结果表明，强化学习方法在减轻模态冲突下的幻觉方面取得了最佳性能，而监督微调方法表现出有希望且稳定的性能。我们的工作揭示了导致幻觉的未被注意到的模态冲突，并提供了关于 MLLM 鲁棒性的更多见解。"
  },
  {
    "id": "arXiv:2507.07147",
    "title": "Weighted Multi-Prompt Learning with Description-free Large Language Model Distillation",
    "authors": "Sua Lee, Kyubum Shin, Jung Ho Park",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)",
    "abs_link": "https://arxiv.org/abs/2507.07147",
    "pdf_link": "https://arxiv.org/pdf/2507.07147",
    "score": 4,
    "abstract": "Recent advances in pre-trained Vision Language Models (VLM) have shown promising potential for effectively adapting to downstream tasks through prompt learning, without the need for additional annotated paired datasets. To supplement the text information in VLM trained on correlations with vision data, new approaches leveraging Large Language Models (LLM) in prompts have been proposed, enhancing robustness to unseen and diverse data. Existing methods typically extract text-based responses (i.e., descriptions) from LLM to incorporate into prompts; however, this approach suffers from high variability and low reliability. In this work, we propose Description-free Multi-prompt Learning(DeMul), a novel method that eliminates the process of extracting descriptions and instead directly distills knowledge from LLM into prompts. By adopting a description-free approach, prompts can encapsulate richer semantics while still being represented as continuous vectors for optimization, thereby eliminating the need for discrete pre-defined templates. Additionally, in a multi-prompt setting, we empirically demonstrate the potential of prompt weighting in reflecting the importance of different prompts during training. Experimental results show that our approach achieves superior performance across 11 recognition datasets.",
    "chinese_title": "加权多提示学习与无描述大型语言模型知识蒸馏",
    "chinese_abstract": "最近，预训练的视觉语言模型 (VLM) 在通过提示学习有效适应下游任务方面显示出令人鼓舞的潜力，无需额外的标注配对数据集。为了补充 VLM 中与视觉数据相关的文本信息，已经提出了利用大型语言模型 (LLM) 在提示中的新方法，从而提高了对未见和多样化数据的鲁棒性。现有方法通常从 LLM 中提取基于文本的响应（即描述）以纳入提示中；然而，这种方法存在高变异性和低可靠性的问题。在这项工作中，我们提出了无描述多提示学习 (DeMul)，这是一种新颖的方法，它消除了提取描述的过程，而是直接将 LLM 的知识蒸馏到提示中。通过采用无描述的方法，提示可以封装更丰富的语义，同时仍然表示为用于优化的连续向量，从而无需离散的预定义模板。此外，在多提示设置中，我们通过实验证明了提示权重在训练过程中反映不同提示重要性的潜力。实验结果表明，我们的方法在 11 个识别数据集上实现了卓越的性能。"
  },
  {
    "id": "arXiv:2507.07120",
    "title": "Helix Parallelism: Rethinking Sharding Strategies for Interactive Multi-Million-Token LLM Decoding",
    "authors": "Nidhi Bhatia, Ankit More, Ritika Borkar, Tiyasa Mitra, Ramon Matas, Ritchie Zhao, Maximilian Golub, Dheevatsa Mudigere, Brian Pharris, Bita Darvish Rouhani",
    "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2507.07120",
    "pdf_link": "https://arxiv.org/pdf/2507.07120",
    "score": 3,
    "abstract": "As LLMs scale to multi-million-token KV histories, real-time autoregressive decoding under tight Token-to-Token Latency (TTL) constraints faces growing pressure. Two core bottlenecks dominate: accessing Feed-Forward Network (FFN) weights and reading long KV caches. While Tensor Parallelism (TP) helps mitigate the cost of FFN weight reads, it does not scale well for attention. When TP width exceeds the number of KV heads, it leads to inefficient KV duplication, limits parallelism, and constrains batch size. Simultaneously, DRAM reads for long KV histories scale linearly with batch size, further capping efficiency.   We introduce Helix Parallelism, a hybrid execution strategy that applies KV parallelism during attention to shard KV caches across GPUs, then reuses the same GPUs for TP in dense LLMs or TPxExpert Parallel (EP) in MoEs during FFN computation. To preserve exact attention behavior, Helix includes a lightweight communication step. To minimize the exposed communication cost, we introduce Helix HOP-B. Helix HOP-B effectively minimizes communication overhead through batchwise overlap, preserving low TTL while improving GPU efficiency. Compared to conventional parallelism approaches, Helix reduces TTL by up to 1.5x at fixed batch sizes and supports up to 32x larger batches under the same latency budget for DeepSeek-R1, pushing forward the throughput-latency Pareto on Blackwell and making real-time inference with ultra-long-sequence practical.",
    "chinese_title": "螺旋并行：重新思考交互式百万级Token LLM解码的分片策略",
    "chinese_abstract": "随着LLM扩展到百万级Token的KV历史，在严格的Token-to-Token延迟（TTL）约束下进行实时自回归解码面临越来越大的压力。两个核心瓶颈占据主导地位：访问前馈网络（FFN）权重和读取长KV缓存。虽然张量并行（TP）有助于减轻FFN权重读取的成本，但它不能很好地扩展到注意力机制。当TP宽度超过KV头的数量时，会导致低效的KV复制，限制并行性，并约束批次大小。同时，长KV历史的DRAM读取随批次大小线性增长，进一步限制了效率。我们引入了螺旋并行，这是一种混合执行策略，在注意力期间应用KV并行性，以在GPU之间分片KV缓存，然后在密集LLM或MoE中的FFN计算中使用相同的GPU进行TP或TPxExpert并行（EP）。为了保持精确的注意力行为，螺旋包含一个轻量级的通信步骤。为了最大限度地减少暴露的通信成本，我们引入了螺旋HOP-B。螺旋HOP-B通过批次重叠有效地最大限度地减少通信开销，同时保持低TTL并提高GPU效率。与传统的并行方法相比，螺旋在固定批次大小下将TTL降低高达1.5倍，并支持在相同的延迟预算下DeepSeek-R1的批次大小增加32倍，从而推动Blackwell上的吞吐量-延迟帕累托前沿，并使超长序列的实时推理成为可能。"
  },
  {
    "id": "arXiv:2507.07117",
    "title": "Collective Communication Profiling of Modern-day Machine Learning Workloads",
    "authors": "Jit Gupta, Andrew Li, Tarun Banka, Ariel Cohen, T. Sridhar, Raj Yavatkar",
    "subjects": "Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (cs.AI); Networking and Internet Architecture (cs.NI)",
    "abs_link": "https://arxiv.org/abs/2507.07117",
    "pdf_link": "https://arxiv.org/pdf/2507.07117",
    "score": 3,
    "abstract": "Machine Learning jobs, carried out on large number of distributed high performance systems, involve periodic communication using operations like AllReduce, AllGather, and Broadcast. These operations may create high bandwidth and bursty traffic patterns, leading to network congestion and packet loss, thus impacting the performance of these jobs. Hence it is imperative to analyze these patterns, which can be helpful in provisioning network resources depending on the type of machine learning workloads. In this poster we carry out extensive analysis of the collective communication behavior seen in a wide variety of models (ex. DeepSeek, GPT, Llama, etc.) To achieve this we instrument Nvidia Collective Communication Library logging functionality for richer context about the collectives and workloads. We adjust configuration parameters that influence collective communication behavior, such as parallelism, number of nodes, and model type. This overview presents and discusses some of the results on the collective communication behavior for the open source DeepSeek V3 inferencing model, which includes operation type and count, transfer sizes per operation, and request size distribution. Our analysis shows that it makes sense to rethink current collective communication frameworks and network topologies so as to accommodate the effect of network anomalies on the mentioned workloads.",
    "chinese_title": "现代机器学习工作负载的集体通信剖析",
    "chinese_abstract": "机器学习任务在大量分布式高性能系统上执行时，涉及使用 AllReduce、AllGather 和 Broadcast 等操作进行周期性通信。这些操作可能会产生高带宽和突发流量模式，导致网络拥塞和数据包丢失，从而影响任务的性能。因此，分析这些模式至关重要，这有助于根据机器学习工作负载的类型来配置网络资源。在本海报中，我们对各种模型（例如 DeepSeek、GPT、Llama 等）中观察到的集体通信行为进行了广泛分析。为了实现这一点，我们利用 Nvidia Collective Communication Library 的日志记录功能，以获取关于集体操作和工作负载的更丰富的信息。我们调整了影响集体通信行为的配置参数，例如并行性、节点数量和模型类型。本概述展示并讨论了针对开源 DeepSeek V3 推理模型的一些集体通信行为结果，包括操作类型和数量、每个操作的传输大小以及请求大小分布。我们的分析表明，有必要重新思考当前的集体通信框架和网络拓扑，以适应网络异常对上述工作负载的影响。"
  },
  {
    "id": "arXiv:2507.07108",
    "title": "Multi-level Mixture of Experts for Multimodal Entity Linking",
    "authors": "Zhiwei Hu, Víctor Gutiérrez-Basulto, Zhiliang Xiang, Ru Li, Jeff Z. Pan",
    "subjects": "Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Computation and Language (cs.CL); Machine Learning (cs.LG); Multimedia (cs.MM)",
    "abs_link": "https://arxiv.org/abs/2507.07108",
    "pdf_link": "https://arxiv.org/pdf/2507.07108",
    "score": 4,
    "abstract": "Multimodal Entity Linking (MEL) aims to link ambiguous mentions within multimodal contexts to associated entities in a multimodal knowledge base. Existing approaches to MEL introduce multimodal interaction and fusion mechanisms to bridge the modality gap and enable multi-grained semantic matching. However, they do not address two important problems: (i) mention ambiguity, i.e., the lack of semantic content caused by the brevity and omission of key information in the mention's textual context; (ii) dynamic selection of modal content, i.e., to dynamically distinguish the importance of different parts of modal information. To mitigate these issues, we propose a Multi-level Mixture of Experts (MMoE) model for MEL. MMoE has four components: (i) the description-aware mention enhancement module leverages large language models to identify the WikiData descriptions that best match a mention, considering the mention's textual context; (ii) the multimodal feature extraction module adopts multimodal feature encoders to obtain textual and visual embeddings for both mentions and entities; (iii)-(iv) the intra-level mixture of experts and inter-level mixture of experts modules apply a switch mixture of experts mechanism to dynamically and adaptively select features from relevant regions of information. Extensive experiments demonstrate the outstanding performance of MMoE compared to the state-of-the-art. MMoE's code is available at: https://github.com/zhiweihu1103/MEL-MMoE.",
    "chinese_title": "多层次混合专家模型用于多模态实体链接",
    "chinese_abstract": "多模态实体链接 (MEL) 旨在将多模态上下文中歧义的提及链接到多模态知识库中的相关实体。现有的 MEL 方法引入了多模态交互和融合机制来弥合模态差距并实现多粒度语义匹配。然而，它们并未解决两个重要问题：(i) 提及歧义，即由于提及文本上下文中关键信息的简短和省略而导致的语义内容缺乏；(ii) 模态内容动态选择，即动态区分不同部分模态信息的重要性。为了缓解这些问题，我们提出了一种用于 MEL 的多层次混合专家 (MMoE) 模型。MMoE 具有四个组成部分：(i) 描述感知提及增强模块利用大型语言模型识别与提及最匹配的 WikiData 描述，同时考虑提及的文本上下文；(ii) 多模态特征提取模块采用多模态特征编码器来获得提及和实体的文本和视觉嵌入；(iii)-(iv) 层次内混合专家和层次间混合专家模块应用切换混合专家机制来动态和自适应地选择来自相关信息区域的特征。大量的实验证明了 MMoE 与最先进技术的出色性能。MMoE 的代码可在以下网址获取：https://github.com/zhiweihu1103/MEL-MMoE。"
  },
  {
    "id": "arXiv:2506.21142",
    "title": "Generative Adversarial Evasion and Out-of-Distribution Detection for UAV Cyber-Attacks",
    "authors": "Deepak Kumar Panda, Weisi Guo",
    "subjects": "Machine Learning (cs.LG); Artificial Intelligence (cs.AI)",
    "abs_link": "https://arxiv.org/abs/2506.21142",
    "pdf_link": "https://arxiv.org/pdf/2506.21142",
    "score": 3,
    "abstract": "The growing integration of UAVs into civilian airspace underscores the need for resilient and intelligent intrusion detection systems (IDS), as traditional anomaly detection methods often fail to identify novel threats. A common approach treats unfamiliar attacks as out-of-distribution (OOD) samples; however, this leaves systems vulnerable when mitigation is inadequate. Moreover, conventional OOD detectors struggle to distinguish stealthy adversarial attacks from genuine OOD events. This paper introduces a conditional generative adversarial network (cGAN)-based framework for crafting stealthy adversarial attacks that evade IDS mechanisms. We first design a robust multi-class IDS classifier trained on benign UAV telemetry and known cyber-attacks, including Denial of Service (DoS), false data injection (FDI), man-in-the-middle (MiTM), and replay attacks. Using this classifier, our cGAN perturbs known attacks to generate adversarial samples that misclassify as benign while retaining statistical resemblance to OOD distributions. These adversarial samples are iteratively refined to achieve high stealth and success rates. To detect such perturbations, we implement a conditional variational autoencoder (CVAE), leveraging negative log-likelihood to separate adversarial inputs from authentic OOD samples. Comparative evaluation shows that CVAE-based regret scores significantly outperform traditional Mahalanobis distance-based detectors in identifying stealthy adversarial threats. Our findings emphasize the importance of advanced probabilistic modeling to strengthen IDS capabilities against adaptive, generative-model-based cyber intrusions.",
    "chinese_title": "生成对抗性规避与用于无人机网络攻击的分布外检测",
    "chinese_abstract": "无人机日益融入民用空域，凸显了对具有弹性和智能入侵检测系统（IDS）的需求，因为传统的异常检测方法通常无法识别新型威胁。一种常见的方法将陌生的攻击视为分布外（OOD）样本；然而，当缓解措施不足时，这会使系统容易受到攻击。此外，传统的OOD检测器难以区分隐蔽的对抗性攻击和真实的OOD事件。本文介绍了一种基于条件生成对抗网络（cGAN）的框架，用于构建规避IDS机制的隐蔽对抗性攻击。我们首先设计了一个强大的多类IDS分类器，该分类器在良性无人机遥测数据和已知的网络攻击（包括拒绝服务（DoS）、虚假数据注入（FDI）、中间人攻击（MiTM）和重放攻击）上进行训练。利用该分类器，我们的cGAN扰动已知的攻击，生成被错误分类为良性的对抗样本，同时保留与OOD分布的统计相似性。这些对抗样本经过迭代优化，以实现高隐蔽性和成功率。为了检测此类扰动，我们实现了条件变分自编码器（CVAE），利用负对数似然来区分对抗性输入和真实的OOD样本。比较评估表明，基于CVAE的后悔分数在识别隐蔽对抗性威胁方面显著优于传统的基于马氏距离的检测器。我们的研究结果强调了先进的概率建模对于加强IDS能力以应对自适应的、基于生成模型的网络入侵的重要性。"
  }
]