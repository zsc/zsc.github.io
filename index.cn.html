<!DOCTYPE html>
<html>
<head>
    <title>周舒畅博士</title>
    <meta http-equiv=Content-Type content="text/html; charset=utf-8">
<style>
    #MyBody {
        margin-left: 200px;
        margin-top: 40px
    }
    #PageBody {
        margin-left: 200px;
        margin-right: 200px;
        margin-bottom: 100px;
        height: 800px;
    }
    #Notice {
        margin-left: 200px;
        margin-right: 200px;
        height: 12px;
    }
</style>
</head>

<body style="background-color=#ffffff;">
        <table id="MyBody">
            <tbody>
               <tr>
                <td width="20"></td>
                <td width="260">
                    <img src="zsc.jpg" width="150" height="200" alt="周舒畅的照片" />
                </td>
                <td width="40"></td>
                <td>
                    周舒畅
                    <br />博士，
                    <br />
                    <address><a href="mailto:shuchang [dot] zhou [at] gmail.com">shuchang [dot] zhou [at] gmail.com</a></address> 
                    <br />
	            我于2004年毕业于清华大学，并在中国科学院获得博士学位。
		    <br />
                </td>
                </tr>
            </tbody>
        </table>
        <div id="PageBody">
            <br />
            <hr />
            <h2>演讲</h2>
            <ul>
		<li> 计算机视觉的软硬件协同设计（<a href="https://github.com/zsc/zsc.github.io/blob/master/Hardware-software%20co-design%20for%20Computer%20Vision.pdf">PDF</a>），清华大学，2022年4月</li>
		<li> 神经网络与计算机架构的协同进化（<a href="Coevolution of Neural Network and Computer Architecture(3).pdf">PDF</a>），2019年8月</li>
		<li> 对未来三年计算机架构的展望（<a href="Speculations+about+Computer+Architecture+in+Next+Three+Years.pdf">PDF</a>），2018年1月20日</li>
		<li> 使用Haskell和FPGA模拟的量子计算（<a href="Quantum Computing with Haskell and FPGA simulation.pdf" target="_blank">PDF</a>，<a href="https://github.com/zsc/qubit-fpga">GitHub</a>），2018年1月18日</li>
		<li> 基于量化神经网络的智能嵌入式视觉（<a href="Smart Embedded Vision with Low Bitwidth Networks.pdf">PDF</a>），清华大学，2017年7月8日</li>
                <li> 深度学习的实用方法论（<a href="Practical Methodology in Deep Learning.pdf" target="_blank">PDF</a>），北京大学，2017年4月</li>
                <li> 神经网络近似（<a href="Neural Network Approximation.pdf" target="_blank">PDF</a>），清华大学姚班，2016年11月</li>
		<li> 指针级分析（<a href="https://github.com/zsc/zsc.github.io/blob/fde85733a7bab395c4f932c0c4174f31eab7d1f3/Pointer%20level%20analysis.pdf" target="_blank">PDF</a>），2009年</li>
            </ul>

            <hr />
            <h2> 代表性论文</h2>
            <ul>
		<li> (2025) Step-audio: 智能语音交互中的统一理解和生成</li>
		<li> (ECCV'24) Chat-edit-3d: 基于文本提示的交互式3D场景编辑</li>
		<li> (ICCAD'23) Sole: 面向高效Transformer推理的Softmax和LayerNorm的软硬件协同设计</li>
		<li> (AAAI'23) One is all: 通过渐进式体积蒸馏弥合神经辐射场架构之间的差距</li>
		<li> (2023) Occdepth: 一种面向3D语义场景补全的深度感知方法</li>
	        <li> (ICCV'23) Occ$^2$Net: 基于3D占用估计的鲁棒图像匹配方法（用于遮挡区域）</li>
		<li> (CVPR'23 highlight) 一种用于视频预测的动态多尺度体素流网络. (<a href="https://arxiv.org/abs/2303.09875">arxiv</a>, <a href="https://github.com/megvii-research/CVPR2023-DMVFN">github</a>) </li>		    
		<li> (CVPR'23 highlight) UniDistill：用于鸟瞰图中3D目标检测的通用跨模态知识蒸馏框架. (<a href="https://arxiv.org/abs/2303.15083">arxiv</a>, <a href="https://github.com/megvii-research/CVPR2023-UniDistill">github</a>)  </li>
		<li> (AAAI oral) One is All: 通过渐进式体积蒸馏弥合神经辐射场架构之间的差距. (<a href="https://arxiv.org/abs/2211.15977">arxiv</a>, <a href="https://github.com/megvii-research/AAAI2023-PVD">github</a>) </li>
		<li> (ECCV oral) 协同自监督和量化学习。(<a href="https://arxiv.org/abs/2207.05432">arxiv</a>, <a href="https://github.com/megvii-research/SSQL-ECCV2022">github</a>) </li>
		<li> (ECCV) RIFE：用于视频帧插值的实时中间流估计。(<a href="https://arxiv.org/abs/2011.06294">arxiv</a>, <a href="https://github.com/hzwer/arXiv2020-RIFE">github</a>) </li>
		<li> (EACL) 多分割可逆变换器可以增强神经机器翻译</li>
		<li> (IJCAI) Fq-vit：无需重新训练的全量化视觉变换器. (<a href="https://arxiv.org/abs/2111.13824">arxiv</a>, <a href="https://github.com/megvii-research/FQ-ViT">github</a>) </li>   
		<li> (EMNLP) 主动学习方法增强神经机器翻译。(<a href="https://aclanthology.org/2020.findings-emnlp.162.pdf">pdf</a>) </li>   
		<li> (ICCV) 基于模型的深度强化学习的绘画学习。(<a href="https://arxiv.org/abs/1903.04411">arxiv</a>, <a href="https://github.com/megvii-research/ICCV2019-LearningToPaint">github</a>) </li>		    
                <li> (CVPR) EAST：一种高效且准确的场景文字检测器。(<a href="https://arxiv.org/abs/1704.03155">arxiv</a>) </li>
		<li> (BMVC) GeneGAN：从非配对数据中学习对象变形和属性子空间。(<a href="https://arxiv.org/abs/1705.04932">arxiv</a>，<a href="GeneGAN-BMVC2017.pdf">幻灯片</a>，<a href="https://github.com/megvii-research/GeneGAN">GitHub</a>) </li>
		<li> DoReFa-Net：用低比特宽度梯度训练低比特宽度卷积神经网络。(<a href="https://arxiv.org/abs/1606.06160">arxiv</a>，<a href="https://github.com/ppwwyyxx/tensorpack/tree/master/examples/DoReFa-Net">GitHub</a>) </li>
		<li> 随机替换策略缓存的高效模拟算法。<a href="https://hal.inria.fr/hal-01054982/document">PDF</a>，<a href="npc_sim_cache.pdf">幻灯片</a>，<a href="https://github.com/zsc/sim-cache">GitHub</a> </li>
		<li> Open64 on MIPS：为龙芯II移植和增强Open64 </li>
		<li> <a href="https://scholar.google.com/citations?user=zYI0rysAAAAJ&hl=en">Google Scholar（引用7000+）</a> </li>
		<li> 两个项目达到 4000+ Github star, 分别是 <a href="https://github.com/stepfun-ai/Step-Audio"> Step-Audio </a> 和 <a href="https://github.com/hzwer/ECCV2022-RIFE"> RIFE </a>.
</ul>
        <hr />

		<h2>竞赛</h2>
		<ul>
			<li> 在ACM Multimedia ViCo 2022对话式头部生成挑战赛中，听力头部生成赛道获得第一名，说话头部生成赛道获得第二名，<a href="https://arxiv.org/pdf/2206.12837.pdf">报告</a> </li>
			<li> 第一名, <a href="https://www.ecole.ai/2021/ml4co-competition/#leaderboard">NeurIPS'21机器学习组合优化</a>双任务赛道。<a href="https://github.com/megvii-research/NeurIPS2021-ML4CO-KIDA">代码</a> </li>				
			<li> 第二名，<a href="https://www.crowdai.org/challenges/nips-2017-learning-to-run/leaderboards">NIPS'17学习跑步挑战赛</a>该竞赛旨在教导骨架尽可能快地奔跑。我们提出了演员-评论家集成（ACE）方法（<a href="https://arxiv.org/abs/1712.08987">PDF</a>，<a href="https://github.com/hzwer/NIPS2017-LearningToRun">Github</a>）。 </li>
			<li> 第一名, <a href="http://nvlpubs.nist.gov/nistpubs/ir/2017/NIST.IR.8199.pdf">NIST TRAIT '16</a>的所有赛道。这是一场关于野外文本识别（OCR）的竞赛。 </li>
		</ul>
		<hr />

        <h2>研究领域</h2>
        <ul>
            <li>机器学习与人工智能</li>
            <li>计算机架构</li>
            <li>随机优化</li>
        </ul>

        <hr />
    <h2>学术服务</h2>
	<li>（中文）在北京大学联合组织了三年的<a href="https://github.com/megvii-research/megvii-pku-dl-course">深度学习与计算机视觉</a>课程。</li>
	<li>（中文）在清华大学讲授计算机视觉和量化神经网络课程<a href="https://github.com/megvii-research/megvii-tsinghua-dl-course">链接</a></li>
	<li>担任<a href="https://jmlr.org/editorial-board-reviewers.html">JMLR编辑委员会</a>成员。</li>
        <hr />
        <!-- hhmts start -->最后更新：2025年3月。
    </div>
</body></html>
